Topic,Count,Name,Representation,Representative_Docs
-1,256,-1_german_political_conversational_energy,"['german', 'political', 'conversational', 'energy', 'sampling']","['why we need to abandon fixed cutoffs for goodness-of-fit indices: an extensive simulation and possible solutions {to evaluate model fit in confirmatory factor analysis, researchers compare goodness-of-fit indices (gofs) against fixed cutoff values (e.g., cfi >.950) derived from simulation studies. methodologists have cautioned that cutoffs for gofs are only valid for settings similar to the simulation scenarios from which cutoffs originated. despite these warnings, fixed cutoffs for popular gofs (i.e., χ2, χ2/df, cfi, rmsea, srmr) continue to be widely used in applied research. we (1) argue that the practice of using fixed cutoffs needs to be abandoned and (2) review time-honored and emerging alternatives to fixed cutoffs. we first present the most in-depth simulation study to date on the sensitivity of gofs to model misspecification (i.e., misspecified factor dimensionality and unmodeled cross-loadings) and their susceptibility to further data and analysis characteristics (i.e., estimator, number of indicators, number and distribution of response options, loading magnitude, sample size, and factor correlation). we included all characteristics identified as influential in previous studies. our simulation enabled us to replicate well-known influences on gofs and establish hitherto unknown or underappreciated ones. in particular, the magnitude of the factor correlation turned out to moderate the effects of several characteristics on gofs. second, to address these problems, we discuss several strategies for assessing model fit that take the dependency of gofs on the modeling context into account. we highlight tailored (or “dynamic”) cutoffs as a way forward. we provide convenient tables with scenario-specific cutoffs as well as regression formulae to predict cutoffs tailored to the empirical setting of interest.} {confirmatory factor analysis,fit index,goodness-of-fit,ordered categorical data,structural equation modeling} {confirmatory factor analysis,fit index,goodness-of-fit,ordered categorical data,structural equation modeling}', 'why we need to abandon fixed cutoffs for goodness-of-fit indices: an extensive simulation and possible solutions {to evaluate model fit in confirmatory factor analysis, researchers compare goodness-of-fit indices (gofs) against fixed cutoff values (e.g., cfi >.950) derived from simulation studies. methodologists have cautioned that cutoffs for gofs are only valid for settings similar to the simulation scenarios from which cutoffs originated. despite these warnings, fixed cutoffs for popular gofs (i.e., χ2, χ2/df, cfi, rmsea, srmr) continue to be widely used in applied research. we (1) argue that the practice of using fixed cutoffs needs to be abandoned and (2) review time-honored and emerging alternatives to fixed cutoffs. we first present the most in-depth simulation study to date on the sensitivity of gofs to model misspecification (i.e., misspecified factor dimensionality and unmodeled cross-loadings) and their susceptibility to further data and analysis characteristics (i.e., estimator, number of indicators, number and distribution of response options, loading magnitude, sample size, and factor correlation). we included all characteristics identified as influential in previous studies. our simulation enabled us to replicate well-known influences on gofs and establish hitherto unknown or underappreciated ones. in particular, the magnitude of the factor correlation turned out to moderate the effects of several characteristics on gofs. second, to address these problems, we discuss several strategies for assessing model fit that take the dependency of gofs on the modeling context into account. we highlight tailored (or “dynamic”) cutoffs as a way forward. we provide convenient tables with scenario-specific cutoffs as well as regression formulae to predict cutoffs tailored to the empirical setting of interest.} {confirmatory factor analysis,fit index,goodness-of-fit,ordered categorical data,structural equation modeling} {confirmatory factor analysis,fit index,goodness-of-fit,ordered categorical data,structural equation modeling}', 'why we need to abandon fixed cutoffs for goodness-of-fit indices: an extensive simulation and possible solutions {to evaluate model fit in confirmatory factor analysis, researchers compare goodness-of-fit indices (gofs) against fixed cutoff values (e.g., cfi >.950) derived from simulation studies. methodologists have cautioned that cutoffs for gofs are only valid for settings similar to the simulation scenarios from which cutoffs originated. despite these warnings, fixed cutoffs for popular gofs (i.e., χ2, χ2/df, cfi, rmsea, srmr) continue to be widely used in applied research. we (1) argue that the practice of using fixed cutoffs needs to be abandoned and (2) review time-honored and emerging alternatives to fixed cutoffs. we first present the most in-depth simulation study to date on the sensitivity of gofs to model misspecification (i.e., misspecified factor dimensionality and unmodeled cross-loadings) and their susceptibility to further data and analysis characteristics (i.e., estimator, number of indicators, number and distribution of response options, loading magnitude, sample size, and factor correlation). we included all characteristics identified as influential in previous studies. our simulation enabled us to replicate well-known influences on gofs and establish hitherto unknown or underappreciated ones. in particular, the magnitude of the factor correlation turned out to moderate the effects of several characteristics on gofs. second, to address these problems, we discuss several strategies for assessing model fit that take the dependency of gofs on the modeling context into account. we highlight tailored (or “dynamic”) cutoffs as a way forward. we provide convenient tables with scenario-specific cutoffs as well as regression formulae to predict cutoffs tailored to the empirical setting of interest.} {confirmatory factor analysis,fit index,goodness-of-fit,ordered categorical data,structural equation modeling} {confirmatory factor analysis,fit index,goodness-of-fit,ordered categorical data,structural equation modeling}']"
0,42,0_migration_party_candidates_attitudes,"['migration', 'party', 'candidates', 'attitudes', 'german federal election']","['should i stay or should i go? testing the influence of ambivalence on vote switching in the german multi-party context {does political ambivalence increase vote switching? while the effects of ambivalence on vote switching have been investigated in the american political sys-tem, its application to multi-party systems has not been explored. to address this gap, this article investigates the effects of ambivalence on vote intention switching and vote switching in germany’s multi-party system, which has recently experienced electoral instability. using the german longitudinal election study (gles), the article teases out the mechanics of party ambivalence, leader ambivalence, and party-leader ambivalence. the results suggest that ambivalence increases the probability of vot-ers switching parties during the pre-election campaigning period and between two consecutive elections. ambivalence therefore has important implications for vote switching and for understanding the underlying determinants of electoral volatility in twenty-first-century politics.} {ambivalence,multi-party system,partisanship,political attitudes,vote switching,voting behavior} {ambivalence,multi-party system,partisanship,political attitudes,vote switching,voting behavior}', 'should i stay or should i go? testing the influence of ambivalence on vote switching in the german multi-party context {does political ambivalence increase vote switching? while the effects of ambivalence on vote switching have been investigated in the american political sys-tem, its application to multi-party systems has not been explored. to address this gap, this article investigates the effects of ambivalence on vote intention switching and vote switching in germany’s multi-party system, which has recently experienced electoral instability. using the german longitudinal election study (gles), the article teases out the mechanics of party ambivalence, leader ambivalence, and party-leader ambivalence. the results suggest that ambivalence increases the probability of vot-ers switching parties during the pre-election campaigning period and between two consecutive elections. ambivalence therefore has important implications for vote switching and for understanding the underlying determinants of electoral volatility in twenty-first-century politics.} {ambivalence,multi-party system,partisanship,political attitudes,vote switching,voting behavior} {ambivalence,multi-party system,partisanship,political attitudes,vote switching,voting behavior}', 'should i stay or should i go? testing the influence of ambivalence on vote switching in the german multi-party context {does political ambivalence increase vote switching? while the effects of ambivalence on vote switching have been investigated in the american political sys-tem, its application to multi-party systems has not been explored. to address this gap, this article investigates the effects of ambivalence on vote intention switching and vote switching in germany’s multi-party system, which has recently experienced electoral instability. using the german longitudinal election study (gles), the article teases out the mechanics of party ambivalence, leader ambivalence, and party-leader ambivalence. the results suggest that ambivalence increases the probability of vot-ers switching parties during the pre-election campaigning period and between two consecutive elections. ambivalence therefore has important implications for vote switching and for understanding the underlying determinants of electoral volatility in twenty-first-century politics.} {ambivalence,multi-party system,partisanship,political attitudes,vote switching,voting behavior} {ambivalence,multi-party system,partisanship,political attitudes,vote switching,voting behavior}']"
1,40,1_elections_distributed_dimension_party,"['elections', 'distributed', 'dimension', 'party', 'europe']","['river sampling – a fishing expedition: a non-probability case study {the ease with which large amounts of data can be collected via the internet has led to a renewed interest in the use of non-probability samples. to that end, this paper performs a case study, comparing two non-probability datasets – one based on a river-sampling approach, one drawn from an online-access panel – to a reference probability sample. of particular interest is the single-question river-sampling approach, as the data collected for this study presents an attempt to field a multi-item scale with such a sampling method. each dataset consists of the same psychometric measures for two of the big-5 personality traits, which are expected to perform independently of sample composition. to assess the similarity of the three datasets we compare their correlation matrices, apply linear and non-linear dimension reduction techniques, and analyze the distance between the datasets. our results show that there are important limitations when implementing a multi-item scale via a single-question river sample. we find that, while the correlation between our data sets is similar, the samples are composed of persons with different personality traits.} {big-5,non-linear dimension reduction,non-probability sample,river sample,web survey research} {big-5,non-linear dimension reduction,non-probability sample,river sample,web survey research}', 'river sampling – a fishing expedition: a non-probability case study {the ease with which large amounts of data can be collected via the internet has led to a renewed interest in the use of non-probability samples. to that end, this paper performs a case study, comparing two non-probability datasets – one based on a river-sampling approach, one drawn from an online-access panel – to a reference probability sample. of particular interest is the single-question river-sampling approach, as the data collected for this study presents an attempt to field a multi-item scale with such a sampling method. each dataset consists of the same psychometric measures for two of the big-5 personality traits, which are expected to perform independently of sample composition. to assess the similarity of the three datasets we compare their correlation matrices, apply linear and non-linear dimension reduction techniques, and analyze the distance between the datasets. our results show that there are important limitations when implementing a multi-item scale via a single-question river sample. we find that, while the correlation between our data sets is similar, the samples are composed of persons with different personality traits.} {big-5,non-linear dimension reduction,non-probability sample,river sample,web survey research} {big-5,non-linear dimension reduction,non-probability sample,river sample,web survey research}', 'river sampling – a fishing expedition: a non-probability case study {the ease with which large amounts of data can be collected via the internet has led to a renewed interest in the use of non-probability samples. to that end, this paper performs a case study, comparing two non-probability datasets – one based on a river-sampling approach, one drawn from an online-access panel – to a reference probability sample. of particular interest is the single-question river-sampling approach, as the data collected for this study presents an attempt to field a multi-item scale with such a sampling method. each dataset consists of the same psychometric measures for two of the big-5 personality traits, which are expected to perform independently of sample composition. to assess the similarity of the three datasets we compare their correlation matrices, apply linear and non-linear dimension reduction techniques, and analyze the distance between the datasets. our results show that there are important limitations when implementing a multi-item scale via a single-question river sample. we find that, while the correlation between our data sets is similar, the samples are composed of persons with different personality traits.} {big-5,non-linear dimension reduction,non-probability sample,river sample,web survey research} {big-5,non-linear dimension reduction,non-probability sample,river sample,web survey research}']"
2,36,2_covid 19 pandemic_trust_cohort_invariance,"['covid 19 pandemic', 'trust', 'cohort', 'invariance', 'social science']","['a dataset on survey designs and quality of social and behavioral science surveys during the covid-19 pandemic {in the social and behavioral sciences, surveys are frequently used to collect data. during the covid-19 pandemic, surveys provided political actors and public health professionals with timely insights on the attitudes and behaviors of the general population. these insights were key in guiding actions to fight the pandemic. however, the data quality of these surveys remains unclear because systematic knowledge about how the survey data were collected during the covid-19 pandemic is lacking. this is unfortunate, since decades of survey research have shown that survey design impacts data. our survey data collection and the covid-19 pandemic (sdccp) project deals with this research gap. we collected rich metadata on survey design for 717 social and behavioral science surveys carried out in germany during the first two years of the covid-19 pandemic. in this data descriptor, we present a unique resource for a systematic assessment of the survey data collection practices and quality of surveys conducted in germany during the covid-19 pandemic.}', 'a dataset on survey designs and quality of social and behavioral science surveys during the covid-19 pandemic {in the social and behavioral sciences, surveys are frequently used to collect data. during the covid-19 pandemic, surveys provided political actors and public health professionals with timely insights on the attitudes and behaviors of the general population. these insights were key in guiding actions to fight the pandemic. however, the data quality of these surveys remains unclear because systematic knowledge about how the survey data were collected during the covid-19 pandemic is lacking. this is unfortunate, since decades of survey research have shown that survey design impacts data. our survey data collection and the covid-19 pandemic (sdccp) project deals with this research gap. we collected rich metadata on survey design for 717 social and behavioral science surveys carried out in germany during the first two years of the covid-19 pandemic. in this data descriptor, we present a unique resource for a systematic assessment of the survey data collection practices and quality of surveys conducted in germany during the covid-19 pandemic.}', 'a dataset on survey designs and quality of social and behavioral science surveys during the covid-19 pandemic {in the social and behavioral sciences, surveys are frequently used to collect data. during the covid-19 pandemic, surveys provided political actors and public health professionals with timely insights on the attitudes and behaviors of the general population. these insights were key in guiding actions to fight the pandemic. however, the data quality of these surveys remains unclear because systematic knowledge about how the survey data were collected during the covid-19 pandemic is lacking. this is unfortunate, since decades of survey research have shown that survey design impacts data. our survey data collection and the covid-19 pandemic (sdccp) project deals with this research gap. we collected rich metadata on survey design for 717 social and behavioral science surveys carried out in germany during the first two years of the covid-19 pandemic. in this data descriptor, we present a unique resource for a systematic assessment of the survey data collection practices and quality of surveys conducted in germany during the covid-19 pandemic.}']"
3,35,3_social media_texts_uncertainty_scientific publications,"['social media', 'texts', 'uncertainty', 'scientific publications', 'access']","['disambiguation of implicit scientific references on x {scientific discourse on the social web has been shown to compromise the accuracy of scientific findings. complex scientific claims are uttered in the form of short snippets with ""implicit references"" (seen as references to scientific publications where the urls to the actual studies are never cited). this has led to uninformed online scientific debates on topics such as health pandemics or climate. to enhance social media content, we introduce in this paper the novel task of disambiguation of implicit scientific references, where the goal is to retrieve the original scientific publications implicitly referred to by social media users. we contribute the first formalization, ground-truth corpus, and baselines for the task. with this work, we aim at shaping an understanding of implicit references on social media, and at laying a foundation for developing and evaluating methods for the disambiguation of implicit references.} {dataset annotation,information retrieval,scientific references} {dataset annotation,information retrieval,scientific references}', 'disambiguation of implicit scientific references on x {scientific discourse on the social web has been shown to compromise the accuracy of scientific findings. complex scientific claims are uttered in the form of short snippets with ""implicit references"" (seen as references to scientific publications where the urls to the actual studies are never cited). this has led to uninformed online scientific debates on topics such as health pandemics or climate. to enhance social media content, we introduce in this paper the novel task of disambiguation of implicit scientific references, where the goal is to retrieve the original scientific publications implicitly referred to by social media users. we contribute the first formalization, ground-truth corpus, and baselines for the task. with this work, we aim at shaping an understanding of implicit references on social media, and at laying a foundation for developing and evaluating methods for the disambiguation of implicit references.} {dataset annotation,information retrieval,scientific references} {dataset annotation,information retrieval,scientific references}', 'disambiguation of implicit scientific references on x {scientific discourse on the social web has been shown to compromise the accuracy of scientific findings. complex scientific claims are uttered in the form of short snippets with ""implicit references"" (seen as references to scientific publications where the urls to the actual studies are never cited). this has led to uninformed online scientific debates on topics such as health pandemics or climate. to enhance social media content, we introduce in this paper the novel task of disambiguation of implicit scientific references, where the goal is to retrieve the original scientific publications implicitly referred to by social media users. we contribute the first formalization, ground-truth corpus, and baselines for the task. with this work, we aim at shaping an understanding of implicit references on social media, and at laying a foundation for developing and evaluating methods for the disambiguation of implicit references.} {dataset annotation,information retrieval,scientific references} {dataset annotation,information retrieval,scientific references}']"
4,34,4_extraction_knowledge graph_language models llms_named entity recognition,"['extraction', 'knowledge graph', 'language models llms', 'named entity recognition', 'performance']","['decoding prompt syntax: analysing its impact on knowledge retrieval in large language models {large language models (llms), with their advanced architectures and training on massive language datasets, contain unexplored knowledge. one method to infer this knowledge is through the use of cloze-style prompts. typically, these prompts are manually designed because the phrasing of these prompts impacts the knowledge retrieval performance, even if the llm encodes the desired information. in this paper, we study the impact of prompt syntax on the knowledge retrieval capacity of llms. we use a template-based approach to paraphrase simple prompts into prompts with a more complex grammatical structure. we then analyse the llm performance for these structurally different but semantically equivalent prompts. our study reveals that simple prompts work better than complex forms of sentences. the performance across the syntactical variations for simple relations (1:1) remains best, with a marginal decrease across different typologies. these results reinforce that simple prompt structures are more effective for knowledge retrieval in llms and motivate future research into the impact of prompt syntax on various tasks.} {bert,knowledge retrieval,large language models,syntax aware prompt} {bert,knowledge retrieval,large language models,syntax aware prompt}', 'enhancing software-related information extraction via single-choice question answering with large language models {this paper describes our participation in the shared task on software mentions disambiguation (somd), with a focus on improving relation extraction in scholarly texts through generative large language models (llms) using single-choice question-answering. the methodology prioritises the use of in-context learning capabilities of llms to extract software-related entities and their descriptive attributes, such as distributive information. our approach uses retrieval-augmented generation (rag) techniques and llms for named entity recognition (ner) and attributive ner to identify relationships between extracted software entities, providing a structured solution for analysing software citations in academic literature. the paper provides a detailed description of our approach, demonstrating how using llms in a single-choice qa paradigm can greatly enhance ie methodologies. our participation in the somd shared task highlights the importance of precise software citation practices and showcases our system’s ability to overcome the challenges of disambiguating and extracting relationships between software mentions. this sets the groundwork for future research and development in this field.} {generative large language models,information extraction,named entity recognition,relation extraction,retrieval-augmented generation,single-choice question answering,software citation,software mentions disambiguation task} {generative large language models,information extraction,named entity recognition,relation extraction,retrieval-augmented generation,single-choice question answering,software citation,software mentions disambiguation task}', 'enhancing software-related information extraction via single-choice question answering with large language models {this paper describes our participation in the shared task on software mentions disambiguation (somd), with a focus on improving relation extraction in scholarly texts through generative large language models (llms) using single-choice question-answering. the methodology prioritises the use of in-context learning capabilities of llms to extract software-related entities and their descriptive attributes, such as distributive information. our approach uses retrieval-augmented generation (rag) techniques and llms for named entity recognition (ner) and attributive ner to identify relationships between extracted software entities, providing a structured solution for analysing software citations in academic literature. the paper provides a detailed description of our approach, demonstrating how using llms in a single-choice qa paradigm can greatly enhance ie methodologies. our participation in the somd shared task highlights the importance of precise software citation practices and showcases our system’s ability to overcome the challenges of disambiguating and extracting relationships between software mentions. this sets the groundwork for future research and development in this field.} {generative large language models,information extraction,named entity recognition,relation extraction,retrieval-augmented generation,single-choice question answering,software citation,software mentions disambiguation task} {generative large language models,information extraction,named entity recognition,relation extraction,retrieval-augmented generation,single-choice question answering,software citation,software mentions disambiguation task}']"
5,33,5_populist_party_voting behavior_right wing,"['populist', 'party', 'voting behavior', 'right wing', 'personality traits']","['left behind in a public services wasteland? on the accessibility of public services and political trust {public discourse and scholars alike argue that the spatial divide in voting behavior and attitudes is rooted in geographic inequalities that serve as breeding grounds for political discontent. in previous studies, scholars have mainly focused on the economic conditions to analyze how place-based context influences the voting behavior of citizens. however, this focus on voting behavior and a small set of contextual variables do not allow us to draw direct conclusions as to how, and which, place-based factors relate to discontent on the attitudinal level. i argue that the accessibility of public service infrastructure specifically serves as a low-intensity information cue for citizens to evaluate the political performance of modern welfare states. these evaluations complement objective economic perceptions and are part of the performance-trust link. hence, citizens should trust the government less if public services are not provided or only hard to access. i test this relationship for the german case by spatially linking the addresses of survey respondents with the location of public service facilities and collective municipallevel data. the resulting unique data set allows to explore the relationship between the accessibility of public service facilities and political trust as well as their temporal development. results of multilevel analyses indicate that shorter distances to train stations are associated with increased trust in the government, but all other results, such as the change in service provision, remain inconclusive. the findings implicate that a long-term lack of public services contributes to geographically polarized discontent in germany.}', 'left behind in a public services wasteland? on the accessibility of public services and political trust {public discourse and scholars alike argue that the spatial divide in voting behavior and attitudes is rooted in geographic inequalities that serve as breeding grounds for political discontent. in previous studies, scholars have mainly focused on the economic conditions to analyze how place-based context influences the voting behavior of citizens. however, this focus on voting behavior and a small set of contextual variables do not allow us to draw direct conclusions as to how, and which, place-based factors relate to discontent on the attitudinal level. i argue that the accessibility of public service infrastructure specifically serves as a low-intensity information cue for citizens to evaluate the political performance of modern welfare states. these evaluations complement objective economic perceptions and are part of the performance-trust link. hence, citizens should trust the government less if public services are not provided or only hard to access. i test this relationship for the german case by spatially linking the addresses of survey respondents with the location of public service facilities and collective municipallevel data. the resulting unique data set allows to explore the relationship between the accessibility of public service facilities and political trust as well as their temporal development. results of multilevel analyses indicate that shorter distances to train stations are associated with increased trust in the government, but all other results, such as the change in service provision, remain inconclusive. the findings implicate that a long-term lack of public services contributes to geographically polarized discontent in germany.}', 'left behind in a public services wasteland? on the accessibility of public services and political trust {public discourse and scholars alike argue that the spatial divide in voting behavior and attitudes is rooted in geographic inequalities that serve as breeding grounds for political discontent. in previous studies, scholars have mainly focused on the economic conditions to analyze how place-based context influences the voting behavior of citizens. however, this focus on voting behavior and a small set of contextual variables do not allow us to draw direct conclusions as to how, and which, place-based factors relate to discontent on the attitudinal level. i argue that the accessibility of public service infrastructure specifically serves as a low-intensity information cue for citizens to evaluate the political performance of modern welfare states. these evaluations complement objective economic perceptions and are part of the performance-trust link. hence, citizens should trust the government less if public services are not provided or only hard to access. i test this relationship for the german case by spatially linking the addresses of survey respondents with the location of public service facilities and collective municipallevel data. the resulting unique data set allows to explore the relationship between the accessibility of public service facilities and political trust as well as their temporal development. results of multilevel analyses indicate that shorter distances to train stations are associated with increased trust in the government, but all other results, such as the change in service provision, remain inconclusive. the findings implicate that a long-term lack of public services contributes to geographically polarized discontent in germany.}']"
6,32,6_similarity_open science_computational social science_package,"['similarity', 'open science', 'computational social science', 'package', 'training']","['computational reproducibility in computational social science {open science practices have been widely discussed and have been implemented with varying success in different disciplines. we argue that computational-x disciplines such as computational social science, are also susceptible to the symptoms of the crises, but in terms of reproducibility. we expand the binary definition of reproducibility into a tier system which allows increasing levels of reproducibility based on external verifiability to counteract the practice of open-washing. we provide solutions for barriers in computational social science that hinder researchers from obtaining the highest level of reproducibility, including the use of alternate data sources and considering reproducibility proactively.} {computational social science,open science,replicability crisis,reproducibility} {computational social science,open science,replicability crisis,reproducibility}', 'computational reproducibility in computational social science {open science practices have been widely discussed and have been implemented with varying success in different disciplines. we argue that computational-x disciplines such as computational social science, are also susceptible to the symptoms of the crises, but in terms of reproducibility. we expand the binary definition of reproducibility into a tier system which allows increasing levels of reproducibility based on external verifiability to counteract the practice of open-washing. we provide solutions for barriers in computational social science that hinder researchers from obtaining the highest level of reproducibility, including the use of alternate data sources and considering reproducibility proactively.} {computational social science,open science,replicability crisis,reproducibility} {computational social science,open science,replicability crisis,reproducibility}', 'computational reproducibility in computational social science {open science practices have been widely discussed and have been implemented with varying success in different disciplines. we argue that computational-x disciplines such as computational social science, are also susceptible to the symptoms of the crises, but in terms of reproducibility. we expand the binary definition of reproducibility into a tier system which allows increasing levels of reproducibility based on external verifiability to counteract the practice of open-washing. we provide solutions for barriers in computational social science that hinder researchers from obtaining the highest level of reproducibility, including the use of alternate data sources and considering reproducibility proactively.} {computational social science,open science,replicability crisis,reproducibility} {computational social science,open science,replicability crisis,reproducibility}']"
7,29,7_graph_networks_label_consistency,"['graph', 'networks', 'label', 'consistency', 'family']","['exploring rich structure information for aspect-based sentiment classification {graph convolutional network (gcn) for aspect-based sentiment classification has attracted a lot of attention recently due to their promising performance in handling complex structure information. however, previous methods based on gcn focused mainly on examining the structure of syntactic dependency relationships, which were subject to the noise and sparsity problem. furthermore, these methods tend to focus on one kind of structural information (namely syntactic dependency) while ignoring many other kinds of rich structures between words. to tackle these problems, we propose a novel gcn based model, named structure-enhanced dual-channel graph convolutional network (sedc-gcn). specifically, we first exploit the rich structure information by constructing a text sequence graph and an enhanced dependency graph, then design a dual-channel graph encoder to model the structure information from the two graphs. after that, we propose two kinds of aspect-specific attention, i.e., aspect-specific semantic attention and aspect-specific structure attention, to learn sentence representation from two different perspectives, i.e., the semantic perspective based on the text encoder, and the structure perspective based on the dual-channel graph encoder. finally, we merge the sentence representations from the above two perspectives and obtain the final sentence representation. we experimentally validate our proposed model sedc-gcn by comparing with seven strong baseline methods. in terms of the metric accuracy, sedc-gcn achieves performance gains of 74.42%, 77.74%, 83.30%, 81.73% and 90.75% on twitter, laptop, rest14, rest15, and rest16, respectively, which are 0.35%, 4.22%, 1.62%, 0.70% and 2.01% better than the best performing baseline bigcn. similar performance improvements are also observed in terms of the metric macro-averaged f1 score. the ablation study further demonstrates the effectiveness of each component of sedc-gcn.} {aspect-based sentiment classification,attention mechanism,graph convolutional networks,sentiment analysis} {aspect-based sentiment classification,attention mechanism,graph convolutional networks,sentiment analysis}', 'exploring rich structure information for aspect-based sentiment classification {graph convolutional network (gcn) for aspect-based sentiment classification has attracted a lot of attention recently due to their promising performance in handling complex structure information. however, previous methods based on gcn focused mainly on examining the structure of syntactic dependency relationships, which were subject to the noise and sparsity problem. furthermore, these methods tend to focus on one kind of structural information (namely syntactic dependency) while ignoring many other kinds of rich structures between words. to tackle these problems, we propose a novel gcn based model, named structure-enhanced dual-channel graph convolutional network (sedc-gcn). specifically, we first exploit the rich structure information by constructing a text sequence graph and an enhanced dependency graph, then design a dual-channel graph encoder to model the structure information from the two graphs. after that, we propose two kinds of aspect-specific attention, i.e., aspect-specific semantic attention and aspect-specific structure attention, to learn sentence representation from two different perspectives, i.e., the semantic perspective based on the text encoder, and the structure perspective based on the dual-channel graph encoder. finally, we merge the sentence representations from the above two perspectives and obtain the final sentence representation. we experimentally validate our proposed model sedc-gcn by comparing with seven strong baseline methods. in terms of the metric accuracy, sedc-gcn achieves performance gains of 74.42%, 77.74%, 83.30%, 81.73% and 90.75% on twitter, laptop, rest14, rest15, and rest16, respectively, which are 0.35%, 4.22%, 1.62%, 0.70% and 2.01% better than the best performing baseline bigcn. similar performance improvements are also observed in terms of the metric macro-averaged f1 score. the ablation study further demonstrates the effectiveness of each component of sedc-gcn.} {aspect-based sentiment classification,attention mechanism,graph convolutional networks,sentiment analysis} {aspect-based sentiment classification,attention mechanism,graph convolutional networks,sentiment analysis}', 'exploring rich structure information for aspect-based sentiment classification {graph convolutional network (gcn) for aspect-based sentiment classification has attracted a lot of attention recently due to their promising performance in handling complex structure information. however, previous methods based on gcn focused mainly on examining the structure of syntactic dependency relationships, which were subject to the noise and sparsity problem. furthermore, these methods tend to focus on one kind of structural information (namely syntactic dependency) while ignoring many other kinds of rich structures between words. to tackle these problems, we propose a novel gcn based model, named structure-enhanced dual-channel graph convolutional network (sedc-gcn). specifically, we first exploit the rich structure information by constructing a text sequence graph and an enhanced dependency graph, then design a dual-channel graph encoder to model the structure information from the two graphs. after that, we propose two kinds of aspect-specific attention, i.e., aspect-specific semantic attention and aspect-specific structure attention, to learn sentence representation from two different perspectives, i.e., the semantic perspective based on the text encoder, and the structure perspective based on the dual-channel graph encoder. finally, we merge the sentence representations from the above two perspectives and obtain the final sentence representation. we experimentally validate our proposed model sedc-gcn by comparing with seven strong baseline methods. in terms of the metric accuracy, sedc-gcn achieves performance gains of 74.42%, 77.74%, 83.30%, 81.73% and 90.75% on twitter, laptop, rest14, rest15, and rest16, respectively, which are 0.35%, 4.22%, 1.62%, 0.70% and 2.01% better than the best performing baseline bigcn. similar performance improvements are also observed in terms of the metric macro-averaged f1 score. the ablation study further demonstrates the effectiveness of each component of sedc-gcn.} {aspect-based sentiment classification,attention mechanism,graph convolutional networks,sentiment analysis} {aspect-based sentiment classification,attention mechanism,graph convolutional networks,sentiment analysis}']"
8,28,8_uncertainty_adaptation_artificial intelligence_german language,"['uncertainty', 'adaptation', 'artificial intelligence', 'german language', 'comparability']","[""measuring six facets of curiosity in germany and the uk: a german-language adaptation of the 5dcr and its comparability with the english-language source version {the five-dimensional curiosity-scale revised (5dcr) by kashdan et al. (2020) is the most comprehensive curiosity inventory available to date. 5dcr measures six facets of curiosity with four items each. here, we present a german-language adaptation of the 5dcr and comprehensively validate this adaptation in a diverse sample of adults from germany (n = 486). moreover, we provide new evidence on the original english-language 5dcr in a parallel sample from the uk (n = 483). in both countries, we investigate the six facets' reliability, factorial validity, and convergent and discriminant validity with a large set of individual-differences constructs. in addition, we analyze the measurement invariance of the curiosity facets across the uk and germany and across socio-demographic subgroups defined by age, sex, and education. findings demonstrate that the new german-language adaptation of 5dcr and its english-language source version show psychometric properties similar to the original studies by kashdan et al. (2020) in the united states. all six curiosity facets reach at least partial scalar invariance across cultures, sex, education, and mostly also across age groups. the findings support the six-faceted theory of curiosity and show that 5dcr allows for a valid assessment of curiosity across cultures.}"", ""measuring six facets of curiosity in germany and the uk: a german-language adaptation of the 5dcr and its comparability with the english-language source version {the five-dimensional curiosity-scale revised (5dcr) by kashdan et al. (2020) is the most comprehensive curiosity inventory available to date. 5dcr measures six facets of curiosity with four items each. here, we present a german-language adaptation of the 5dcr and comprehensively validate this adaptation in a diverse sample of adults from germany (n = 486). moreover, we provide new evidence on the original english-language 5dcr in a parallel sample from the uk (n = 483). in both countries, we investigate the six facets' reliability, factorial validity, and convergent and discriminant validity with a large set of individual-differences constructs. in addition, we analyze the measurement invariance of the curiosity facets across the uk and germany and across socio-demographic subgroups defined by age, sex, and education. findings demonstrate that the new german-language adaptation of 5dcr and its english-language source version show psychometric properties similar to the original studies by kashdan et al. (2020) in the united states. all six curiosity facets reach at least partial scalar invariance across cultures, sex, education, and mostly also across age groups. the findings support the six-faceted theory of curiosity and show that 5dcr allows for a valid assessment of curiosity across cultures.}"", ""measuring six facets of curiosity in germany and the uk: a german-language adaptation of the 5dcr and its comparability with the english-language source version {the five-dimensional curiosity-scale revised (5dcr) by kashdan et al. (2020) is the most comprehensive curiosity inventory available to date. 5dcr measures six facets of curiosity with four items each. here, we present a german-language adaptation of the 5dcr and comprehensively validate this adaptation in a diverse sample of adults from germany (n = 486). moreover, we provide new evidence on the original english-language 5dcr in a parallel sample from the uk (n = 483). in both countries, we investigate the six facets' reliability, factorial validity, and convergent and discriminant validity with a large set of individual-differences constructs. in addition, we analyze the measurement invariance of the curiosity facets across the uk and germany and across socio-demographic subgroups defined by age, sex, and education. findings demonstrate that the new german-language adaptation of 5dcr and its english-language source version show psychometric properties similar to the original studies by kashdan et al. (2020) in the united states. all six curiosity facets reach at least partial scalar invariance across cultures, sex, education, and mostly also across age groups. the findings support the six-faceted theory of curiosity and show that 5dcr allows for a valid assessment of curiosity across cultures.}""]"
9,28,9_facebook_inclusion_social sciences_control,"['facebook', 'inclusion', 'social sciences', 'control', 'measurement invariance']","['assessing data quality in the age of digital social research: a systematic review {while survey data has long been the focus of quantitative social science analyses, observational and content data, although long-established, are gaining renewed attention; especially when this type of data is obtained by and for observing digital content and behavior. today, digital technologies allow social scientists to track “everyday behavior” and to extract opinions from public discussions on online platforms. these new types of digital traces of human behavior, together with computational methods for analyzing them, have opened new avenues for analyzing, understanding, and addressing social science research questions. however, even the most innovative and extensive amounts of data are hollow if they are not of high quality. but what does data quality mean for modern social science data? to investigate this rather abstract question the present study focuses on four objectives. first, we provide researchers with a decision tree to identify appropriate data quality frameworks for a given use case. second, we determine which data types and quality dimensions are already addressed in the existing frameworks. third, we identify gaps with respect to different data types and data quality dimensions within the existing frameworks which need to be filled. and fourth, we provide a detailed literature overview for the intrinsic and extrinsic perspectives on data quality. by conducting a systematic literature review based on text mining methods, we identified and reviewed 58 data quality frameworks. in our decision tree, the three categories, namely, data type, the perspective it takes, and its level of granularity, help researchers to find appropriate data quality frameworks. we, furthermore, discovered gaps in the available frameworks with respect to visual and especially linked data and point out in our review that even famous frameworks might miss important aspects. the article ends with a critical discussion of the current state of the literature and potential future research avenues.} {data quality,data quality concepts,data quality frameworks,measurement,representation,systematic review} {data quality,data quality concepts,data quality frameworks,measurement,representation,systematic review}', 'assessing data quality in the age of digital social research: a systematic review {while survey data has long been the focus of quantitative social science analyses, observational and content data, although long-established, are gaining renewed attention; especially when this type of data is obtained by and for observing digital content and behavior. today, digital technologies allow social scientists to track “everyday behavior” and to extract opinions from public discussions on online platforms. these new types of digital traces of human behavior, together with computational methods for analyzing them, have opened new avenues for analyzing, understanding, and addressing social science research questions. however, even the most innovative and extensive amounts of data are hollow if they are not of high quality. but what does data quality mean for modern social science data? to investigate this rather abstract question the present study focuses on four objectives. first, we provide researchers with a decision tree to identify appropriate data quality frameworks for a given use case. second, we determine which data types and quality dimensions are already addressed in the existing frameworks. third, we identify gaps with respect to different data types and data quality dimensions within the existing frameworks which need to be filled. and fourth, we provide a detailed literature overview for the intrinsic and extrinsic perspectives on data quality. by conducting a systematic literature review based on text mining methods, we identified and reviewed 58 data quality frameworks. in our decision tree, the three categories, namely, data type, the perspective it takes, and its level of granularity, help researchers to find appropriate data quality frameworks. we, furthermore, discovered gaps in the available frameworks with respect to visual and especially linked data and point out in our review that even famous frameworks might miss important aspects. the article ends with a critical discussion of the current state of the literature and potential future research avenues.} {data quality,data quality concepts,data quality frameworks,measurement,representation,systematic review} {data quality,data quality concepts,data quality frameworks,measurement,representation,systematic review}', 'assessing data quality in the age of digital social research: a systematic review {while survey data has long been the focus of quantitative social science analyses, observational and content data, although long-established, are gaining renewed attention; especially when this type of data is obtained by and for observing digital content and behavior. today, digital technologies allow social scientists to track “everyday behavior” and to extract opinions from public discussions on online platforms. these new types of digital traces of human behavior, together with computational methods for analyzing them, have opened new avenues for analyzing, understanding, and addressing social science research questions. however, even the most innovative and extensive amounts of data are hollow if they are not of high quality. but what does data quality mean for modern social science data? to investigate this rather abstract question the present study focuses on four objectives. first, we provide researchers with a decision tree to identify appropriate data quality frameworks for a given use case. second, we determine which data types and quality dimensions are already addressed in the existing frameworks. third, we identify gaps with respect to different data types and data quality dimensions within the existing frameworks which need to be filled. and fourth, we provide a detailed literature overview for the intrinsic and extrinsic perspectives on data quality. by conducting a systematic literature review based on text mining methods, we identified and reviewed 58 data quality frameworks. in our decision tree, the three categories, namely, data type, the perspective it takes, and its level of granularity, help researchers to find appropriate data quality frameworks. we, furthermore, discovered gaps in the available frameworks with respect to visual and especially linked data and point out in our review that even famous frameworks might miss important aspects. the article ends with a critical discussion of the current state of the literature and potential future research avenues.} {data quality,data quality concepts,data quality frameworks,measurement,representation,systematic review} {data quality,data quality concepts,data quality frameworks,measurement,representation,systematic review}']"
10,28,10_knowledge graphs_semantic web_machine learning_pipeline,"['knowledge graphs', 'semantic web', 'machine learning', 'pipeline', 'argument mining']","['sime4kg: distributed and explainable multi-modal semantic similarity estimation for knowledge graphs {in recent years, exciting sources of data have been modeled as knowledge graphs (kgs). this modeling represents both structural relationships and the entity-specific multi-modal data in kgs. in various data analytics pipelines and machine learning (ml), the task of semantic similarity estimation plays a significant role. assigning similarity values to entity pairs is needed in recommendation systems, clustering, classification, entity matching/disambiguation and many others. efficient and scalable frameworks are needed to handle the quadratic complexity of all-pair semantic similarity on big data kgs. moreover, heterogeneous kgs demand multi-modal semantic similarity estimation to cover the versatile contents like categorical relations between classes or their attribute literals like strings, timestamps or numeric data. in this paper, we propose the sime4kg framework as a resource providing generic open-source modules that perform semantic similarity estimation in multi-modal kgs. to justify the computational costs of similarity estimation, the sime4kg generates reproducible, reusable and explainable results. the pipeline results are a native semantic rdf kg, including the experiment results, hyper-parameter setup and explanation of the results, like the most influential features. for fast and scalable execution in memory, we implemented the distributed approach using apache spark. the entire development of this framework is integrated into the holistic distributed semantic analytics stack (sansa).} {apache spark,distributed computing,explainable artificial intelligence,knowledge graphs,machine learning,rdf,scalable semantic processing,semantic similarity} {apache spark,distributed computing,explainable artificial intelligence,knowledge graphs,machine learning,rdf,scalable semantic processing,semantic similarity}', 'sime4kg: distributed and explainable multi-modal semantic similarity estimation for knowledge graphs {in recent years, exciting sources of data have been modeled as knowledge graphs (kgs). this modeling represents both structural relationships and the entity-specific multi-modal data in kgs. in various data analytics pipelines and machine learning (ml), the task of semantic similarity estimation plays a significant role. assigning similarity values to entity pairs is needed in recommendation systems, clustering, classification, entity matching/disambiguation and many others. efficient and scalable frameworks are needed to handle the quadratic complexity of all-pair semantic similarity on big data kgs. moreover, heterogeneous kgs demand multi-modal semantic similarity estimation to cover the versatile contents like categorical relations between classes or their attribute literals like strings, timestamps or numeric data. in this paper, we propose the sime4kg framework as a resource providing generic open-source modules that perform semantic similarity estimation in multi-modal kgs. to justify the computational costs of similarity estimation, the sime4kg generates reproducible, reusable and explainable results. the pipeline results are a native semantic rdf kg, including the experiment results, hyper-parameter setup and explanation of the results, like the most influential features. for fast and scalable execution in memory, we implemented the distributed approach using apache spark. the entire development of this framework is integrated into the holistic distributed semantic analytics stack (sansa).} {apache spark,distributed computing,explainable artificial intelligence,knowledge graphs,machine learning,rdf,scalable semantic processing,semantic similarity} {apache spark,distributed computing,explainable artificial intelligence,knowledge graphs,machine learning,rdf,scalable semantic processing,semantic similarity}', 'sime4kg: distributed and explainable multi-modal semantic similarity estimation for knowledge graphs {in recent years, exciting sources of data have been modeled as knowledge graphs (kgs). this modeling represents both structural relationships and the entity-specific multi-modal data in kgs. in various data analytics pipelines and machine learning (ml), the task of semantic similarity estimation plays a significant role. assigning similarity values to entity pairs is needed in recommendation systems, clustering, classification, entity matching/disambiguation and many others. efficient and scalable frameworks are needed to handle the quadratic complexity of all-pair semantic similarity on big data kgs. moreover, heterogeneous kgs demand multi-modal semantic similarity estimation to cover the versatile contents like categorical relations between classes or their attribute literals like strings, timestamps or numeric data. in this paper, we propose the sime4kg framework as a resource providing generic open-source modules that perform semantic similarity estimation in multi-modal kgs. to justify the computational costs of similarity estimation, the sime4kg generates reproducible, reusable and explainable results. the pipeline results are a native semantic rdf kg, including the experiment results, hyper-parameter setup and explanation of the results, like the most influential features. for fast and scalable execution in memory, we implemented the distributed approach using apache spark. the entire development of this framework is integrated into the holistic distributed semantic analytics stack (sansa).} {apache spark,distributed computing,explainable artificial intelligence,knowledge graphs,machine learning,rdf,scalable semantic processing,semantic similarity} {apache spark,distributed computing,explainable artificial intelligence,knowledge graphs,machine learning,rdf,scalable semantic processing,semantic similarity}']"
11,28,11_parental_germany_changing_socioeconomic,"['parental', 'germany', 'changing', 'socioeconomic', 'gaps']","['intergenerational family life courses and wealth accumulation in norway {while prior research has widely acknowledged the consequences of specific family transitions (e.g., parental death, parenthood, grandparenthood) for individual wealth holdings, the interplay of multiple family transitions and positions occurring at different life stages and in various orderings has received little attention. this is despite the fact that these transitions and positions most likely jointly shape wealth accumulation, both in the shorter and longer run. we apply (1) sequence analysis to identify typical family life course clusters defined by the timing of the death of the parent generation, the timing of the transition into parenthood, and grandparenthood and (2) regression analysis to describe how the accumulation of wealth between ages 40 and 64 differs by family life course cluster. using norwegian register data of individuals born in 1953 (n = 47,945), we identified six clusters of family trajectories ranging from childless individuals to individuals who were sandwiched between their parents, children, and grandchildren because of relatively early (grand)parenthood and late parental death. individuals experiencing patterns with a later transition into (grand)parenthood occupied stable and high wealth positions over time. individuals without children exhibited a steady increase in their wealth position. additionally, experiencing parental death later in life was associated with increasing wealth, whereas early parental death was not. these results held net of gender and education. pronounced and even increasing wealth differences over the life course seem to be associated with the interplay of multiple family transitions.} {administrative register data,intergenerational transmission,sequence analysis,wealth inequality} {administrative register data,intergenerational transmission,sequence analysis,wealth inequality}', 'intergenerational family life courses and wealth accumulation in norway {while prior research has widely acknowledged the consequences of specific family transitions (e.g., parental death, parenthood, grandparenthood) for individual wealth holdings, the interplay of multiple family transitions and positions occurring at different life stages and in various orderings has received little attention. this is despite the fact that these transitions and positions most likely jointly shape wealth accumulation, both in the shorter and longer run. we apply (1) sequence analysis to identify typical family life course clusters defined by the timing of the death of the parent generation, the timing of the transition into parenthood, and grandparenthood and (2) regression analysis to describe how the accumulation of wealth between ages 40 and 64 differs by family life course cluster. using norwegian register data of individuals born in 1953 (n = 47,945), we identified six clusters of family trajectories ranging from childless individuals to individuals who were sandwiched between their parents, children, and grandchildren because of relatively early (grand)parenthood and late parental death. individuals experiencing patterns with a later transition into (grand)parenthood occupied stable and high wealth positions over time. individuals without children exhibited a steady increase in their wealth position. additionally, experiencing parental death later in life was associated with increasing wealth, whereas early parental death was not. these results held net of gender and education. pronounced and even increasing wealth differences over the life course seem to be associated with the interplay of multiple family transitions.} {administrative register data,intergenerational transmission,sequence analysis,wealth inequality} {administrative register data,intergenerational transmission,sequence analysis,wealth inequality}', 'intergenerational family life courses and wealth accumulation in norway {while prior research has widely acknowledged the consequences of specific family transitions (e.g., parental death, parenthood, grandparenthood) for individual wealth holdings, the interplay of multiple family transitions and positions occurring at different life stages and in various orderings has received little attention. this is despite the fact that these transitions and positions most likely jointly shape wealth accumulation, both in the shorter and longer run. we apply (1) sequence analysis to identify typical family life course clusters defined by the timing of the death of the parent generation, the timing of the transition into parenthood, and grandparenthood and (2) regression analysis to describe how the accumulation of wealth between ages 40 and 64 differs by family life course cluster. using norwegian register data of individuals born in 1953 (n = 47,945), we identified six clusters of family trajectories ranging from childless individuals to individuals who were sandwiched between their parents, children, and grandchildren because of relatively early (grand)parenthood and late parental death. individuals experiencing patterns with a later transition into (grand)parenthood occupied stable and high wealth positions over time. individuals without children exhibited a steady increase in their wealth position. additionally, experiencing parental death later in life was associated with increasing wealth, whereas early parental death was not. these results held net of gender and education. pronounced and even increasing wealth differences over the life course seem to be associated with the interplay of multiple family transitions.} {administrative register data,intergenerational transmission,sequence analysis,wealth inequality} {administrative register data,intergenerational transmission,sequence analysis,wealth inequality}']"
12,28,12_personality_vocational_matching_outcomes,"['personality', 'vocational', 'matching', 'outcomes', 'state']","['do social engagement skills exist and matter beyond personality facet traits and vocational interests? a generalization study across six countries {social engagement skills as capacities for active interpersonal engagement are thought to conceptually differ from behavioral and motivational tendencies and to predict learning and life outcomes. we tested these assumptions on the distinct nature and relevance of social engagement skills. quota-representative self-reports from 6987 adults in six countries showed strong relations of social engagement skills with personality facets and weaker with vocational interests. partially supporting their distinctiveness, social engagement skills were not fully reducible to those correlates. skills predicted self-reported learning, quality-of-life, and job outcomes, but offered little incremental validity beyond personality and interests. results largely generalized across countries. yet, the complex interplay between social engagement skills, individual differences, and outcomes demonstrated cross-country variations, suggesting sensitivity to sociocontextual factors. we conclude that while social engagement skills conceptually differ from personality and interests and in themselves predict life success, they add limited empirical value beyond these constructs, at least for self-reports. educational relevance statement: social engagement skills are the capacities to actively engage with others. it is thought that these capacities differ from other person characteristics (e.g., behavioral or motivational tendencies), and that this distinction matters for explaining life success. our study showed that while self-reported social engagement skills shared similarities with other person characteristics, they still had unique aspects. moreover, social engagement skills mattered, such that more skilled adults reported higher quality-of-life, but not necessarily better learning. however, social engagement skills did not provide much extra insight into life success beyond what was already known from other person characteristics. other than the remaining results, these complex relations between social engagement skills, person characteristics, and life success largely varied across countries. the results highlight the importance of assessing social skills in a situation-specific manner, which will be imperative for targeted educational practices in the future. moreover, our study focused on adults, limiting applicability to youth, but results suggest that intervention efforts targeting social engagement skills may probably yield more interpersonal than academic benefits. finally, when designing or adapting complex educational programs, practitioners should consider sociocontextual factors.} {cross-national data,individual differences,learning,life outcomes,social-emotional skills} {cross-national data,individual differences,learning,life outcomes,social-emotional skills}', 'do social engagement skills exist and matter beyond personality facet traits and vocational interests? a generalization study across six countries {social engagement skills as capacities for active interpersonal engagement are thought to conceptually differ from behavioral and motivational tendencies and to predict learning and life outcomes. we tested these assumptions on the distinct nature and relevance of social engagement skills. quota-representative self-reports from 6987 adults in six countries showed strong relations of social engagement skills with personality facets and weaker with vocational interests. partially supporting their distinctiveness, social engagement skills were not fully reducible to those correlates. skills predicted self-reported learning, quality-of-life, and job outcomes, but offered little incremental validity beyond personality and interests. results largely generalized across countries. yet, the complex interplay between social engagement skills, individual differences, and outcomes demonstrated cross-country variations, suggesting sensitivity to sociocontextual factors. we conclude that while social engagement skills conceptually differ from personality and interests and in themselves predict life success, they add limited empirical value beyond these constructs, at least for self-reports. educational relevance statement: social engagement skills are the capacities to actively engage with others. it is thought that these capacities differ from other person characteristics (e.g., behavioral or motivational tendencies), and that this distinction matters for explaining life success. our study showed that while self-reported social engagement skills shared similarities with other person characteristics, they still had unique aspects. moreover, social engagement skills mattered, such that more skilled adults reported higher quality-of-life, but not necessarily better learning. however, social engagement skills did not provide much extra insight into life success beyond what was already known from other person characteristics. other than the remaining results, these complex relations between social engagement skills, person characteristics, and life success largely varied across countries. the results highlight the importance of assessing social skills in a situation-specific manner, which will be imperative for targeted educational practices in the future. moreover, our study focused on adults, limiting applicability to youth, but results suggest that intervention efforts targeting social engagement skills may probably yield more interpersonal than academic benefits. finally, when designing or adapting complex educational programs, practitioners should consider sociocontextual factors.} {cross-national data,individual differences,learning,life outcomes,social-emotional skills} {cross-national data,individual differences,learning,life outcomes,social-emotional skills}', 'do social engagement skills exist and matter beyond personality facet traits and vocational interests? a generalization study across six countries {social engagement skills as capacities for active interpersonal engagement are thought to conceptually differ from behavioral and motivational tendencies and to predict learning and life outcomes. we tested these assumptions on the distinct nature and relevance of social engagement skills. quota-representative self-reports from 6987 adults in six countries showed strong relations of social engagement skills with personality facets and weaker with vocational interests. partially supporting their distinctiveness, social engagement skills were not fully reducible to those correlates. skills predicted self-reported learning, quality-of-life, and job outcomes, but offered little incremental validity beyond personality and interests. results largely generalized across countries. yet, the complex interplay between social engagement skills, individual differences, and outcomes demonstrated cross-country variations, suggesting sensitivity to sociocontextual factors. we conclude that while social engagement skills conceptually differ from personality and interests and in themselves predict life success, they add limited empirical value beyond these constructs, at least for self-reports. educational relevance statement: social engagement skills are the capacities to actively engage with others. it is thought that these capacities differ from other person characteristics (e.g., behavioral or motivational tendencies), and that this distinction matters for explaining life success. our study showed that while self-reported social engagement skills shared similarities with other person characteristics, they still had unique aspects. moreover, social engagement skills mattered, such that more skilled adults reported higher quality-of-life, but not necessarily better learning. however, social engagement skills did not provide much extra insight into life success beyond what was already known from other person characteristics. other than the remaining results, these complex relations between social engagement skills, person characteristics, and life success largely varied across countries. the results highlight the importance of assessing social skills in a situation-specific manner, which will be imperative for targeted educational practices in the future. moreover, our study focused on adults, limiting applicability to youth, but results suggest that intervention efforts targeting social engagement skills may probably yield more interpersonal than academic benefits. finally, when designing or adapting complex educational programs, practitioners should consider sociocontextual factors.} {cross-national data,individual differences,learning,life outcomes,social-emotional skills} {cross-national data,individual differences,learning,life outcomes,social-emotional skills}']"
13,23,13_cognitive_loss_labels_pretesting,"['cognitive', 'loss', 'labels', 'pretesting', 'coding']","['innovating web probing: comparing written and oral answers to open-ended probing questions in a smartphone survey {cognitive interviewing in the form of probing is key for developing methodologically sound survey questions. for a long time, probing was tied to the laboratory setting, making it difficult to achieve large sample sizes and creating a time-intensive undertaking for both researchers and participants. web surveys paved the way for administering probing questions over the internet in a time- and cost-efficient manner. in so-called web probing studies, respondents first answer a question and then they receive one or more open-ended questions about their response process, with requests for written answers. however, participants frequently provide very short or no answers at all to open-ended questions, in part because answering questions in writing is tedious. this is especially the case when the web survey is completed via a smartphone with a virtual on-screen keypad that shrinks the viewing space. in this study, we examine whether the problem of short and uninterpretable answers in web probing studies can be mitigated by asking respondents to complete the web survey on a smartphone and to record their answers via the built-in microphone. we conducted an experiment in a smartphone survey (n= 1,001), randomizing respondents to different communication modes (written or oral) for answering two comprehension probes about two questions on national identity and citizenship. the results indicate that probes with requests for oral answers produce four to five times more nonresponse than their written counterparts. however, oral answers contain about three times as many words, include about 0.3 more themes (first probing question only), and the proportion of clearly interpretable answers is about 6 percentage points higher (for the first probing question only). nonetheless, both communication modes result in similar themes mentioned by respondents.} {cognitive pretesting,experiment,smartphone survey,survey question design,voice recording,web probing} {cognitive pretesting,experiment,smartphone survey,survey question design,voice recording,web probing}', 'the effects of open-ended probes on closed survey questions in web surveys {probes are follow-ups to survey questions used to gain insights on respondents’ understanding of and responses to these questions. they are usually administered as open-ended questions, primarily in the context of questionnaire pretesting. due to the decreased cost of data collection for open-ended questions in web surveys, researchers have argued for embedding more open-ended probes in large-scale web surveys. however, there are concerns that this may cause reactivity and impact survey data. the study presents a randomized experiment in which identical survey questions were run with and without open-ended probes. embedding open-ended probes resulted in higher levels of survey break off, as well as increased backtracking and answer changes to previous questions. in most cases, there was no impact of open-ended probes on the cognitive processing of and response to survey questions. implications for embedding open-ended probes into web surveys are discussed.} {cognitive pretest,open-ended questions,reactivity,response quality,web probing} {cognitive pretest,open-ended questions,reactivity,response quality,web probing}', 'the effects of open-ended probes on closed survey questions in web surveys {probes are follow-ups to survey questions used to gain insights on respondents’ understanding of and responses to these questions. they are usually administered as open-ended questions, primarily in the context of questionnaire pretesting. due to the decreased cost of data collection for open-ended questions in web surveys, researchers have argued for embedding more open-ended probes in large-scale web surveys. however, there are concerns that this may cause reactivity and impact survey data. the study presents a randomized experiment in which identical survey questions were run with and without open-ended probes. embedding open-ended probes resulted in higher levels of survey break off, as well as increased backtracking and answer changes to previous questions. in most cases, there was no impact of open-ended probes on the cognitive processing of and response to survey questions. implications for embedding open-ended probes into web surveys are discussed.} {cognitive pretest,open-ended questions,reactivity,response quality,web probing} {cognitive pretest,open-ended questions,reactivity,response quality,web probing}']"
14,23,14_recruitment_online panel_probability based_mixed mode,"['recruitment', 'online panel', 'probability based', 'mixed mode', 'mail']","['enhancing participation in probability-based online panels: two incentive experiments and their effects on response and panel recruitment {this article investigates how mail-based online panel recruitment can be facilitated through incentives. the analysis relies on two incentive experiments and their effects on panel recruitment, and the intermediate participation in the recruitment survey. the experiments were implemented in the context of the german emigration and remigration panel study and encompass two samples of randomly sampled persons. tested incentives include a conditional lottery, conditional monetary incentives, and the combination of unconditional money-in-hand with conditional monetary incentives. for an encompassing evaluation of the link between incentives and panel recruitment, the article further assesses the incentives’ implications for demographic composition and panel recruitment unit costs. multivariate analysis indicates that low combined incentives (€5/€5) or, where unconditional disbursement is unfeasible, high conditional incentives (€20) are most effective in enhancing panel participation. in terms of demographic bias, low combined incentives (€5/€5) and €10 conditional incentives are the favored options. the budget options from the perspective of panel recruitment include the lottery and the €10 conditional incentive which break-even at net sample sizes of 1000.} {combined incentives,demographic bias,generous lottery,incentive experiment,mobile populations,money-in-hand,prepaid cash,probability-based panel recruitment,recruitment costs} {combined incentives,demographic bias,generous lottery,incentive experiment,mobile populations,money-in-hand,prepaid cash,probability-based panel recruitment,recruitment costs}', 'enhancing participation in probability-based online panels: two incentive experiments and their effects on response and panel recruitment {this article investigates how mail-based online panel recruitment can be facilitated through incentives. the analysis relies on two incentive experiments and their effects on panel recruitment, and the intermediate participation in the recruitment survey. the experiments were implemented in the context of the german emigration and remigration panel study and encompass two samples of randomly sampled persons. tested incentives include a conditional lottery, conditional monetary incentives, and the combination of unconditional money-in-hand with conditional monetary incentives. for an encompassing evaluation of the link between incentives and panel recruitment, the article further assesses the incentives’ implications for demographic composition and panel recruitment unit costs. multivariate analysis indicates that low combined incentives (€5/€5) or, where unconditional disbursement is unfeasible, high conditional incentives (€20) are most effective in enhancing panel participation. in terms of demographic bias, low combined incentives (€5/€5) and €10 conditional incentives are the favored options. the budget options from the perspective of panel recruitment include the lottery and the €10 conditional incentive which break-even at net sample sizes of 1000.} {combined incentives,demographic bias,generous lottery,incentive experiment,mobile populations,money-in-hand,prepaid cash,probability-based panel recruitment,recruitment costs} {combined incentives,demographic bias,generous lottery,incentive experiment,mobile populations,money-in-hand,prepaid cash,probability-based panel recruitment,recruitment costs}', 'enhancing participation in probability-based online panels: two incentive experiments and their effects on response and panel recruitment {this article investigates how mail-based online panel recruitment can be facilitated through incentives. the analysis relies on two incentive experiments and their effects on panel recruitment, and the intermediate participation in the recruitment survey. the experiments were implemented in the context of the german emigration and remigration panel study and encompass two samples of randomly sampled persons. tested incentives include a conditional lottery, conditional monetary incentives, and the combination of unconditional money-in-hand with conditional monetary incentives. for an encompassing evaluation of the link between incentives and panel recruitment, the article further assesses the incentives’ implications for demographic composition and panel recruitment unit costs. multivariate analysis indicates that low combined incentives (€5/€5) or, where unconditional disbursement is unfeasible, high conditional incentives (€20) are most effective in enhancing panel participation. in terms of demographic bias, low combined incentives (€5/€5) and €10 conditional incentives are the favored options. the budget options from the perspective of panel recruitment include the lottery and the €10 conditional incentive which break-even at net sample sizes of 1000.} {combined incentives,demographic bias,generous lottery,incentive experiment,mobile populations,money-in-hand,prepaid cash,probability-based panel recruitment,recruitment costs} {combined incentives,demographic bias,generous lottery,incentive experiment,mobile populations,money-in-hand,prepaid cash,probability-based panel recruitment,recruitment costs}']"
15,22,15_public opinion_driven_ads_privacy,"['public opinion', 'driven', 'ads', 'privacy', 'cross national']","['the role of public opinion research in the democratic process: insights from politicians, journalists, and the general public {this study reveals the existence of a paradox in how the public views polling within the democratic process. specifically, even though the public believes that it can influence policymaking, it considers public opinion polls not as useful as other, less representative forms of public input, such as comments at town hall meetings. analyzing data from multiple surveys conducted in the united states of america, we find no evidence for the democratic representation hypothesis with respect to polling. comparisons across stakeholders (public, journalists, and politicians) demonstrate that general perceptions of inputs into the democratic process are similar, which confirms the citizen-elite congruence hypothesis. however, unlike members of the public, experts are more likely to believe that public opinion polls are the optimal method by which the public can successfully inform policymaking, a finding consistent with the legitimization hypothesis. with respect to perceptions of politicians, we found substantial differences regarding party registration with democrats and independents favoring public opinion polling and republicans preferring alternative methods (e.g., town hall meetings) of informing policymakers.} {democratic representation,media,policymaking,politicians,preferences,public opinion research,public policy,survey value} {democratic representation,media,policymaking,politicians,preferences,public opinion research,public policy,survey value}', 'the role of public opinion research in the democratic process: insights from politicians, journalists, and the general public {this study reveals the existence of a paradox in how the public views polling within the democratic process. specifically, even though the public believes that it can influence policymaking, it considers public opinion polls not as useful as other, less representative forms of public input, such as comments at town hall meetings. analyzing data from multiple surveys conducted in the united states of america, we find no evidence for the democratic representation hypothesis with respect to polling. comparisons across stakeholders (public, journalists, and politicians) demonstrate that general perceptions of inputs into the democratic process are similar, which confirms the citizen-elite congruence hypothesis. however, unlike members of the public, experts are more likely to believe that public opinion polls are the optimal method by which the public can successfully inform policymaking, a finding consistent with the legitimization hypothesis. with respect to perceptions of politicians, we found substantial differences regarding party registration with democrats and independents favoring public opinion polling and republicans preferring alternative methods (e.g., town hall meetings) of informing policymakers.} {democratic representation,media,policymaking,politicians,preferences,public opinion research,public policy,survey value} {democratic representation,media,policymaking,politicians,preferences,public opinion research,public policy,survey value}', 'the role of public opinion research in the democratic process: insights from politicians, journalists, and the general public {this study reveals the existence of a paradox in how the public views polling within the democratic process. specifically, even though the public believes that it can influence policymaking, it considers public opinion polls not as useful as other, less representative forms of public input, such as comments at town hall meetings. analyzing data from multiple surveys conducted in the united states of america, we find no evidence for the democratic representation hypothesis with respect to polling. comparisons across stakeholders (public, journalists, and politicians) demonstrate that general perceptions of inputs into the democratic process are similar, which confirms the citizen-elite congruence hypothesis. however, unlike members of the public, experts are more likely to believe that public opinion polls are the optimal method by which the public can successfully inform policymaking, a finding consistent with the legitimization hypothesis. with respect to perceptions of politicians, we found substantial differences regarding party registration with democrats and independents favoring public opinion polling and republicans preferring alternative methods (e.g., town hall meetings) of informing policymakers.} {democratic representation,media,policymaking,politicians,preferences,public opinion research,public policy,survey value} {democratic representation,media,policymaking,politicians,preferences,public opinion research,public policy,survey value}']"
16,22,16_security_misinformation_social media_climate,"['security', 'misinformation', 'social media', 'climate', 'political parties']","[""non-news websites expose people to more political content than news websites: evidence from browsing data in three countries {most scholars focus on the prevalence and democratic effects of (partisan) news exposure. this focus misses large parts of online activities of a majority of politically disinterested citizens. although political content also appears outside of news outlets and may profoundly shape public opinion, its prevalence and effects are under-studied at scale. this project combines three-wave panel survey data from three countries (total n = 7,266) with online behavioral data from the same participants (over 106m visits). we create a multi-lingual classifier to identify political content both in news and outside (e.g. in shopping or entertainment sites). we find that news consumption is infrequent: just 3.4% of participants’ online browsing comprised visits to news sites. only between 14% (nl) and 36% (us) of these visits were to news about politics. the overwhelming majority of participants' visits were to non-news sites. although only 1.6\\% of those visits related to politics, in absolute terms, citizens encounter politics more frequently outside of news than within news. out of every 10 visits to political content, 3.4 come from news and 6.6 from non-news sites. furthermore, exposure to political content outside news domains had the same–and in some cases stronger - associations with key democratic attitudes and behaviors as news exposure. these findings offer a comprehensive analysis of the online political (not solely news) ecosystem and demonstrate the importance of assessing the prevalence and effects of political content in non-news sources.} {computational social science,information consumption,misinformation,news exposure,polarization,political content,political knowledge} {computational social science,information consumption,misinformation,news exposure,polarization,political content,political knowledge}"", 'social media posts as source for political news coverage inside and outside election campaigns: examining effects on deliberative news media quality {journalists increasingly cite and/or embed social media posts in news articles. while social media posts have been found to be of little deliberative quality, we do not know whether this also affects the deliberative quality of the news. against the background of a hybrid media system and deliberative news media standards, we answer this research question with a content analysis of news articles including or not including posts from x (formerly twitter) in the twelve widest-reaching german news websites prior and after the german general election 2021. we were particularly interested in the differences inside and outside election campaigns as the interdependence of the mass media and the political sphere is particularly pronounced during campaign periods. results show that posts are more often cited and/or embedded in news articles inside than outside election campaigns. articles including posts feature a greater number of actors but are not more diverse as mainly actors from the political center are referenced. moreover, articles with posts are associated with a higher position responsiveness but on the other hand a decreased civility of the represented political discourse. this pattern only emerged inside but not outside campaign periods. these findings add to our understanding of contemporary hybrid media systems and the nature of political journalism during contentious political periods.} {content analysis,deliberation,hybrid media system,media quality,political journalism} {content analysis,deliberation,hybrid media system,media quality,political journalism}', 'social media posts as source for political news coverage inside and outside election campaigns: examining effects on deliberative news media quality {journalists increasingly cite and/or embed social media posts in news articles. while social media posts have been found to be of little deliberative quality, we do not know whether this also affects the deliberative quality of the news. against the background of a hybrid media system and deliberative news media standards, we answer this research question with a content analysis of news articles including or not including posts from x (formerly twitter) in the twelve widest-reaching german news websites prior and after the german general election 2021. we were particularly interested in the differences inside and outside election campaigns as the interdependence of the mass media and the political sphere is particularly pronounced during campaign periods. results show that posts are more often cited and/or embedded in news articles inside than outside election campaigns. articles including posts feature a greater number of actors but are not more diverse as mainly actors from the political center are referenced. moreover, articles with posts are associated with a higher position responsiveness but on the other hand a decreased civility of the represented political discourse. this pattern only emerged inside but not outside campaign periods. these findings add to our understanding of contemporary hybrid media systems and the nature of political journalism during contentious political periods.} {content analysis,deliberation,hybrid media system,media quality,political journalism} {content analysis,deliberation,hybrid media system,media quality,political journalism}']"
17,21,17_literacy_adolescents_inequalities_emotional,"['literacy', 'adolescents', 'inequalities', 'emotional', 'categories']","[""inequalities in adolescents' social, emotional, and behavioral skills: differences across social categories and their intersections {this paper explores inequalities in adolescents' social, emotional, and behavioral skills. we examine whether skills vary by gender, parental education, immigrant background, school track—and their intersections. in two samples of german adolescents (age 14–20y; n = 3162), we fielded the behavioral, emotional, and self-regulatory skills inventory (bessi), enabling a fine-grained assessment of 32 skill facets from five domains. analyses revealed skill advantages for youth whose parents completed academic education and youth without immigrant background across most skills. gender and school track had more varied effects mostly in favor of girls and adolescents attending academic tracks. inequalities tended to be most pronounced for innovation skills. intersectional analyses suggested that skill inequalities across intersectional strata (i.e., combinations of social categories) arose primarily from main effects of social categories, rather than intersectional interactions. we conclude that inequalities in seb skills are small but systematic and unfold primarily as main effects. educational relevance and implications: our research explored whether adolescents differ in their levels of social, emotional, and behavioral (seb) skills depending on their gender, immigrant background, parents' education, and school track. we found that parents' education and immigrant background were the factors generating most consistent inequalities in seb skills, with skill advantages for adolescents whose parents completed academic education and autochthonous adolescents across all skill domains and most skill facets, especially in innovation skills (e.g., information processing, creative skill, abstract thinking skill). gender differences and, to a lesser extent, differences by school track were also present but more varied in terms of which subgroup showed skill advantages: on most skills, girls showed skill advantages over boys (with the exception of emotional resilience), as did and adolescents attending an academic school track over those attending a vocational track. we further established that inequalities in seb skills mainly arise from the simple effects of the social categories, rather than through complex interactions among their intersections. our findings constitute a step towards helping educators, policymakers, and researchers identify groups of adolescents who are at a heightened need of support in developing seb skills. this may help in developing targeted interventions and policies aimed at fostering equitable development of seb skills in the future. addressing these inequalities is essential for reducing educational gaps and enhancing the academic success and wellbeing of all students.} {bessi,inequality,intersectionality,maihda,non-cognitive skills} {bessi,inequality,intersectionality,maihda,non-cognitive skills}"", ""inequalities in adolescents' social, emotional, and behavioral skills: differences across social categories and their intersections {this paper explores inequalities in adolescents' social, emotional, and behavioral skills. we examine whether skills vary by gender, parental education, immigrant background, school track—and their intersections. in two samples of german adolescents (age 14–20y; n = 3162), we fielded the behavioral, emotional, and self-regulatory skills inventory (bessi), enabling a fine-grained assessment of 32 skill facets from five domains. analyses revealed skill advantages for youth whose parents completed academic education and youth without immigrant background across most skills. gender and school track had more varied effects mostly in favor of girls and adolescents attending academic tracks. inequalities tended to be most pronounced for innovation skills. intersectional analyses suggested that skill inequalities across intersectional strata (i.e., combinations of social categories) arose primarily from main effects of social categories, rather than intersectional interactions. we conclude that inequalities in seb skills are small but systematic and unfold primarily as main effects. educational relevance and implications: our research explored whether adolescents differ in their levels of social, emotional, and behavioral (seb) skills depending on their gender, immigrant background, parents' education, and school track. we found that parents' education and immigrant background were the factors generating most consistent inequalities in seb skills, with skill advantages for adolescents whose parents completed academic education and autochthonous adolescents across all skill domains and most skill facets, especially in innovation skills (e.g., information processing, creative skill, abstract thinking skill). gender differences and, to a lesser extent, differences by school track were also present but more varied in terms of which subgroup showed skill advantages: on most skills, girls showed skill advantages over boys (with the exception of emotional resilience), as did and adolescents attending an academic school track over those attending a vocational track. we further established that inequalities in seb skills mainly arise from the simple effects of the social categories, rather than through complex interactions among their intersections. our findings constitute a step towards helping educators, policymakers, and researchers identify groups of adolescents who are at a heightened need of support in developing seb skills. this may help in developing targeted interventions and policies aimed at fostering equitable development of seb skills in the future. addressing these inequalities is essential for reducing educational gaps and enhancing the academic success and wellbeing of all students.} {bessi,inequality,intersectionality,maihda,non-cognitive skills} {bessi,inequality,intersectionality,maihda,non-cognitive skills}"", ""inequalities in adolescents' social, emotional, and behavioral skills: differences across social categories and their intersections {this paper explores inequalities in adolescents' social, emotional, and behavioral skills. we examine whether skills vary by gender, parental education, immigrant background, school track—and their intersections. in two samples of german adolescents (age 14–20y; n = 3162), we fielded the behavioral, emotional, and self-regulatory skills inventory (bessi), enabling a fine-grained assessment of 32 skill facets from five domains. analyses revealed skill advantages for youth whose parents completed academic education and youth without immigrant background across most skills. gender and school track had more varied effects mostly in favor of girls and adolescents attending academic tracks. inequalities tended to be most pronounced for innovation skills. intersectional analyses suggested that skill inequalities across intersectional strata (i.e., combinations of social categories) arose primarily from main effects of social categories, rather than intersectional interactions. we conclude that inequalities in seb skills are small but systematic and unfold primarily as main effects. educational relevance and implications: our research explored whether adolescents differ in their levels of social, emotional, and behavioral (seb) skills depending on their gender, immigrant background, parents' education, and school track. we found that parents' education and immigrant background were the factors generating most consistent inequalities in seb skills, with skill advantages for adolescents whose parents completed academic education and autochthonous adolescents across all skill domains and most skill facets, especially in innovation skills (e.g., information processing, creative skill, abstract thinking skill). gender differences and, to a lesser extent, differences by school track were also present but more varied in terms of which subgroup showed skill advantages: on most skills, girls showed skill advantages over boys (with the exception of emotional resilience), as did and adolescents attending an academic school track over those attending a vocational track. we further established that inequalities in seb skills mainly arise from the simple effects of the social categories, rather than through complex interactions among their intersections. our findings constitute a step towards helping educators, policymakers, and researchers identify groups of adolescents who are at a heightened need of support in developing seb skills. this may help in developing targeted interventions and policies aimed at fostering equitable development of seb skills in the future. addressing these inequalities is essential for reducing educational gaps and enhancing the academic success and wellbeing of all students.} {bessi,inequality,intersectionality,maihda,non-cognitive skills} {bessi,inequality,intersectionality,maihda,non-cognitive skills}""]"
18,20,18_acceptance_cohorts_younger_cross cultural,"['acceptance', 'cohorts', 'younger', 'cross cultural', 'german']","['enhancing autonomous vehicle acceptance with age and education sensitive simulation interventions: an experimental trial {the familiarity principle posits that acceptance increases with exposure, which has previously been shown with in vivo and simulated experiences with connected and autonomous vehicles (cavs). we investigate the impact of a simulated video-based first-person drive on cav acceptance, as well as the impact of information customization, with a particular focus on acceptance by older individuals and those with lower education. findings from an online experiment with n = 799 german residents reveal that the simulated experience improved acceptance across response variables such as intention to use and ease of use, particularly among older individuals. however, the opportunity to customize navigation information decreased acceptance of older individuals and those with university degrees and increased acceptance for younger individuals and those with lower educational levels.} {acceptance,autonomous vehicles,education,older adults,self-driving cars,simulated autonomous driving,transportation} {acceptance,autonomous vehicles,education,older adults,self-driving cars,simulated autonomous driving,transportation}', 'enhancing autonomous vehicle acceptance with age and education sensitive simulation interventions: an experimental trial {the familiarity principle posits that acceptance increases with exposure, which has previously been shown with in vivo and simulated experiences with connected and autonomous vehicles (cavs). we investigate the impact of a simulated video-based first-person drive on cav acceptance, as well as the impact of information customization, with a particular focus on acceptance by older individuals and those with lower education. findings from an online experiment with n = 799 german residents reveal that the simulated experience improved acceptance across response variables such as intention to use and ease of use, particularly among older individuals. however, the opportunity to customize navigation information decreased acceptance of older individuals and those with university degrees and increased acceptance for younger individuals and those with lower educational levels.} {acceptance,autonomous vehicles,education,older adults,self-driving cars,simulated autonomous driving,transportation} {acceptance,autonomous vehicles,education,older adults,self-driving cars,simulated autonomous driving,transportation}', 'enhancing autonomous vehicle acceptance with age and education sensitive simulation interventions: an experimental trial {the familiarity principle posits that acceptance increases with exposure, which has previously been shown with in vivo and simulated experiences with connected and autonomous vehicles (cavs). we investigate the impact of a simulated video-based first-person drive on cav acceptance, as well as the impact of information customization, with a particular focus on acceptance by older individuals and those with lower education. findings from an online experiment with n = 799 german residents reveal that the simulated experience improved acceptance across response variables such as intention to use and ease of use, particularly among older individuals. however, the opportunity to customize navigation information decreased acceptance of older individuals and those with university degrees and increased acceptance for younger individuals and those with lower educational levels.} {acceptance,autonomous vehicles,education,older adults,self-driving cars,simulated autonomous driving,transportation} {acceptance,autonomous vehicles,education,older adults,self-driving cars,simulated autonomous driving,transportation}']"
19,20,19_digital trace_sharing_disciplinary_vignette experiment,"['digital trace', 'sharing', 'disciplinary', 'vignette experiment', 'linkage']","['sharing digital trace data: researchers’ challenges and needs {over the past decade, research has made rapid progress in the collection and analysis of digital trace data. however, when it comes to sharing data, researchers still face major barriers that often limit or prevent the reproducibility of research results and the reuse of data. against this backdrop, we identify three broader categories of user challenges, namely researchers’ capacities & incentives, legal & ethical challenges, and technical hurdles. we describe in detail the problems researchers face in each category and why these often prevent researchers from sharing data, thus limiting both the reproducibility of research outputs and data reuse in other research projects. we conclude each category with specific needs of researchers for sharing digital trace data and making it reusable for others. these are intended to provide researchers as well as research institutes and repositories with approaches to improve the situation of data sharing.} {data access,data archives,digital trace data,open science,reproducibility,research data management} {data access,data archives,digital trace data,open science,reproducibility,research data management}', 'sharing digital trace data: researchers’ challenges and needs {over the past decade, research has made rapid progress in the collection and analysis of digital trace data. however, when it comes to sharing data, researchers still face major barriers that often limit or prevent the reproducibility of research results and the reuse of data. against this backdrop, we identify three broader categories of user challenges, namely researchers’ capacities & incentives, legal & ethical challenges, and technical hurdles. we describe in detail the problems researchers face in each category and why these often prevent researchers from sharing data, thus limiting both the reproducibility of research outputs and data reuse in other research projects. we conclude each category with specific needs of researchers for sharing digital trace data and making it reusable for others. these are intended to provide researchers as well as research institutes and repositories with approaches to improve the situation of data sharing.} {data access,data archives,digital trace data,open science,reproducibility,research data management} {data access,data archives,digital trace data,open science,reproducibility,research data management}', 'sharing digital trace data: researchers’ challenges and needs {over the past decade, research has made rapid progress in the collection and analysis of digital trace data. however, when it comes to sharing data, researchers still face major barriers that often limit or prevent the reproducibility of research results and the reuse of data. against this backdrop, we identify three broader categories of user challenges, namely researchers’ capacities & incentives, legal & ethical challenges, and technical hurdles. we describe in detail the problems researchers face in each category and why these often prevent researchers from sharing data, thus limiting both the reproducibility of research outputs and data reuse in other research projects. we conclude each category with specific needs of researchers for sharing digital trace data and making it reusable for others. these are intended to provide researchers as well as research institutes and repositories with approaches to improve the situation of data sharing.} {data access,data archives,digital trace data,open science,reproducibility,research data management} {data access,data archives,digital trace data,open science,reproducibility,research data management}']"
20,19,20_risk_children_19 pandemic_life satisfaction,"['risk', 'children', '19 pandemic', 'life satisfaction', 'immigration']","[""covid-19 labor market protection and support for the welfare state: job retention versus job loss in four european countries {the covid-19 pandemic presents a natural setting to study how labor market protection policies may influence welfare attitudes because while lockdowns and economic recession threatened millions of jobs, job retention schemes shielded many workers from unemployment. we investigate support for unemployment protection and the unemployed among people active in the labor force and participating in the mannheim corona study in germany, coping with covid-19 in france, response in italy, and the british social attitudes survey in great britain. two-way fixed effects analyses on the german data show that there was a general increase in respondents' support over the onset of the pandemic and that while job loss significantly boosted support, there was little attitudinal difference between those who experienced job retention and those who continued working. we confirm these patterns with cross-sectional analyses in all four countries, providing comparative insight into attitudes across the largest european economies. unemployment is materially similar to job retention, but because it is associated with higher support, we contend that nonmaterial factors such as risk perceptions may be consequential in influencing preference changes when individuals lose their jobs.} {comparative analysis,covid-19,job retention,longitudinal analysis,unemployment,welfare attitudes} {comparative analysis,covid-19,job retention,longitudinal analysis,unemployment,welfare attitudes}"", ""covid-19 labor market protection and support for the welfare state: job retention versus job loss in four european countries {the covid-19 pandemic presents a natural setting to study how labor market protection policies may influence welfare attitudes because while lockdowns and economic recession threatened millions of jobs, job retention schemes shielded many workers from unemployment. we investigate support for unemployment protection and the unemployed among people active in the labor force and participating in the mannheim corona study in germany, coping with covid-19 in france, response in italy, and the british social attitudes survey in great britain. two-way fixed effects analyses on the german data show that there was a general increase in respondents' support over the onset of the pandemic and that while job loss significantly boosted support, there was little attitudinal difference between those who experienced job retention and those who continued working. we confirm these patterns with cross-sectional analyses in all four countries, providing comparative insight into attitudes across the largest european economies. unemployment is materially similar to job retention, but because it is associated with higher support, we contend that nonmaterial factors such as risk perceptions may be consequential in influencing preference changes when individuals lose their jobs.} {comparative analysis,covid-19,job retention,longitudinal analysis,unemployment,welfare attitudes} {comparative analysis,covid-19,job retention,longitudinal analysis,unemployment,welfare attitudes}"", ""covid-19 labor market protection and support for the welfare state: job retention versus job loss in four european countries {the covid-19 pandemic presents a natural setting to study how labor market protection policies may influence welfare attitudes because while lockdowns and economic recession threatened millions of jobs, job retention schemes shielded many workers from unemployment. we investigate support for unemployment protection and the unemployed among people active in the labor force and participating in the mannheim corona study in germany, coping with covid-19 in france, response in italy, and the british social attitudes survey in great britain. two-way fixed effects analyses on the german data show that there was a general increase in respondents' support over the onset of the pandemic and that while job loss significantly boosted support, there was little attitudinal difference between those who experienced job retention and those who continued working. we confirm these patterns with cross-sectional analyses in all four countries, providing comparative insight into attitudes across the largest european economies. unemployment is materially similar to job retention, but because it is associated with higher support, we contend that nonmaterial factors such as risk perceptions may be consequential in influencing preference changes when individuals lose their jobs.} {comparative analysis,covid-19,job retention,longitudinal analysis,unemployment,welfare attitudes} {comparative analysis,covid-19,job retention,longitudinal analysis,unemployment,welfare attitudes}""]"
21,19,21_fact checking_tasks_landscape_online,"['fact checking', 'tasks', 'landscape', 'online', 'classification']","['investigating characteristics, biases and evolution of fact-checked claims on the web {given the recent proliferation of fake news online, fact-checking has emerged as a critical defence against misinformation. several fact-checking organisations are currently employed in the initiative to assess the truthfulness of online claims. verified claims serve as foundational data for various cross-domain research, including fields of social science and natural language processing, where they are used to study misinformation and several downstream tasks such as automated fact-verification. however, these fact-checking websites inherently harbour biases, posing challenges for academic endeavours aiming to discern truth from misinformation. in this study, we aim to explore the evolving landscape of online claims verified by multiple fact-checking organisations and analyse the underlying biases of individual fact-checking websites. leveraging claimskg, the largest available corpus of fact-checked claims, we analyse the temporal evolution of claims, focusing on topics, veracity levels, and entities to offer insights into the complex dimensions of online information. we utilise data and dimensions available from claimskg for our analysis and for dimensions such as topics which are not present in claimskg, we create a topic taxonomy and implement a transformer-based model, for multi-label classification of claims. we also observe how similar claims are co-occurant amongst different websites. our work serves as a standardised framework for categorising claims sourced from diverse fact-checking organisations, laying the foundation for coherent and interpretable fact-checking datasets. the analysis conducted in this work sheds light on the dynamic landscape of online claims verified by several fact-checking organisations and dives into biases and distributions of several fact-checking websites.} {claims analysis,claims classification,fact-checking,knowledge graphs,mis- and disinformation} {claims analysis,claims classification,fact-checking,knowledge graphs,mis- and disinformation}', 'investigating characteristics, biases and evolution of fact-checked claims on the web {given the recent proliferation of fake news online, fact-checking has emerged as a critical defence against misinformation. several fact-checking organisations are currently employed in the initiative to assess the truthfulness of online claims. verified claims serve as foundational data for various cross-domain research, including fields of social science and natural language processing, where they are used to study misinformation and several downstream tasks such as automated fact-verification. however, these fact-checking websites inherently harbour biases, posing challenges for academic endeavours aiming to discern truth from misinformation. in this study, we aim to explore the evolving landscape of online claims verified by multiple fact-checking organisations and analyse the underlying biases of individual fact-checking websites. leveraging claimskg, the largest available corpus of fact-checked claims, we analyse the temporal evolution of claims, focusing on topics, veracity levels, and entities to offer insights into the complex dimensions of online information. we utilise data and dimensions available from claimskg for our analysis and for dimensions such as topics which are not present in claimskg, we create a topic taxonomy and implement a transformer-based model, for multi-label classification of claims. we also observe how similar claims are co-occurant amongst different websites. our work serves as a standardised framework for categorising claims sourced from diverse fact-checking organisations, laying the foundation for coherent and interpretable fact-checking datasets. the analysis conducted in this work sheds light on the dynamic landscape of online claims verified by several fact-checking organisations and dives into biases and distributions of several fact-checking websites.} {claims analysis,claims classification,fact-checking,knowledge graphs,mis- and disinformation} {claims analysis,claims classification,fact-checking,knowledge graphs,mis- and disinformation}', 'investigating characteristics, biases and evolution of fact-checked claims on the web {given the recent proliferation of fake news online, fact-checking has emerged as a critical defence against misinformation. several fact-checking organisations are currently employed in the initiative to assess the truthfulness of online claims. verified claims serve as foundational data for various cross-domain research, including fields of social science and natural language processing, where they are used to study misinformation and several downstream tasks such as automated fact-verification. however, these fact-checking websites inherently harbour biases, posing challenges for academic endeavours aiming to discern truth from misinformation. in this study, we aim to explore the evolving landscape of online claims verified by multiple fact-checking organisations and analyse the underlying biases of individual fact-checking websites. leveraging claimskg, the largest available corpus of fact-checked claims, we analyse the temporal evolution of claims, focusing on topics, veracity levels, and entities to offer insights into the complex dimensions of online information. we utilise data and dimensions available from claimskg for our analysis and for dimensions such as topics which are not present in claimskg, we create a topic taxonomy and implement a transformer-based model, for multi-label classification of claims. we also observe how similar claims are co-occurant amongst different websites. our work serves as a standardised framework for categorising claims sourced from diverse fact-checking organisations, laying the foundation for coherent and interpretable fact-checking datasets. the analysis conducted in this work sheds light on the dynamic landscape of online claims verified by several fact-checking organisations and dives into biases and distributions of several fact-checking websites.} {claims analysis,claims classification,fact-checking,knowledge graphs,mis- and disinformation} {claims analysis,claims classification,fact-checking,knowledge graphs,mis- and disinformation}']"
22,18,22_speech_cohorts_discrimination_computer science,"['speech', 'cohorts', 'discrimination', 'computer science', 'career']","['a multidisciplinary lens of bias in hate speech {hate speech detection systems may exhibit discriminatory behaviours. research in this field has focused primarily on issues of discrimination toward the language use of minoritised communities and non-white aligned english. the interrelated issues of bias, model robustness, and disproportionate harms are weakly addressed by recent evaluation approaches, which capture them only implicitly. in this paper, we recruit a multidisciplinary group of experts to bring closer this divide between fairness and trustworthy model evaluation. specifically, we encourage the experts to discuss not only the technical, but the social, ethical, and legal aspects of this timely issue. the discussion sheds light on critical bias facets that require careful considerations when deploying hate speech detection systems in society. crucially, they bring clarity to different approaches for assessing, becoming aware of bias from a broader perspective, and offer valuable recommendations for future research in this field.} {bias,hate speech,multidisciplinary methods} {bias,hate speech,multidisciplinary methods}', 'a multidisciplinary lens of bias in hate speech {hate speech detection systems may exhibit discriminatory behaviours. research in this field has focused primarily on issues of discrimination toward the language use of minoritised communities and non-white aligned english. the interrelated issues of bias, model robustness, and disproportionate harms are weakly addressed by recent evaluation approaches, which capture them only implicitly. in this paper, we recruit a multidisciplinary group of experts to bring closer this divide between fairness and trustworthy model evaluation. specifically, we encourage the experts to discuss not only the technical, but the social, ethical, and legal aspects of this timely issue. the discussion sheds light on critical bias facets that require careful considerations when deploying hate speech detection systems in society. crucially, they bring clarity to different approaches for assessing, becoming aware of bias from a broader perspective, and offer valuable recommendations for future research in this field.} {bias,hate speech,multidisciplinary methods} {bias,hate speech,multidisciplinary methods}', 'a multidisciplinary lens of bias in hate speech {hate speech detection systems may exhibit discriminatory behaviours. research in this field has focused primarily on issues of discrimination toward the language use of minoritised communities and non-white aligned english. the interrelated issues of bias, model robustness, and disproportionate harms are weakly addressed by recent evaluation approaches, which capture them only implicitly. in this paper, we recruit a multidisciplinary group of experts to bring closer this divide between fairness and trustworthy model evaluation. specifically, we encourage the experts to discuss not only the technical, but the social, ethical, and legal aspects of this timely issue. the discussion sheds light on critical bias facets that require careful considerations when deploying hate speech detection systems in society. crucially, they bring clarity to different approaches for assessing, becoming aware of bias from a broader perspective, and offer valuable recommendations for future research in this field.} {bias,hate speech,multidisciplinary methods} {bias,hate speech,multidisciplinary methods}']"
23,18,23_violence_europe_higher education_inequalities,"['violence', 'europe', 'higher education', 'inequalities', 'women']","['the role of intersectionality and context in measuring gender-based violence in universities and research-performing organizations in europe for the development of inclusive structural interventions {the aim of the article is to discuss how thinking about gender-based violence intersectionally and in context can not only enrich our understanding but also lead to transformative change in organizations. the article argues that to better understand gender-based violence in universities and research institutions, analyses need to be intersectional and contextual. such approaches go beyond binary understandings of gender and narrow legalistic definitions of gender-based violence. the article reflects on how to operationalize this to derive starting points for intersectional categories to consider and contextual factors to measure at micro-, meso-, and macro-levels. it concludes that a multilevel intersectional analysis leads to more nuanced knowledge on experiences of gender-based violence and is, therefore, better equipped to inform the development of measures to eradicate the problem in an inclusive way.} {gender-based violence,intersectionality,research-performing organizations,surveys,theorizing quantitative measurement} {gender-based violence,intersectionality,research-performing organizations,surveys,theorizing quantitative measurement}', 'the role of intersectionality and context in measuring gender-based violence in universities and research-performing organizations in europe for the development of inclusive structural interventions {the aim of the article is to discuss how thinking about gender-based violence intersectionally and in context can not only enrich our understanding but also lead to transformative change in organizations. the article argues that to better understand gender-based violence in universities and research institutions, analyses need to be intersectional and contextual. such approaches go beyond binary understandings of gender and narrow legalistic definitions of gender-based violence. the article reflects on how to operationalize this to derive starting points for intersectional categories to consider and contextual factors to measure at micro-, meso-, and macro-levels. it concludes that a multilevel intersectional analysis leads to more nuanced knowledge on experiences of gender-based violence and is, therefore, better equipped to inform the development of measures to eradicate the problem in an inclusive way.} {gender-based violence,intersectionality,research-performing organizations,surveys,theorizing quantitative measurement} {gender-based violence,intersectionality,research-performing organizations,surveys,theorizing quantitative measurement}', 'the role of intersectionality and context in measuring gender-based violence in universities and research-performing organizations in europe for the development of inclusive structural interventions {the aim of the article is to discuss how thinking about gender-based violence intersectionally and in context can not only enrich our understanding but also lead to transformative change in organizations. the article argues that to better understand gender-based violence in universities and research institutions, analyses need to be intersectional and contextual. such approaches go beyond binary understandings of gender and narrow legalistic definitions of gender-based violence. the article reflects on how to operationalize this to derive starting points for intersectional categories to consider and contextual factors to measure at micro-, meso-, and macro-levels. it concludes that a multilevel intersectional analysis leads to more nuanced knowledge on experiences of gender-based violence and is, therefore, better equipped to inform the development of measures to eradicate the problem in an inclusive way.} {gender-based violence,intersectionality,research-performing organizations,surveys,theorizing quantitative measurement} {gender-based violence,intersectionality,research-performing organizations,surveys,theorizing quantitative measurement}']"
24,18,24_gaps_domain_language models_women,"['gaps', 'domain', 'language models', 'women', 'training']","[""exploring global gender gaps in the blockchain domain: insights from linkedin advertising data {blockchain technology has gained widespread attention through bitcoin, but the blockchain domain is still striving to increase gender diversity and widely assess skills gaps by gender. there is limited awareness of women's participation in blockchain, prompting this study to assess and explore global gender gaps in interests, skills, and professions within the field. by analyzing gender-disaggregated data from linkedin's advertisement platform, we reveal that women are significantly underrepresented in blockchain compared to men, with the gender gap being even more pronounced than in the broader it sector. this study delves into the volume, velocity, variety, veracity, and value that linkedin ad data offers to assess gender gaps in the blockchain domain at a global level.} {gender gaps in the blockchain interests,gender gaps in the blockchain jobs,gender gaps in the blockchain skills,linkedin ad data,mining of social media data} {gender gaps in the blockchain interests,gender gaps in the blockchain jobs,gender gaps in the blockchain skills,linkedin ad data,mining of social media data}"", ""exploring global gender gaps in the blockchain domain: insights from linkedin advertising data {blockchain technology has gained widespread attention through bitcoin, but the blockchain domain is still striving to increase gender diversity and widely assess skills gaps by gender. there is limited awareness of women's participation in blockchain, prompting this study to assess and explore global gender gaps in interests, skills, and professions within the field. by analyzing gender-disaggregated data from linkedin's advertisement platform, we reveal that women are significantly underrepresented in blockchain compared to men, with the gender gap being even more pronounced than in the broader it sector. this study delves into the volume, velocity, variety, veracity, and value that linkedin ad data offers to assess gender gaps in the blockchain domain at a global level.} {gender gaps in the blockchain interests,gender gaps in the blockchain jobs,gender gaps in the blockchain skills,linkedin ad data,mining of social media data} {gender gaps in the blockchain interests,gender gaps in the blockchain jobs,gender gaps in the blockchain skills,linkedin ad data,mining of social media data}"", ""exploring global gender gaps in the blockchain domain: insights from linkedin advertising data {blockchain technology has gained widespread attention through bitcoin, but the blockchain domain is still striving to increase gender diversity and widely assess skills gaps by gender. there is limited awareness of women's participation in blockchain, prompting this study to assess and explore global gender gaps in interests, skills, and professions within the field. by analyzing gender-disaggregated data from linkedin's advertisement platform, we reveal that women are significantly underrepresented in blockchain compared to men, with the gender gap being even more pronounced than in the broader it sector. this study delves into the volume, velocity, variety, veracity, and value that linkedin ad data offers to assess gender gaps in the blockchain domain at a global level.} {gender gaps in the blockchain interests,gender gaps in the blockchain jobs,gender gaps in the blockchain skills,linkedin ad data,mining of social media data} {gender gaps in the blockchain interests,gender gaps in the blockchain jobs,gender gaps in the blockchain skills,linkedin ad data,mining of social media data}""]"
25,18,25_probability based_inclusion_mixed mode panel_waves,"['probability based', 'inclusion', 'mixed mode panel', 'waves', 'levels']","['creating design weights for a panel survey with multiple refreshment samples: a general discussion with an application to a probability-based mixed-mode panel {panel surveys suffer from attrition, where participants drop out over time. to maintain generalizability, refreshment samples are frequently employed, bringing in new individuals, increasing the number of panelists, and balancing sample composition. although refreshment samples offer numerous advantages, the inclusion of new panel members may introduce bias into the analysis if the design weights are not appropriately tailored to these new members and adjusted to align with existing panel members. if not correctly accounted for, their inclusion may bias results. this paper addresses the issue of designing proper weights by applying the multiple-frame weighting approach proposed by kalton and anderson, which is generally used for cross-sectional surveys, to ongoing panel studies with refreshment samples. we demonstrate its application to a synthetic data set and a probability-based mixed-mode panel with an initial sample and two refreshment samples. we compare estimates obtained using multiple-frame weighting with those obtained using unweighted and naively weighted methods (where design weights are used as calculated for the respective samples without adjusting for the fact that some members of the population have a chance of being sampled more than once due to the refreshments). these comparisons showcase the potential for bias introduced by neglecting proper weighting and underscore the importance of both a multiple-frame weighting approach and meticulous sample documentation.} {gesis panel,inclusion probabilities,multiple-frame weighting,panel surveys,refreshment samples} {gesis panel,inclusion probabilities,multiple-frame weighting,panel surveys,refreshment samples}', 'creating design weights for a panel survey with multiple refreshment samples: a general discussion with an application to a probability-based mixed-mode panel {panel surveys suffer from attrition, where participants drop out over time. to maintain generalizability, refreshment samples are frequently employed, bringing in new individuals, increasing the number of panelists, and balancing sample composition. although refreshment samples offer numerous advantages, the inclusion of new panel members may introduce bias into the analysis if the design weights are not appropriately tailored to these new members and adjusted to align with existing panel members. if not correctly accounted for, their inclusion may bias results. this paper addresses the issue of designing proper weights by applying the multiple-frame weighting approach proposed by kalton and anderson, which is generally used for cross-sectional surveys, to ongoing panel studies with refreshment samples. we demonstrate its application to a synthetic data set and a probability-based mixed-mode panel with an initial sample and two refreshment samples. we compare estimates obtained using multiple-frame weighting with those obtained using unweighted and naively weighted methods (where design weights are used as calculated for the respective samples without adjusting for the fact that some members of the population have a chance of being sampled more than once due to the refreshments). these comparisons showcase the potential for bias introduced by neglecting proper weighting and underscore the importance of both a multiple-frame weighting approach and meticulous sample documentation.} {gesis panel,inclusion probabilities,multiple-frame weighting,panel surveys,refreshment samples} {gesis panel,inclusion probabilities,multiple-frame weighting,panel surveys,refreshment samples}', 'creating design weights for a panel survey with multiple refreshment samples: a general discussion with an application to a probability-based mixed-mode panel {panel surveys suffer from attrition, where participants drop out over time. to maintain generalizability, refreshment samples are frequently employed, bringing in new individuals, increasing the number of panelists, and balancing sample composition. although refreshment samples offer numerous advantages, the inclusion of new panel members may introduce bias into the analysis if the design weights are not appropriately tailored to these new members and adjusted to align with existing panel members. if not correctly accounted for, their inclusion may bias results. this paper addresses the issue of designing proper weights by applying the multiple-frame weighting approach proposed by kalton and anderson, which is generally used for cross-sectional surveys, to ongoing panel studies with refreshment samples. we demonstrate its application to a synthetic data set and a probability-based mixed-mode panel with an initial sample and two refreshment samples. we compare estimates obtained using multiple-frame weighting with those obtained using unweighted and naively weighted methods (where design weights are used as calculated for the respective samples without adjusting for the fact that some members of the population have a chance of being sampled more than once due to the refreshments). these comparisons showcase the potential for bias introduced by neglecting proper weighting and underscore the importance of both a multiple-frame weighting approach and meticulous sample documentation.} {gesis panel,inclusion probabilities,multiple-frame weighting,panel surveys,refreshment samples} {gesis panel,inclusion probabilities,multiple-frame weighting,panel surveys,refreshment samples}']"
26,17,26_interventions_recruitment_response behavior_testing,"['interventions', 'recruitment', 'response behavior', 'testing', 'online panel']","['comparing participation motives of professional and non-professional respondents {in times of declining response rates and over-surveying, improving our understanding of why people participate in surveys is more important than ever. previous research showed that online panel participants have intrinsic (e.g., topic interest, altruism) and extrinsic (e.g., incentives) participation reasons. our study expands this research by implementing an experiment using two common forms of survey measurement: ranking and rating. the experiment was fielded in a professional respondents’ sample from a german online panel (n = 407) and in an address-based sample (mail and online) of german non-professional respondents (n = 1,137). besides extrinsic and intrinsic motivations, the experiment included various study design features (i.e., mode, length, data security) and the mood during the time of contact as possible reasons for participation. the results confirm previous findings regarding the motivations of online panelists but also show important differences between professional and non-professional respondents. specifically, the main participation reasons of professionals are topic interest (intrinsic) and incentives (extrinsic), while non-professionals are primarily motivated by intrinsic reasons (topic interest and purpose of study). this notion is also supported by the latent class analyses, which showed that three of the four classes for professional respondents had a high probability of naming incentives as one of their main reasons for survey participation, whereas none of the four non-professional clusters rated incentives highly. the differences between the two samples highlight that professional panel members have different motivation structures than participants in general population surveys. this may undermine generalizability, but it also provides opportunities for targeted recruitment.} {experiment,motivation,professional respondents,ranking vs. rating,survey participation} {experiment,motivation,professional respondents,ranking vs. rating,survey participation}', 'comparing participation motives of professional and non-professional respondents {in times of declining response rates and over-surveying, improving our understanding of why people participate in surveys is more important than ever. previous research showed that online panel participants have intrinsic (e.g., topic interest, altruism) and extrinsic (e.g., incentives) participation reasons. our study expands this research by implementing an experiment using two common forms of survey measurement: ranking and rating. the experiment was fielded in a professional respondents’ sample from a german online panel (n = 407) and in an address-based sample (mail and online) of german non-professional respondents (n = 1,137). besides extrinsic and intrinsic motivations, the experiment included various study design features (i.e., mode, length, data security) and the mood during the time of contact as possible reasons for participation. the results confirm previous findings regarding the motivations of online panelists but also show important differences between professional and non-professional respondents. specifically, the main participation reasons of professionals are topic interest (intrinsic) and incentives (extrinsic), while non-professionals are primarily motivated by intrinsic reasons (topic interest and purpose of study). this notion is also supported by the latent class analyses, which showed that three of the four classes for professional respondents had a high probability of naming incentives as one of their main reasons for survey participation, whereas none of the four non-professional clusters rated incentives highly. the differences between the two samples highlight that professional panel members have different motivation structures than participants in general population surveys. this may undermine generalizability, but it also provides opportunities for targeted recruitment.} {experiment,motivation,professional respondents,ranking vs. rating,survey participation} {experiment,motivation,professional respondents,ranking vs. rating,survey participation}', 'comparing participation motives of professional and non-professional respondents {in times of declining response rates and over-surveying, improving our understanding of why people participate in surveys is more important than ever. previous research showed that online panel participants have intrinsic (e.g., topic interest, altruism) and extrinsic (e.g., incentives) participation reasons. our study expands this research by implementing an experiment using two common forms of survey measurement: ranking and rating. the experiment was fielded in a professional respondents’ sample from a german online panel (n = 407) and in an address-based sample (mail and online) of german non-professional respondents (n = 1,137). besides extrinsic and intrinsic motivations, the experiment included various study design features (i.e., mode, length, data security) and the mood during the time of contact as possible reasons for participation. the results confirm previous findings regarding the motivations of online panelists but also show important differences between professional and non-professional respondents. specifically, the main participation reasons of professionals are topic interest (intrinsic) and incentives (extrinsic), while non-professionals are primarily motivated by intrinsic reasons (topic interest and purpose of study). this notion is also supported by the latent class analyses, which showed that three of the four classes for professional respondents had a high probability of naming incentives as one of their main reasons for survey participation, whereas none of the four non-professional clusters rated incentives highly. the differences between the two samples highlight that professional panel members have different motivation structures than participants in general population surveys. this may undermine generalizability, but it also provides opportunities for targeted recruitment.} {experiment,motivation,professional respondents,ranking vs. rating,survey participation} {experiment,motivation,professional respondents,ranking vs. rating,survey participation}']"
27,16,27_questionnaire_multilingual_errors_machine,"['questionnaire', 'multilingual', 'errors', 'machine', 'german']","['how does back translation fare against team translation? an experimental case study in the language combination english–german {when it comes to quality in questionnaire translation and hence comparability in comparative research, the chosen translation method is crucial for the outcome. few empirical studies compare different translation methods—a fact which is often deplored in the research community. to fill the gap, in this study, the team translation approach is compared against a simple back-translation approach. the starting point in both cases was the initial english–german translations of issp (international social survey program) questions. the final translations from both approaches were assessed, with a focus on how translation issues, such as mistranslations or wording issues identified in the initial translations were addressed. while none of the twenty-nine issues in the initial translation were present in the final team translation version, twenty-two of these issues were still present in the final version after the back-translation approach. for a selected number of items, we also ran a split-ballot experiment in a web survey. only five out of fifteen items (33 percent) that went into the experiment showed significant differences between the translations, and only one could clearly be attributed to remaining errors in the back-translation version. in sum, the final translation from the team approach clearly outperformed the final translation from the back-translation approach when it comes to text-based criteria (in particular, accuracy and fluency). the quantitative test showed that many translation issues (those remaining in the translation after the back translation step) had no effect on the estimates. nevertheless, we ask respondents to put effort into survey responding; in the same vein, we as researchers should put effort in the survey experience by providing questions that are clearly worded and free of errors, which puts the team approach ahead of the back-translation approach.} {back translation,comparison of translation methods,questionnaire translation,split-ballot experiment,team translation} {back translation,comparison of translation methods,questionnaire translation,split-ballot experiment,team translation}', 'how does back translation fare against team translation? an experimental case study in the language combination english–german {when it comes to quality in questionnaire translation and hence comparability in comparative research, the chosen translation method is crucial for the outcome. few empirical studies compare different translation methods—a fact which is often deplored in the research community. to fill the gap, in this study, the team translation approach is compared against a simple back-translation approach. the starting point in both cases was the initial english–german translations of issp (international social survey program) questions. the final translations from both approaches were assessed, with a focus on how translation issues, such as mistranslations or wording issues identified in the initial translations were addressed. while none of the twenty-nine issues in the initial translation were present in the final team translation version, twenty-two of these issues were still present in the final version after the back-translation approach. for a selected number of items, we also ran a split-ballot experiment in a web survey. only five out of fifteen items (33 percent) that went into the experiment showed significant differences between the translations, and only one could clearly be attributed to remaining errors in the back-translation version. in sum, the final translation from the team approach clearly outperformed the final translation from the back-translation approach when it comes to text-based criteria (in particular, accuracy and fluency). the quantitative test showed that many translation issues (those remaining in the translation after the back translation step) had no effect on the estimates. nevertheless, we ask respondents to put effort into survey responding; in the same vein, we as researchers should put effort in the survey experience by providing questions that are clearly worded and free of errors, which puts the team approach ahead of the back-translation approach.} {back translation,comparison of translation methods,questionnaire translation,split-ballot experiment,team translation} {back translation,comparison of translation methods,questionnaire translation,split-ballot experiment,team translation}', 'how does back translation fare against team translation? an experimental case study in the language combination english–german {when it comes to quality in questionnaire translation and hence comparability in comparative research, the chosen translation method is crucial for the outcome. few empirical studies compare different translation methods—a fact which is often deplored in the research community. to fill the gap, in this study, the team translation approach is compared against a simple back-translation approach. the starting point in both cases was the initial english–german translations of issp (international social survey program) questions. the final translations from both approaches were assessed, with a focus on how translation issues, such as mistranslations or wording issues identified in the initial translations were addressed. while none of the twenty-nine issues in the initial translation were present in the final team translation version, twenty-two of these issues were still present in the final version after the back-translation approach. for a selected number of items, we also ran a split-ballot experiment in a web survey. only five out of fifteen items (33 percent) that went into the experiment showed significant differences between the translations, and only one could clearly be attributed to remaining errors in the back-translation version. in sum, the final translation from the team approach clearly outperformed the final translation from the back-translation approach when it comes to text-based criteria (in particular, accuracy and fluency). the quantitative test showed that many translation issues (those remaining in the translation after the back translation step) had no effect on the estimates. nevertheless, we ask respondents to put effort into survey responding; in the same vein, we as researchers should put effort in the survey experience by providing questions that are clearly worded and free of errors, which puts the team approach ahead of the back-translation approach.} {back translation,comparison of translation methods,questionnaire translation,split-ballot experiment,team translation} {back translation,comparison of translation methods,questionnaire translation,split-ballot experiment,team translation}']"
28,16,28_nonresponse_machine learning_panel_waves,"['nonresponse', 'machine learning', 'panel', 'waves', 'time']","['predicting nonresponse in future waves of a probability-based mixed-mode panel with machine learning {nonresponse in panel studies can lead to a substantial loss in data quality owing to its potential to introduce bias and distort survey estimates. recent work investigates the usage of machine learning to predict nonresponse in advance, such that predicted nonresponse propensities can be used to inform the data collection process. however, predicting nonresponse in panel studies requires accounting for the longitudinal data structure in terms of model building, tuning, and evaluation. this study proposes a longitudinal framework for predicting nonresponse with machine learning and multiple panel waves and illustrates its application. with respect to model building, this approach utilizes information from multiple waves by introducing features that aggregate previous (non)response patterns. concerning model tuning and evaluation, temporal crossvalidation is employed by iterating through pairs of panel waves such that the training and test sets move in time. implementing this approach with data from a german probability-based mixed-mode panel shows that aggregating information over multiple panel waves can be used to build prediction models with competitive and robust performance over all test waves.} {machine learning,nonresponse,panel attrition,prediction,temporal crossvalidation} {machine learning,nonresponse,panel attrition,prediction,temporal crossvalidation}', 'predicting nonresponse in future waves of a probability-based mixed-mode panel with machine learning {nonresponse in panel studies can lead to a substantial loss in data quality owing to its potential to introduce bias and distort survey estimates. recent work investigates the usage of machine learning to predict nonresponse in advance, such that predicted nonresponse propensities can be used to inform the data collection process. however, predicting nonresponse in panel studies requires accounting for the longitudinal data structure in terms of model building, tuning, and evaluation. this study proposes a longitudinal framework for predicting nonresponse with machine learning and multiple panel waves and illustrates its application. with respect to model building, this approach utilizes information from multiple waves by introducing features that aggregate previous (non)response patterns. concerning model tuning and evaluation, temporal crossvalidation is employed by iterating through pairs of panel waves such that the training and test sets move in time. implementing this approach with data from a german probability-based mixed-mode panel shows that aggregating information over multiple panel waves can be used to build prediction models with competitive and robust performance over all test waves.} {machine learning,nonresponse,panel attrition,prediction,temporal crossvalidation} {machine learning,nonresponse,panel attrition,prediction,temporal crossvalidation}', 'predicting nonresponse in future waves of a probability-based mixed-mode panel with machine learning {nonresponse in panel studies can lead to a substantial loss in data quality owing to its potential to introduce bias and distort survey estimates. recent work investigates the usage of machine learning to predict nonresponse in advance, such that predicted nonresponse propensities can be used to inform the data collection process. however, predicting nonresponse in panel studies requires accounting for the longitudinal data structure in terms of model building, tuning, and evaluation. this study proposes a longitudinal framework for predicting nonresponse with machine learning and multiple panel waves and illustrates its application. with respect to model building, this approach utilizes information from multiple waves by introducing features that aggregate previous (non)response patterns. concerning model tuning and evaluation, temporal crossvalidation is employed by iterating through pairs of panel waves such that the training and test sets move in time. implementing this approach with data from a german probability-based mixed-mode panel shows that aggregating information over multiple panel waves can be used to build prediction models with competitive and robust performance over all test waves.} {machine learning,nonresponse,panel attrition,prediction,temporal crossvalidation} {machine learning,nonresponse,panel attrition,prediction,temporal crossvalidation}']"
29,16,29_political knowledge_web tracking_immigration_actors,"['political knowledge', 'web tracking', 'immigration', 'actors', 'european union']","['how to detect and influence looking up answers to political knowledge questions in web surveys {when answering political knowledge questions in web surveys, respondents can look up the correct answer on the internet. this response behavior artificially inflates political knowledge scores that are supposed to measure fact-based information. in the present study, we address the existing knowledge gaps of previous research regarding looking up answers to political knowledge questions in web surveys. we conducted an experimental study based on the german internet panel, a large-scale population survey that uses a probability-based sample. based on this experiment, we show that instructions help to reduce the number of lookups to knowledge questions in web surveys. we provide further evidence that looking up answers results in more correct answers to knowledge questions and, thus, in inflated political knowledge scores. finally, our findings illustrate the challenges and benefits of using self-reported or paradata-based lookup measures as well as a combined measure that aims at utilizing both to detect lookups to political knowledge questions in web surveys.}', 'how to detect and influence looking up answers to political knowledge questions in web surveys {when answering political knowledge questions in web surveys, respondents can look up the correct answer on the internet. this response behavior artificially inflates political knowledge scores that are supposed to measure fact-based information. in the present study, we address the existing knowledge gaps of previous research regarding looking up answers to political knowledge questions in web surveys. we conducted an experimental study based on the german internet panel, a large-scale population survey that uses a probability-based sample. based on this experiment, we show that instructions help to reduce the number of lookups to knowledge questions in web surveys. we provide further evidence that looking up answers results in more correct answers to knowledge questions and, thus, in inflated political knowledge scores. finally, our findings illustrate the challenges and benefits of using self-reported or paradata-based lookup measures as well as a combined measure that aims at utilizing both to detect lookups to political knowledge questions in web surveys.}', 'how to detect and influence looking up answers to political knowledge questions in web surveys {when answering political knowledge questions in web surveys, respondents can look up the correct answer on the internet. this response behavior artificially inflates political knowledge scores that are supposed to measure fact-based information. in the present study, we address the existing knowledge gaps of previous research regarding looking up answers to political knowledge questions in web surveys. we conducted an experimental study based on the german internet panel, a large-scale population survey that uses a probability-based sample. based on this experiment, we show that instructions help to reduce the number of lookups to knowledge questions in web surveys. we provide further evidence that looking up answers results in more correct answers to knowledge questions and, thus, in inflated political knowledge scores. finally, our findings illustrate the challenges and benefits of using self-reported or paradata-based lookup measures as well as a combined measure that aims at utilizing both to detect lookups to political knowledge questions in web surveys.}']"
30,16,30_welfare_crises_multilevel_factorial,"['welfare', 'crises', 'multilevel', 'factorial', 'europe']","['is there a geography of euroscepticism among the winners and losers of globalization? {support for eu membership has long been an important topic of study. individual-level research shows that winners of globalisation, including the higher educated, express greater eu support as they profit from economic and cultural conditions resulting from european integration. recent context-focused work suggests that individuals in ‘left-behind’ places are less supportive of eu integration because of their home regions’ weaker long-term economic conditions. this paper brings these two research strands into conversation with each other by examining how the relationship between eu support and individual-level education is contingent on subnational economic conditions. using harmonised eurobarometer data from almost 750,000 respondents spanning 2004–2019, combined with subnational economic data from 201 european regions, we find no evidence that subnational economic conditions influence the relationship between eu support and respondents’ education level. at the same time, when cross-sectionally comparing long-term differences between regions, we find that eu support is positively related to regional gdp per capita (though unrelated to regional unemployment), among both the higher and lower educated, and especially in the post-great recession period. longitudinally, eu support is positively related to declining regional unemployment, both among the higher and lower educated, but not to increasing regional gdp per capita.} {education,euroscepticism,political geography,subnational economic conditions} {education,euroscepticism,political geography,subnational economic conditions}', 'is there a geography of euroscepticism among the winners and losers of globalization? {support for eu membership has long been an important topic of study. individual-level research shows that winners of globalisation, including the higher educated, express greater eu support as they profit from economic and cultural conditions resulting from european integration. recent context-focused work suggests that individuals in ‘left-behind’ places are less supportive of eu integration because of their home regions’ weaker long-term economic conditions. this paper brings these two research strands into conversation with each other by examining how the relationship between eu support and individual-level education is contingent on subnational economic conditions. using harmonised eurobarometer data from almost 750,000 respondents spanning 2004–2019, combined with subnational economic data from 201 european regions, we find no evidence that subnational economic conditions influence the relationship between eu support and respondents’ education level. at the same time, when cross-sectionally comparing long-term differences between regions, we find that eu support is positively related to regional gdp per capita (though unrelated to regional unemployment), among both the higher and lower educated, and especially in the post-great recession period. longitudinally, eu support is positively related to declining regional unemployment, both among the higher and lower educated, but not to increasing regional gdp per capita.} {education,euroscepticism,political geography,subnational economic conditions} {education,euroscepticism,political geography,subnational economic conditions}', 'is there a geography of euroscepticism among the winners and losers of globalization? {support for eu membership has long been an important topic of study. individual-level research shows that winners of globalisation, including the higher educated, express greater eu support as they profit from economic and cultural conditions resulting from european integration. recent context-focused work suggests that individuals in ‘left-behind’ places are less supportive of eu integration because of their home regions’ weaker long-term economic conditions. this paper brings these two research strands into conversation with each other by examining how the relationship between eu support and individual-level education is contingent on subnational economic conditions. using harmonised eurobarometer data from almost 750,000 respondents spanning 2004–2019, combined with subnational economic data from 201 european regions, we find no evidence that subnational economic conditions influence the relationship between eu support and respondents’ education level. at the same time, when cross-sectionally comparing long-term differences between regions, we find that eu support is positively related to regional gdp per capita (though unrelated to regional unemployment), among both the higher and lower educated, and especially in the post-great recession period. longitudinally, eu support is positively related to declining regional unemployment, both among the higher and lower educated, but not to increasing regional gdp per capita.} {education,euroscepticism,political geography,subnational economic conditions} {education,euroscepticism,political geography,subnational economic conditions}']"
31,15,31_labour_migration_differences_couples,"['labour', 'migration', 'differences', 'couples', 'germany']","['pre-existing company contacts and premature termination of apprenticeship training in germany {using longitudinal data from starting cohort 4 of the german national educational panel study (neps), we examined whether pre-existing strong ties and weak ties in the training company are associated with the risk of premature termination of apprenticeship training in germany. this is highly relevant for the literature on social capital in the labor market since so far little is known about the role of social contacts for the turnover propensity of labor market entrants. by examining a potentially important factor for a successful labor market integration, our research also adds to both the school-to-work and the social stratification literature. our empirical results are only partly consistent with our theoretically derived expectations. while contrary to our expectations, we found no association between strong ties and termination probability, weak ties were, as expected, associated with a lower probability of premature training termination among those apprentices who were trained in their desired occupation. our main results, combined with several robustness checks, let us assume that this is due to better matched training situations.} {matching quality,pre-existing company contacts,premature termination of apprenticeship training,school-to-work transition,strong and weak ties} {matching quality,pre-existing company contacts,premature termination of apprenticeship training,school-to-work transition,strong and weak ties}', 'ethnic differences in social capital mobilization at the transition to vocational training in germany {in this chapter, we provide an in-depth analysis of the differences between students with and without a migration background in germany in mobilising social capital during the transition to vocational education and training (vet) after lower secondary education. besides retrospective information, we analyse (hypothetical) prospective information. furthermore, we distinguish between different kinds of social contacts and different types of support. using data from the first five waves of starting cohort 4 (9th graders) of the national educational panel study (neps) we find that students rely heavily on their social contacts, with parents playing the most important role. regarding general information and support, we find only small ethnic differences in the mobilization of non-institutional social contacts. in contrast, adolescents with a migration background tend to receive specific assistance less often from relatives outside the nuclear family and substantively less often from parents. our results suggest that the general motivation of non-institutional social contacts to provide support at the transition to vet does not differ between natives and migrants, but that the ability of these ties to provide more specific, instrumental assistance depends on their receiving-country-specific resources and thus on their migration history.} {ethnic differences,migrants,network mobilization,school-to-work transition,social capital,vocational training} {ethnic differences,migrants,network mobilization,school-to-work transition,social capital,vocational training}', 'ethnic differences in social capital mobilization at the transition to vocational training in germany {in this chapter, we provide an in-depth analysis of the differences between students with and without a migration background in germany in mobilising social capital during the transition to vocational education and training (vet) after lower secondary education. besides retrospective information, we analyse (hypothetical) prospective information. furthermore, we distinguish between different kinds of social contacts and different types of support. using data from the first five waves of starting cohort 4 (9th graders) of the national educational panel study (neps) we find that students rely heavily on their social contacts, with parents playing the most important role. regarding general information and support, we find only small ethnic differences in the mobilization of non-institutional social contacts. in contrast, adolescents with a migration background tend to receive specific assistance less often from relatives outside the nuclear family and substantively less often from parents. our results suggest that the general motivation of non-institutional social contacts to provide support at the transition to vet does not differ between natives and migrants, but that the ability of these ties to provide more specific, instrumental assistance depends on their receiving-country-specific resources and thus on their migration history.} {ethnic differences,migrants,network mobilization,school-to-work transition,social capital,vocational training} {ethnic differences,migrants,network mobilization,school-to-work transition,social capital,vocational training}']"
32,15,32_knowledge graphs_heterogeneous_domain_artificial intelligence,"['knowledge graphs', 'heterogeneous', 'domain', 'artificial intelligence', 'scientific publications']","['research knowledge graphs: the shifting paradigm of scholarly information representation {sharing and reusing research artifacts, such as datasets, publications, or methods is a fundamental part of scientific activity, where heterogeneity of resources and metadata and the common practice of capturing information in unstructured publications pose crucial challenges. reproducibility of research and finding state-of-the-art methods or data have become increasingly challenging. in this context, the concept of research knowledge graphs (rkgs) has emerged, aiming at providing an easy to use and machine-actionable representation of research artifacts and their relations. that is facilitated through the use of established principles for data representation, the consistent adoption of globally unique persistent identifiers and the reuse and linking of vocabularies and data. this paper provides the first conceptualisation of the rkg vision, a categorisation of in-use rkgs together with a description of rkg building blocks and principles. we also survey real-world rkg implementations differing with respect to scale, schema, data, used vocabulary, and reliability of the contained data. we also characterise different rkg construction methodologies and provide a forward-looking perspective on the diverse applications, opportunities, and challenges associated with the rkg vision.} {information representation,knowledge graphs,linked data,open science,scholarly knowledge} {information representation,knowledge graphs,linked data,open science,scholarly knowledge}', 'research knowledge graphs: the shifting paradigm of scholarly information representation {sharing and reusing research artifacts, such as datasets, publications, or methods is a fundamental part of scientific activity, where heterogeneity of resources and metadata and the common practice of capturing information in unstructured publications pose crucial challenges. reproducibility of research and finding state-of-the-art methods or data have become increasingly challenging. in this context, the concept of research knowledge graphs (rkgs) has emerged, aiming at providing an easy to use and machine-actionable representation of research artifacts and their relations. that is facilitated through the use of established principles for data representation, the consistent adoption of globally unique persistent identifiers and the reuse and linking of vocabularies and data. this paper provides the first conceptualisation of the rkg vision, a categorisation of in-use rkgs together with a description of rkg building blocks and principles. we also survey real-world rkg implementations differing with respect to scale, schema, data, used vocabulary, and reliability of the contained data. we also characterise different rkg construction methodologies and provide a forward-looking perspective on the diverse applications, opportunities, and challenges associated with the rkg vision.} {information representation,knowledge graphs,linked data,open science,scholarly knowledge} {information representation,knowledge graphs,linked data,open science,scholarly knowledge}', 'triplétoile: extraction of knowledge from microblogging text {numerous methods and pipelines have recently emerged for the automatic extraction of knowledge graphs from documents such as scientific publications and patents. however, adapting these methods to incorporate alternative text sources like micro-blogging posts and news has proven challenging as they struggle to model open-domain entities and relations, typically found in these sources. in this paper, we propose an enhanced information extraction pipeline tailored to the extraction of a knowledge graph comprising open-domain entities from micro-blogging posts on social media platforms. our pipeline leverages dependency parsing and classifies entity relations in an unsupervised manner through hierarchical clustering over word embeddings. we provide a use case on extracting semantic triples from a corpus of 100 thousand tweets about digital transformation and publicly release the generated knowledge graph. on the same dataset, we conduct two experimental evaluations, showing that the system produces triples with precision over 95% and outperforms similar pipelines of around 5% in terms of precision, while generating a comparatively higher number of triples.} {hierarchical clustering,information extraction,knowledge graphs,named entity recognition,social media analysis,word embeddings} {hierarchical clustering,information extraction,knowledge graphs,named entity recognition,social media analysis,word embeddings}']"
33,15,33_hybrid_journalism_knowledge graphs_multilingual,"['hybrid', 'journalism', 'knowledge graphs', 'multilingual', 'fact checking']","['beyondfacts 2025: 5th international workshop on computational methods for online discourse analysis {this workshop explores the intersection of computational and interdisciplinary approaches to analyzing online discourse, including claims, arguments, and opinions on controversial topics. with the rise of mis- and disinformation, bias, and echo chambers, nlp-based methods such as argument mining, stance detection, and fact verification have become essential. however, these tasks require robust conceptual foundations across fields like communication studies, computational linguistics, and computer science. beyondfacts fosters collaboration among diverse research communities-including social sciences, political science, computational journalism, and computer science-to enhance machine-interpretation and analysis of societal debates using techniques from web mining, ai, and nlp.} {computational fact-checking,computational journalism,intent detection,knowledge graphs,llms,mis- and dis-information spread and detection,online discourse analysis,social media mining,stance viewpoint discovery,web mining} {computational fact-checking,computational journalism,intent detection,knowledge graphs,llms,mis- and dis-information spread and detection,online discourse analysis,social media mining,stance viewpoint discovery,web mining}', 'beyond facts: 4th international workshop on computational methods for online discourse analysis {expressing opinions and interacting with others on the web has led to the production of an abundance of online discourse data, such as claims and viewpoints on controversial topics, their sources and contexts (events, entities). this data constitutes a valuable source of insights for studies into misinformation spread, bias reinforcement, echo chambers or political agenda setting. computational methods, mostly from the field of nlp, have emerged that tackle a wide range of tasks in this context, including argument and opinion mining, claim detection, checkworthiness detection, stance detection or fact verification. however, computational models require robust definitions of classes and concepts under investigation. thus, these computational tasks require a strong interdisciplinary and epistemological foundation, specifically with respect to the underlying definitions of key concepts such as claims, arguments, stances, check-worthiness or veracity. this requires a highly interdisciplinary approach combining expertise from fields such as communication studies, computational linguistics and computer science. as opposed to facts, claims are inherently more complex. their interpretation strongly depends on the context and a variety of intentional or unintended meanings, where terminology and conceptual understandings strongly diverge across communities. from a computational perspective, in order to address this complexity, the synergy of multiple approaches, coming both from symbolic (knowledge representation) and statistical ai seem to be promising to tackle such challenges. this workshop aims at strengthening the relations between these communities, providing a forum for shared works on the modeling, extraction and analysis of discourse on the web. it will address the need for a shared understanding and structured knowledge about discourse data in order to enable machine-interpretation, discoverability and reuse, in support of scientific or journalistic studies into the analysis of societal debates on the web. beyond research into information and knowledge extraction, data consolidation and modeling for knowledge graphs building, the workshop targets communities focusing on the analysis of online discourse, relying on methods from machine learning, natural language processing, large language models and web data mining.} {computational fact-checking,computational journalism,intent detection,knowledge graphs,language models,mis- and disinformation spread and detection,online discourse analysis,social web mining,stance / viewpoint discovery} {computational fact-checking,computational journalism,intent detection,knowledge graphs,language models,mis- and disinformation spread and detection,online discourse analysis,social web mining,stance / viewpoint discovery}', 'beyond facts: 4th international workshop on computational methods for online discourse analysis {expressing opinions and interacting with others on the web has led to the production of an abundance of online discourse data, such as claims and viewpoints on controversial topics, their sources and contexts (events, entities). this data constitutes a valuable source of insights for studies into misinformation spread, bias reinforcement, echo chambers or political agenda setting. computational methods, mostly from the field of nlp, have emerged that tackle a wide range of tasks in this context, including argument and opinion mining, claim detection, checkworthiness detection, stance detection or fact verification. however, computational models require robust definitions of classes and concepts under investigation. thus, these computational tasks require a strong interdisciplinary and epistemological foundation, specifically with respect to the underlying definitions of key concepts such as claims, arguments, stances, check-worthiness or veracity. this requires a highly interdisciplinary approach combining expertise from fields such as communication studies, computational linguistics and computer science. as opposed to facts, claims are inherently more complex. their interpretation strongly depends on the context and a variety of intentional or unintended meanings, where terminology and conceptual understandings strongly diverge across communities. from a computational perspective, in order to address this complexity, the synergy of multiple approaches, coming both from symbolic (knowledge representation) and statistical ai seem to be promising to tackle such challenges. this workshop aims at strengthening the relations between these communities, providing a forum for shared works on the modeling, extraction and analysis of discourse on the web. it will address the need for a shared understanding and structured knowledge about discourse data in order to enable machine-interpretation, discoverability and reuse, in support of scientific or journalistic studies into the analysis of societal debates on the web. beyond research into information and knowledge extraction, data consolidation and modeling for knowledge graphs building, the workshop targets communities focusing on the analysis of online discourse, relying on methods from machine learning, natural language processing, large language models and web data mining.} {computational fact-checking,computational journalism,intent detection,knowledge graphs,language models,mis- and disinformation spread and detection,online discourse analysis,social web mining,stance / viewpoint discovery} {computational fact-checking,computational journalism,intent detection,knowledge graphs,language models,mis- and disinformation spread and detection,online discourse analysis,social web mining,stance / viewpoint discovery}']"
34,15,34_chapter_war_east west germany_changes,"['chapter', 'war', 'east west germany', 'changes', 'mental']","['thirty years after the berlin wall: german unification and transformation research {this book examines the increasing body of research dedicated to the lasting differences between the former separate states of the federal german republic (frg) and the german democratic republic (gdr). thirty years after the fall of the berlin wall, it takes a broad view on german unification and transformation research. transformation and unification processes in east and west germany are still ongoing, and they may serve as a model for social change and its political, economic, and psychological consequences. using advanced statistical methods of analysis, this edited volume provides insights into the valuable contextualization of individual and social phenomena that current research on german unification and transformation is producing. following the open science mindset using code and data, the authors investigate temporal trends in (1) mental health, (2) political attitudes, and (3) work and family life. it explores changes in mental health and political attitudes, as well as continued differences in work and family arrangements, that may stem from heterogeneous experiences within the systems and during the transformation process. this book will appeal to scholars and students from the disciplines of sociology, political science, public health, social psychology, psychology, and communication science interested in postsocialist transition processes and temporal changes in individuals and societies.}', 'thirty years after the berlin wall: german unification and transformation research {this book examines the increasing body of research dedicated to the lasting differences between the former separate states of the federal german republic (frg) and the german democratic republic (gdr). thirty years after the fall of the berlin wall, it takes a broad view on german unification and transformation research. transformation and unification processes in east and west germany are still ongoing, and they may serve as a model for social change and its political, economic, and psychological consequences. using advanced statistical methods of analysis, this edited volume provides insights into the valuable contextualization of individual and social phenomena that current research on german unification and transformation is producing. following the open science mindset using code and data, the authors investigate temporal trends in (1) mental health, (2) political attitudes, and (3) work and family life. it explores changes in mental health and political attitudes, as well as continued differences in work and family arrangements, that may stem from heterogeneous experiences within the systems and during the transformation process. this book will appeal to scholars and students from the disciplines of sociology, political science, public health, social psychology, psychology, and communication science interested in postsocialist transition processes and temporal changes in individuals and societies.}', 'thirty years after the berlin wall: german unification and transformation research {this book examines the increasing body of research dedicated to the lasting differences between the former separate states of the federal german republic (frg) and the german democratic republic (gdr). thirty years after the fall of the berlin wall, it takes a broad view on german unification and transformation research. transformation and unification processes in east and west germany are still ongoing, and they may serve as a model for social change and its political, economic, and psychological consequences. using advanced statistical methods of analysis, this edited volume provides insights into the valuable contextualization of individual and social phenomena that current research on german unification and transformation is producing. following the open science mindset using code and data, the authors investigate temporal trends in (1) mental health, (2) political attitudes, and (3) work and family life. it explores changes in mental health and political attitudes, as well as continued differences in work and family arrangements, that may stem from heterogeneous experiences within the systems and during the transformation process. this book will appeal to scholars and students from the disciplines of sociology, political science, public health, social psychology, psychology, and communication science interested in postsocialist transition processes and temporal changes in individuals and societies.}']"
35,14,35_voting_immigration_media_right wing,"['voting', 'immigration', 'media', 'right wing', 'individual level']","[""ready or not. national identity, vote choice, and mass media: evidence from germany {exploiting the increased prominence of debates on immigration, right-wing parties often frame and campaign against immigrants as a threat to national societies. research on national identity has shown that these parties are particularly successful among voters with an ethnically charged, exclusionary conception of nation. national identity, however, tends to be rather latent and stable, while far-right voting is much more volatile. explaining a temporal influence of national identity on political behavior, social-psychological theories argue that identities need to be activated to become behaviorally relevant. the main argument of this article is that the presence of immigration-related news in the mass media can serve as such a situational factor for thinking about the nation and thus increase its salience for electoral behavior. combining individual-level panel data from the german longitudinal election study's short-term campaign panel (gles, 2019) with a measure of media salience of immigration-related news in news articles, this study is the first to examine whether national identity can be activated for political behavior through the salience of immigration-related issues in the mass media using panel data.} {identity activation,media salience,national identity,voting} {identity activation,media salience,national identity,voting}"", ""ready or not. national identity, vote choice, and mass media: evidence from germany {exploiting the increased prominence of debates on immigration, right-wing parties often frame and campaign against immigrants as a threat to national societies. research on national identity has shown that these parties are particularly successful among voters with an ethnically charged, exclusionary conception of nation. national identity, however, tends to be rather latent and stable, while far-right voting is much more volatile. explaining a temporal influence of national identity on political behavior, social-psychological theories argue that identities need to be activated to become behaviorally relevant. the main argument of this article is that the presence of immigration-related news in the mass media can serve as such a situational factor for thinking about the nation and thus increase its salience for electoral behavior. combining individual-level panel data from the german longitudinal election study's short-term campaign panel (gles, 2019) with a measure of media salience of immigration-related news in news articles, this study is the first to examine whether national identity can be activated for political behavior through the salience of immigration-related issues in the mass media using panel data.} {identity activation,media salience,national identity,voting} {identity activation,media salience,national identity,voting}"", ""ready or not. national identity, vote choice, and mass media: evidence from germany {exploiting the increased prominence of debates on immigration, right-wing parties often frame and campaign against immigrants as a threat to national societies. research on national identity has shown that these parties are particularly successful among voters with an ethnically charged, exclusionary conception of nation. national identity, however, tends to be rather latent and stable, while far-right voting is much more volatile. explaining a temporal influence of national identity on political behavior, social-psychological theories argue that identities need to be activated to become behaviorally relevant. the main argument of this article is that the presence of immigration-related news in the mass media can serve as such a situational factor for thinking about the nation and thus increase its salience for electoral behavior. combining individual-level panel data from the german longitudinal election study's short-term campaign panel (gles, 2019) with a measure of media salience of immigration-related news in news articles, this study is the first to examine whether national identity can be activated for political behavior through the salience of immigration-related issues in the mass media using panel data.} {identity activation,media salience,national identity,voting} {identity activation,media salience,national identity,voting}""]"
36,14,36_fake_news_named entity recognition_deep learning,"['fake', 'news', 'named entity recognition', 'deep learning', 'machine']","['linguistic feature fusion for arabic fake news detection and named entity recognition using reinforcement learning and swarm optimization {in the context of the escalating use of social media in arabic-speaking countries, driven by improved internet access, affordable smartphones, and a growing digital connectivity trend, this study addresses a significant challenge: the widespread dissemination of fake news. the ease and rapidity of spreading information on social media, coupled with a lack of stringent fact-checking measures, exacerbate the issue of misinformation. our study examines how language features, especially named entity recognition (ner) features, play a role in detecting fake news. we built two models: an arabert multi-task learning (mtl) based one for classifying arabic fake news, and a token classification model that focuses on fake news ner features. the study combines embedding vectors from these models using an embedding fusion technique and applies machine learning algorithms for fake news detection in arabic. we also introduced a feature selection algorithm named rlttao based on improving the triangulation topology aggregation optimizer (ttao) performance using reinforcement learning and random opposition-based learning to enhance the performance by selecting relevant features, thereby improving the fusion process. our results show that incorporating ner features enhances the accuracy of fake news detection in 5 out of 7 datasets, with an average improvement of 1.62%.} {arabic fake news detection,deep learning,linguistic feature fusion,named entity recognition,reinforcement learning,swarm optimization} {arabic fake news detection,deep learning,linguistic feature fusion,named entity recognition,reinforcement learning,swarm optimization}', 'linguistic feature fusion for arabic fake news detection and named entity recognition using reinforcement learning and swarm optimization {in the context of the escalating use of social media in arabic-speaking countries, driven by improved internet access, affordable smartphones, and a growing digital connectivity trend, this study addresses a significant challenge: the widespread dissemination of fake news. the ease and rapidity of spreading information on social media, coupled with a lack of stringent fact-checking measures, exacerbate the issue of misinformation. our study examines how language features, especially named entity recognition (ner) features, play a role in detecting fake news. we built two models: an arabert multi-task learning (mtl) based one for classifying arabic fake news, and a token classification model that focuses on fake news ner features. the study combines embedding vectors from these models using an embedding fusion technique and applies machine learning algorithms for fake news detection in arabic. we also introduced a feature selection algorithm named rlttao based on improving the triangulation topology aggregation optimizer (ttao) performance using reinforcement learning and random opposition-based learning to enhance the performance by selecting relevant features, thereby improving the fusion process. our results show that incorporating ner features enhances the accuracy of fake news detection in 5 out of 7 datasets, with an average improvement of 1.62%.} {arabic fake news detection,deep learning,linguistic feature fusion,named entity recognition,reinforcement learning,swarm optimization} {arabic fake news detection,deep learning,linguistic feature fusion,named entity recognition,reinforcement learning,swarm optimization}', 'linguistic feature fusion for arabic fake news detection and named entity recognition using reinforcement learning and swarm optimization {in the context of the escalating use of social media in arabic-speaking countries, driven by improved internet access, affordable smartphones, and a growing digital connectivity trend, this study addresses a significant challenge: the widespread dissemination of fake news. the ease and rapidity of spreading information on social media, coupled with a lack of stringent fact-checking measures, exacerbate the issue of misinformation. our study examines how language features, especially named entity recognition (ner) features, play a role in detecting fake news. we built two models: an arabert multi-task learning (mtl) based one for classifying arabic fake news, and a token classification model that focuses on fake news ner features. the study combines embedding vectors from these models using an embedding fusion technique and applies machine learning algorithms for fake news detection in arabic. we also introduced a feature selection algorithm named rlttao based on improving the triangulation topology aggregation optimizer (ttao) performance using reinforcement learning and random opposition-based learning to enhance the performance by selecting relevant features, thereby improving the fusion process. our results show that incorporating ner features enhances the accuracy of fake news detection in 5 out of 7 datasets, with an average improvement of 1.62%.} {arabic fake news detection,deep learning,linguistic feature fusion,named entity recognition,reinforcement learning,swarm optimization} {arabic fake news detection,deep learning,linguistic feature fusion,named entity recognition,reinforcement learning,swarm optimization}']"
37,13,37_validation_machine learning_annotated_versions,"['validation', 'machine learning', 'annotated', 'versions', 'strategies']","[""establishing standards for human-annotated samples applied in supervised machine learning - evidence from a monte carlo simulation {automated content analyses have become a popular tool in communication science. while standard procedures for manual content analysis were established decades ago, it remains an open question whether these standards are sufficient for the use of human-annotated data to train supervised machine learning models. scholars typically follow a two-stage procedure to obtain high prediction accuracy: manual content analysis followed by model training with human-annotated samples. we argue that a loss in prediction accuracy in supervised machine learning builds up over this two-stage procedure. in a monte carlo simulation, we tested (1) human coder errors (random, individual systematic, joint systematic) and (2) curation strategies for human-annotated datasets (one coder per document, majority rule, full agreement) as two sequential sources of accuracy loss of automated content analysis. coder agreement prior to conducting manual content analysis remains an important quality criterion for automated content analyses. a krippendorff's alpha of at least 0.8 is desirable to achieve satisfying prediction results after machine learning. systematic errors (individual and joint) must be avoided at all costs. the best training samples were obtained using one coder per document or the majority coding curation strategy. ultimately, this paper can help researchers produce trustworthy predictions when combining manual coding and machine learning.} {impact of coder errors,impact of curation strategies,monte carlo simulation,prediction accuracy,supervised machine learning} {impact of coder errors,impact of curation strategies,monte carlo simulation,prediction accuracy,supervised machine learning}"", ""establishing standards for human-annotated samples applied in supervised machine learning - evidence from a monte carlo simulation {automated content analyses have become a popular tool in communication science. while standard procedures for manual content analysis were established decades ago, it remains an open question whether these standards are sufficient for the use of human-annotated data to train supervised machine learning models. scholars typically follow a two-stage procedure to obtain high prediction accuracy: manual content analysis followed by model training with human-annotated samples. we argue that a loss in prediction accuracy in supervised machine learning builds up over this two-stage procedure. in a monte carlo simulation, we tested (1) human coder errors (random, individual systematic, joint systematic) and (2) curation strategies for human-annotated datasets (one coder per document, majority rule, full agreement) as two sequential sources of accuracy loss of automated content analysis. coder agreement prior to conducting manual content analysis remains an important quality criterion for automated content analyses. a krippendorff's alpha of at least 0.8 is desirable to achieve satisfying prediction results after machine learning. systematic errors (individual and joint) must be avoided at all costs. the best training samples were obtained using one coder per document or the majority coding curation strategy. ultimately, this paper can help researchers produce trustworthy predictions when combining manual coding and machine learning.} {impact of coder errors,impact of curation strategies,monte carlo simulation,prediction accuracy,supervised machine learning} {impact of coder errors,impact of curation strategies,monte carlo simulation,prediction accuracy,supervised machine learning}"", ""establishing standards for human-annotated samples applied in supervised machine learning - evidence from a monte carlo simulation {automated content analyses have become a popular tool in communication science. while standard procedures for manual content analysis were established decades ago, it remains an open question whether these standards are sufficient for the use of human-annotated data to train supervised machine learning models. scholars typically follow a two-stage procedure to obtain high prediction accuracy: manual content analysis followed by model training with human-annotated samples. we argue that a loss in prediction accuracy in supervised machine learning builds up over this two-stage procedure. in a monte carlo simulation, we tested (1) human coder errors (random, individual systematic, joint systematic) and (2) curation strategies for human-annotated datasets (one coder per document, majority rule, full agreement) as two sequential sources of accuracy loss of automated content analysis. coder agreement prior to conducting manual content analysis remains an important quality criterion for automated content analyses. a krippendorff's alpha of at least 0.8 is desirable to achieve satisfying prediction results after machine learning. systematic errors (individual and joint) must be avoided at all costs. the best training samples were obtained using one coder per document or the majority coding curation strategy. ultimately, this paper can help researchers produce trustworthy predictions when combining manual coding and machine learning.} {impact of coder errors,impact of curation strategies,monte carlo simulation,prediction accuracy,supervised machine learning} {impact of coder errors,impact of curation strategies,monte carlo simulation,prediction accuracy,supervised machine learning}""]"
38,13,38_recommendation_graph_named entity recognition_natural language processing,"['recommendation', 'graph', 'named entity recognition', 'natural language processing', 'user']","[""dynamic global structure enhanced multi-channel graph neural network for session-based recommendation {session-based recommendation is a challenging task, which aims at making recommendation for anonymous users based on in-session data, i.e. short-term interaction data. most session-based recommendation methods only model user's preferences with the current session sequence, which ignore rich information from a global perspective. meanwhile, previous works usually apply gnn to capture the transformation relationship between items, however the graph used in gnn is built through a static mode, which may introduce noise to the graph structure if user's preferences shift. in this paper, we propose a novel method called dynamic global structure enhanced multi-channel graph neural network (dgs-mgnn) to learn accurate representations of items from multiple perspectives. in dgs-mgnn, we propose a novel gnn model named multi-channel graph neural network to generate the local, global and consensus graphs dynamically and learn more informative representations of items based on the corresponding graph. meanwhile, in order to reduce the noise information within sessions, we utilize the graph structure to assist the attention mechanism to filter noisy information within each session, so as to generate an accurate intention representation for the user. finally, combined with a repeat and explore module, a more accurate prediction probability distribution is generated. we conduct extensive experiments on three widely used datasets, and the results demonstrate that dgs-mgnn is consistently superior to the state-of-the-art baseline models.} {attention model,behavior modeling,graph neural network,recommendation system,representation learning,session-based recommendation} {attention model,behavior modeling,graph neural network,recommendation system,representation learning,session-based recommendation}"", ""dynamic global structure enhanced multi-channel graph neural network for session-based recommendation {session-based recommendation is a challenging task, which aims at making recommendation for anonymous users based on in-session data, i.e. short-term interaction data. most session-based recommendation methods only model user's preferences with the current session sequence, which ignore rich information from a global perspective. meanwhile, previous works usually apply gnn to capture the transformation relationship between items, however the graph used in gnn is built through a static mode, which may introduce noise to the graph structure if user's preferences shift. in this paper, we propose a novel method called dynamic global structure enhanced multi-channel graph neural network (dgs-mgnn) to learn accurate representations of items from multiple perspectives. in dgs-mgnn, we propose a novel gnn model named multi-channel graph neural network to generate the local, global and consensus graphs dynamically and learn more informative representations of items based on the corresponding graph. meanwhile, in order to reduce the noise information within sessions, we utilize the graph structure to assist the attention mechanism to filter noisy information within each session, so as to generate an accurate intention representation for the user. finally, combined with a repeat and explore module, a more accurate prediction probability distribution is generated. we conduct extensive experiments on three widely used datasets, and the results demonstrate that dgs-mgnn is consistently superior to the state-of-the-art baseline models.} {attention model,behavior modeling,graph neural network,recommendation system,representation learning,session-based recommendation} {attention model,behavior modeling,graph neural network,recommendation system,representation learning,session-based recommendation}"", ""dynamic global structure enhanced multi-channel graph neural network for session-based recommendation {session-based recommendation is a challenging task, which aims at making recommendation for anonymous users based on in-session data, i.e. short-term interaction data. most session-based recommendation methods only model user's preferences with the current session sequence, which ignore rich information from a global perspective. meanwhile, previous works usually apply gnn to capture the transformation relationship between items, however the graph used in gnn is built through a static mode, which may introduce noise to the graph structure if user's preferences shift. in this paper, we propose a novel method called dynamic global structure enhanced multi-channel graph neural network (dgs-mgnn) to learn accurate representations of items from multiple perspectives. in dgs-mgnn, we propose a novel gnn model named multi-channel graph neural network to generate the local, global and consensus graphs dynamically and learn more informative representations of items based on the corresponding graph. meanwhile, in order to reduce the noise information within sessions, we utilize the graph structure to assist the attention mechanism to filter noisy information within each session, so as to generate an accurate intention representation for the user. finally, combined with a repeat and explore module, a more accurate prediction probability distribution is generated. we conduct extensive experiments on three widely used datasets, and the results demonstrate that dgs-mgnn is consistently superior to the state-of-the-art baseline models.} {attention model,behavior modeling,graph neural network,recommendation system,representation learning,session-based recommendation} {attention model,behavior modeling,graph neural network,recommendation system,representation learning,session-based recommendation}""]"
39,13,39_web_functions_behavioral_temporal,"['web', 'functions', 'behavioral', 'temporal', 'satisfaction']","['shall androids dream of genocides? how generative ai can change the future of memorialization of mass atrocities {the memorialization of mass atrocities such as war crimes and genocides facilitates the remembrance of past suffering, honors those who resisted the perpetrators, and helps prevent the distortion of historical facts. digital technologies have transformed memorialization practices by enabling less top-down and more creative approaches to remember mass atrocities. at the same time, they may also facilitate the spread of denialism and distortion, attempt to justify past crimes and attack the dignity of victims. the emergence of generative forms of artificial intelligence (ai), which produce textual and visual content, has the potential to revolutionize the field of memorialization even further. ai can identify patterns in training data to create new narratives for representing and interpreting mass atrocities—and do so in a fraction of the time it takes for humans. the use of generative ai in this context raises numerous questions: for example, can the paucity of training data on mass atrocities distort how ai interprets some atrocity-related inquiries? how important is the ability to differentiate between human- and ai-made content concerning mass atrocities? can ai-made content be used to promote false information concerning atrocities? this article addresses these and other questions by examining the opportunities and risks associated with using generative ais for memorializing mass atrocities. it also discusses recommendations for ais integration in memorialization practices to steer the use of these technologies toward a more ethical and sustainable direction.}', 'shall androids dream of genocides? how generative ai can change the future of memorialization of mass atrocities {the memorialization of mass atrocities such as war crimes and genocides facilitates the remembrance of past suffering, honors those who resisted the perpetrators, and helps prevent the distortion of historical facts. digital technologies have transformed memorialization practices by enabling less top-down and more creative approaches to remember mass atrocities. at the same time, they may also facilitate the spread of denialism and distortion, attempt to justify past crimes and attack the dignity of victims. the emergence of generative forms of artificial intelligence (ai), which produce textual and visual content, has the potential to revolutionize the field of memorialization even further. ai can identify patterns in training data to create new narratives for representing and interpreting mass atrocities—and do so in a fraction of the time it takes for humans. the use of generative ai in this context raises numerous questions: for example, can the paucity of training data on mass atrocities distort how ai interprets some atrocity-related inquiries? how important is the ability to differentiate between human- and ai-made content concerning mass atrocities? can ai-made content be used to promote false information concerning atrocities? this article addresses these and other questions by examining the opportunities and risks associated with using generative ais for memorializing mass atrocities. it also discusses recommendations for ais integration in memorialization practices to steer the use of these technologies toward a more ethical and sustainable direction.}', 'shall androids dream of genocides? how generative ai can change the future of memorialization of mass atrocities {the memorialization of mass atrocities such as war crimes and genocides facilitates the remembrance of past suffering, honors those who resisted the perpetrators, and helps prevent the distortion of historical facts. digital technologies have transformed memorialization practices by enabling less top-down and more creative approaches to remember mass atrocities. at the same time, they may also facilitate the spread of denialism and distortion, attempt to justify past crimes and attack the dignity of victims. the emergence of generative forms of artificial intelligence (ai), which produce textual and visual content, has the potential to revolutionize the field of memorialization even further. ai can identify patterns in training data to create new narratives for representing and interpreting mass atrocities—and do so in a fraction of the time it takes for humans. the use of generative ai in this context raises numerous questions: for example, can the paucity of training data on mass atrocities distort how ai interprets some atrocity-related inquiries? how important is the ability to differentiate between human- and ai-made content concerning mass atrocities? can ai-made content be used to promote false information concerning atrocities? this article addresses these and other questions by examining the opportunities and risks associated with using generative ais for memorializing mass atrocities. it also discusses recommendations for ais integration in memorialization practices to steer the use of these technologies toward a more ethical and sustainable direction.}']"
40,13,40_equivalence_regression_primary_performance,"['equivalence', 'regression', 'primary', 'performance', 'package']","['a comparative evaluation of quantification methods {quantification represents the problem of estimating the distribution of class labels on unseen data. it also represents a growing research field in supervised machine learning, for which a large variety of different algorithms has been proposed in recent years. however, a comprehensive empirical comparison of quantification methods that supports algorithm selection is not available yet. in this work, we close this research gap by conducting a thorough empirical performance comparison of 24 different quantification methods on in total more than 40 datasets, considering binary as well as multiclass quantification settings. we observe that no single algorithm generally outperforms all competitors, but identify a group of methods that perform best in the binary setting, including the threshold selection-based median sweep and tsmax methods, the dys framework including the hdy method, forman’s mixture model, and friedman’s method. for the multiclass setting, we observe that a different, broad group of algorithms yields good performance, including the hdx method, the generalized probabilistic adjusted count, the readme method, the energy distance minimization method, the em algorithm for quantification, and friedman’s method. we also find that tuning the underlying classifiers has in most cases only a limited impact on the quantification performance. more generally, we find that the performance on multiclass quantification is inferior to the results obtained in the binary setting. our results can guide practitioners who intend to apply quantification algorithms and help researchers identify opportunities for future research.} {class distribution estimation,comparative evaluation,prevalence estimation,quantification,supervised machine learning} {class distribution estimation,comparative evaluation,prevalence estimation,quantification,supervised machine learning}', 'a comparative evaluation of quantification methods {quantification represents the problem of estimating the distribution of class labels on unseen data. it also represents a growing research field in supervised machine learning, for which a large variety of different algorithms has been proposed in recent years. however, a comprehensive empirical comparison of quantification methods that supports algorithm selection is not available yet. in this work, we close this research gap by conducting a thorough empirical performance comparison of 24 different quantification methods on in total more than 40 datasets, considering binary as well as multiclass quantification settings. we observe that no single algorithm generally outperforms all competitors, but identify a group of methods that perform best in the binary setting, including the threshold selection-based median sweep and tsmax methods, the dys framework including the hdy method, forman’s mixture model, and friedman’s method. for the multiclass setting, we observe that a different, broad group of algorithms yields good performance, including the hdx method, the generalized probabilistic adjusted count, the readme method, the energy distance minimization method, the em algorithm for quantification, and friedman’s method. we also find that tuning the underlying classifiers has in most cases only a limited impact on the quantification performance. more generally, we find that the performance on multiclass quantification is inferior to the results obtained in the binary setting. our results can guide practitioners who intend to apply quantification algorithms and help researchers identify opportunities for future research.} {class distribution estimation,comparative evaluation,prevalence estimation,quantification,supervised machine learning} {class distribution estimation,comparative evaluation,prevalence estimation,quantification,supervised machine learning}', 'a comparative evaluation of quantification methods {quantification represents the problem of estimating the distribution of class labels on unseen data. it also represents a growing research field in supervised machine learning, for which a large variety of different algorithms has been proposed in recent years. however, a comprehensive empirical comparison of quantification methods that supports algorithm selection is not available yet. in this work, we close this research gap by conducting a thorough empirical performance comparison of 24 different quantification methods on in total more than 40 datasets, considering binary as well as multiclass quantification settings. we observe that no single algorithm generally outperforms all competitors, but identify a group of methods that perform best in the binary setting, including the threshold selection-based median sweep and tsmax methods, the dys framework including the hdy method, forman’s mixture model, and friedman’s method. for the multiclass setting, we observe that a different, broad group of algorithms yields good performance, including the hdx method, the generalized probabilistic adjusted count, the readme method, the energy distance minimization method, the em algorithm for quantification, and friedman’s method. we also find that tuning the underlying classifiers has in most cases only a limited impact on the quantification performance. more generally, we find that the performance on multiclass quantification is inferior to the results obtained in the binary setting. our results can guide practitioners who intend to apply quantification algorithms and help researchers identify opportunities for future research.} {class distribution estimation,comparative evaluation,prevalence estimation,quantification,supervised machine learning} {class distribution estimation,comparative evaluation,prevalence estimation,quantification,supervised machine learning}']"
41,13,41_learning models_entities_task_energy,"['learning models', 'entities', 'task', 'energy', 'citizenship']","[""tracing architecture of machine learning models through their mentions in scholarly articles {relation extraction, is a pivotal task in nlp, impacts information retrieval, natural language understanding (nlu) and knowledge generation. machine learning model has coined itself as the most influential term in this era of deep learning and llm. in scientific text how machine learning models relate with other key entities, holds always a quintessentially interesting topic. knowing the origins of machine learning model in terms of their architecture open a crucial tunnel of understanding towards its characteristics. in this paper we experiment on tracing the machine learning model architecture of the machine learning models from their mentions in scholarly texts. we attack this problem in supervised approach; first we identify multiple machine learning model oriented entities present in a sentence and then figure out if each of such entities are based on another such entity through binary ('based on' and other relation) classification task. we report our findings with four state of the art baseline models. the findings report here exemplary performance with luke model as winner. the presence of 'based on' relation has quite low evidence support, which effected the performance result of the models, which inspire for further explorations for improvement.} {baseline,extraction,machine learning model,machine learning model architecture,relation} {baseline,extraction,machine learning model,machine learning model architecture,relation}"", ""tracing architecture of machine learning models through their mentions in scholarly articles {relation extraction, is a pivotal task in nlp, impacts information retrieval, natural language understanding (nlu) and knowledge generation. machine learning model has coined itself as the most influential term in this era of deep learning and llm. in scientific text how machine learning models relate with other key entities, holds always a quintessentially interesting topic. knowing the origins of machine learning model in terms of their architecture open a crucial tunnel of understanding towards its characteristics. in this paper we experiment on tracing the machine learning model architecture of the machine learning models from their mentions in scholarly texts. we attack this problem in supervised approach; first we identify multiple machine learning model oriented entities present in a sentence and then figure out if each of such entities are based on another such entity through binary ('based on' and other relation) classification task. we report our findings with four state of the art baseline models. the findings report here exemplary performance with luke model as winner. the presence of 'based on' relation has quite low evidence support, which effected the performance result of the models, which inspire for further explorations for improvement.} {baseline,extraction,machine learning model,machine learning model architecture,relation} {baseline,extraction,machine learning model,machine learning model architecture,relation}"", ""tracing architecture of machine learning models through their mentions in scholarly articles {relation extraction, is a pivotal task in nlp, impacts information retrieval, natural language understanding (nlu) and knowledge generation. machine learning model has coined itself as the most influential term in this era of deep learning and llm. in scientific text how machine learning models relate with other key entities, holds always a quintessentially interesting topic. knowing the origins of machine learning model in terms of their architecture open a crucial tunnel of understanding towards its characteristics. in this paper we experiment on tracing the machine learning model architecture of the machine learning models from their mentions in scholarly texts. we attack this problem in supervised approach; first we identify multiple machine learning model oriented entities present in a sentence and then figure out if each of such entities are based on another such entity through binary ('based on' and other relation) classification task. we report our findings with four state of the art baseline models. the findings report here exemplary performance with luke model as winner. the presence of 'based on' relation has quite low evidence support, which effected the performance result of the models, which inspire for further explorations for improvement.} {baseline,extraction,machine learning model,machine learning model architecture,relation} {baseline,extraction,machine learning model,machine learning model architecture,relation}""]"
42,13,42_workshop_retrieval_event_natural language processing,"['workshop', 'retrieval', 'event', 'natural language processing', 'digital']","['bibliometric-enhanced information retrieval: 13th international bir workshop (bir 2023) {the 13th iteration of the bibliometric-enhanced information retrieval (bir) workshop series will take place at ecir 2023 as a full-day workshop. bir tackles issues related to, for instance, academic search and recommendation, at the intersection of information retrieval, natural language processing, and bibliometrics. as an interdisciplinary scientific event, bir brings together researchers and practitioners from the scientometrics/bibliometrics community on the one hand, and the information retrieval community on the other hand. bir is an ever-growing topic investigated by both academia and the industry.} {academic search,bibliometrics,digital libraries,information retrieval,scientometrics} {academic search,bibliometrics,digital libraries,information retrieval,scientometrics}', 'the first workshop on scholarly information access (scolia) {the first workshop on scholarly information access (scolia) will take place at ecir 2025 as a half-day workshop. the workshop is building upon and following up on the long series of the bibliometric-enhanced information retrieval (bir) workshops at ecir. scolia addresses research topics related to academic search and recommendation, at the intersection of information retrieval, natural language processing (including generative ai), and bibliometrics. as an interdisciplinary and intersectoral scientific event, addressing an ever-growing topic investigated by both academia and industry, scolia brings together researchers and practitioners from the aforementioned communities. the interactive format fosters engagement of all participants and fruitful discussions. the outcome of the workshop will reflect the current state and identify future research questions.} {academic search,bibliometrics,digital libraries,information access,information retrieval,natural language processing} {academic search,bibliometrics,digital libraries,information access,information retrieval,natural language processing}', 'the first workshop on scholarly information access (scolia) {the first workshop on scholarly information access (scolia) will take place at ecir 2025 as a half-day workshop. the workshop is building upon and following up on the long series of the bibliometric-enhanced information retrieval (bir) workshops at ecir. scolia addresses research topics related to academic search and recommendation, at the intersection of information retrieval, natural language processing (including generative ai), and bibliometrics. as an interdisciplinary and intersectoral scientific event, addressing an ever-growing topic investigated by both academia and industry, scolia brings together researchers and practitioners from the aforementioned communities. the interactive format fosters engagement of all participants and fruitful discussions. the outcome of the workshop will reflect the current state and identify future research questions.} {academic search,bibliometrics,digital libraries,information access,information retrieval,natural language processing} {academic search,bibliometrics,digital libraries,information access,information retrieval,natural language processing}']"
43,12,43_interviewer_mixed mode_concurrent_self administered,"['interviewer', 'mixed mode', 'concurrent', 'self administered', 'rates']","['sequential and concurrent mixed-mode designs: a tailored approach {due to rising costs and declining response rates, surveys are increasingly moving from face-to-face interviewing to a self-administered mixed-mode design. mixed-mode surveys can be conducted using a concurrent or a sequential design. a sequential design in which the web mode is offered first is a common strategy for mixed-mode surveys as it reduces survey costs. however, when deciding which mode choice sequence to use, sample balance should also be considered. one approach to achieving a balanced sample might be to tailor the sequence of the choice of modes, or the mode choice sequence. for this purpose, we use an indicator that assigns the sampled persons to the different mode choice sequences to minimize the variability of response probabilities. in this study, we compare the sample composition achieved with a concurrent and a sequential design. additionally, we investigate whether indicator-based tailoring of the two mode choice sequences can improve sample composition. we implemented a randomized experiment in the 2021 german general social survey (allbus), which surveyed the general population aged 18 and older in private households (n 5,342) using a mixed-mode design (web and mail). in a first step, respondents were randomly assigned to a concurrent or a sequential design. we find that the two mode choice sequences lead to a similar sample composition. next, we identify age as the best available single indicator of the variables known before the survey to tailor the mode choice sequence. our analyses show that a tailored approach based on age improves the sample composition slightly.}', 'sequential and concurrent mixed-mode designs: a tailored approach {due to rising costs and declining response rates, surveys are increasingly moving from face-to-face interviewing to a self-administered mixed-mode design. mixed-mode surveys can be conducted using a concurrent or a sequential design. a sequential design in which the web mode is offered first is a common strategy for mixed-mode surveys as it reduces survey costs. however, when deciding which mode choice sequence to use, sample balance should also be considered. one approach to achieving a balanced sample might be to tailor the sequence of the choice of modes, or the mode choice sequence. for this purpose, we use an indicator that assigns the sampled persons to the different mode choice sequences to minimize the variability of response probabilities. in this study, we compare the sample composition achieved with a concurrent and a sequential design. additionally, we investigate whether indicator-based tailoring of the two mode choice sequences can improve sample composition. we implemented a randomized experiment in the 2021 german general social survey (allbus), which surveyed the general population aged 18 and older in private households (n 5,342) using a mixed-mode design (web and mail). in a first step, respondents were randomly assigned to a concurrent or a sequential design. we find that the two mode choice sequences lead to a similar sample composition. next, we identify age as the best available single indicator of the variables known before the survey to tailor the mode choice sequence. our analyses show that a tailored approach based on age improves the sample composition slightly.}', 'sequential and concurrent mixed-mode designs: a tailored approach {due to rising costs and declining response rates, surveys are increasingly moving from face-to-face interviewing to a self-administered mixed-mode design. mixed-mode surveys can be conducted using a concurrent or a sequential design. a sequential design in which the web mode is offered first is a common strategy for mixed-mode surveys as it reduces survey costs. however, when deciding which mode choice sequence to use, sample balance should also be considered. one approach to achieving a balanced sample might be to tailor the sequence of the choice of modes, or the mode choice sequence. for this purpose, we use an indicator that assigns the sampled persons to the different mode choice sequences to minimize the variability of response probabilities. in this study, we compare the sample composition achieved with a concurrent and a sequential design. additionally, we investigate whether indicator-based tailoring of the two mode choice sequences can improve sample composition. we implemented a randomized experiment in the 2021 german general social survey (allbus), which surveyed the general population aged 18 and older in private households (n 5,342) using a mixed-mode design (web and mail). in a first step, respondents were randomly assigned to a concurrent or a sequential design. we find that the two mode choice sequences lead to a similar sample composition. next, we identify age as the best available single indicator of the variables known before the survey to tailor the mode choice sequence. our analyses show that a tailored approach based on age improves the sample composition slightly.}']"
44,12,44_exposure_time_computational social science_web tracking,"['exposure', 'time', 'computational social science', 'web tracking', 'registration']","['analysis of web browsing data: a guide {the use of individual-level browsing data, that is, the records of a person’s visits to online content through a desktop or mobile browser, is of increasing importance for social scientists. browsing data have characteristics that raise many questions for statistical analysis, yet to date, little hands-on guidance on how to handle them exists. reviewing extant research, and exploring data sets collected by our four research teams spanning seven countries and several years, with over 14,000 participants and 360 million web visits, we derive recommendations along four steps: preprocessing the raw data; filtering out observations; classifying web visits; and modelling browsing behavior. the recommendations we formulate aim to foster best practices in the field, which so far has paid little attention to justifying the many decisions researchers need to take when analyzing web browsing data.} {computational social science,digital trace data,web browsing data,web tracking data} {computational social science,digital trace data,web browsing data,web tracking data}', 'analysis of web browsing data: a guide {the use of individual-level browsing data, that is, the records of a person’s visits to online content through a desktop or mobile browser, is of increasing importance for social scientists. browsing data have characteristics that raise many questions for statistical analysis, yet to date, little hands-on guidance on how to handle them exists. reviewing extant research, and exploring data sets collected by our four research teams spanning seven countries and several years, with over 14,000 participants and 360 million web visits, we derive recommendations along four steps: preprocessing the raw data; filtering out observations; classifying web visits; and modelling browsing behavior. the recommendations we formulate aim to foster best practices in the field, which so far has paid little attention to justifying the many decisions researchers need to take when analyzing web browsing data.} {computational social science,digital trace data,web browsing data,web tracking data} {computational social science,digital trace data,web browsing data,web tracking data}', 'analysis of web browsing data: a guide {the use of individual-level browsing data, that is, the records of a person’s visits to online content through a desktop or mobile browser, is of increasing importance for social scientists. browsing data have characteristics that raise many questions for statistical analysis, yet to date, little hands-on guidance on how to handle them exists. reviewing extant research, and exploring data sets collected by our four research teams spanning seven countries and several years, with over 14,000 participants and 360 million web visits, we derive recommendations along four steps: preprocessing the raw data; filtering out observations; classifying web visits; and modelling browsing behavior. the recommendations we formulate aim to foster best practices in the field, which so far has paid little attention to justifying the many decisions researchers need to take when analyzing web browsing data.} {computational social science,digital trace data,web browsing data,web tracking data} {computational social science,digital trace data,web browsing data,web tracking data}']"
45,11,45_privacy_media_credibility_ethnic,"['privacy', 'media', 'credibility', 'ethnic', 'perspective']","['improving media trust research through better measurement: an item response theory perspective {while trust in news media has come to the forefront of scholarly and public debate in recent years, academic researchers have raised persistent concern that measurement issues have prevented a better understanding of the concept. this research introduces an item response theory (irt) perspective to advance the state-of-the-art in media trust measurement beyond recent conceptual and analytical progress. i argue that standard survey instruments that concentrate on the perceived believability of news media restrict our capability to measure truly low media trust. furthermore, i suggest an important yet previously unnoticed pathway to overcoming this restriction in a scale by abdulla et al. that captures currency perceptions alongside believability perceptions. using a representative survey conducted in germany, i find robust empirical evidence that capturing currency vs. believability perceptions significantly impacts our ability to accurately measure lower vs. higher levels of media trust. the findings have implications for not only studies of media trust’s associations with antecedent and consequential constructs but any attempt to determine the true amount and divergence of citizens’ media trust. more generally, the results demonstrate how irt aids in putting scholarly debates on the dimensionality and interplay of trust with distrust on more common and fruitful grounds.} {confirmatory item factor analysis,item response theory,measurement,media trust,news credibility,news media,survey research} {confirmatory item factor analysis,item response theory,measurement,media trust,news credibility,news media,survey research}', 'improving media trust research through better measurement: an item response theory perspective {while trust in news media has come to the forefront of scholarly and public debate in recent years, academic researchers have raised persistent concern that measurement issues have prevented a better understanding of the concept. this research introduces an item response theory (irt) perspective to advance the state-of-the-art in media trust measurement beyond recent conceptual and analytical progress. i argue that standard survey instruments that concentrate on the perceived believability of news media restrict our capability to measure truly low media trust. furthermore, i suggest an important yet previously unnoticed pathway to overcoming this restriction in a scale by abdulla et al. that captures currency perceptions alongside believability perceptions. using a representative survey conducted in germany, i find robust empirical evidence that capturing currency vs. believability perceptions significantly impacts our ability to accurately measure lower vs. higher levels of media trust. the findings have implications for not only studies of media trust’s associations with antecedent and consequential constructs but any attempt to determine the true amount and divergence of citizens’ media trust. more generally, the results demonstrate how irt aids in putting scholarly debates on the dimensionality and interplay of trust with distrust on more common and fruitful grounds.} {confirmatory item factor analysis,item response theory,measurement,media trust,news credibility,news media,survey research} {confirmatory item factor analysis,item response theory,measurement,media trust,news credibility,news media,survey research}', 'improving media trust research through better measurement: an item response theory perspective {while trust in news media has come to the forefront of scholarly and public debate in recent years, academic researchers have raised persistent concern that measurement issues have prevented a better understanding of the concept. this research introduces an item response theory (irt) perspective to advance the state-of-the-art in media trust measurement beyond recent conceptual and analytical progress. i argue that standard survey instruments that concentrate on the perceived believability of news media restrict our capability to measure truly low media trust. furthermore, i suggest an important yet previously unnoticed pathway to overcoming this restriction in a scale by abdulla et al. that captures currency perceptions alongside believability perceptions. using a representative survey conducted in germany, i find robust empirical evidence that capturing currency vs. believability perceptions significantly impacts our ability to accurately measure lower vs. higher levels of media trust. the findings have implications for not only studies of media trust’s associations with antecedent and consequential constructs but any attempt to determine the true amount and divergence of citizens’ media trust. more generally, the results demonstrate how irt aids in putting scholarly debates on the dimensionality and interplay of trust with distrust on more common and fruitful grounds.} {confirmatory item factor analysis,item response theory,measurement,media trust,news credibility,news media,survey research} {confirmatory item factor analysis,item response theory,measurement,media trust,news credibility,news media,survey research}']"
46,11,46_language models_training_computer_zero,"['language models', 'training', 'computer', 'zero', 'benchmarks']","['evaluating language models for computer graphics code completion {evaluation benchmarks are essential for developing and training language models, providing both comparison and optimization targets. existing code completion benchmarks, often based on standalone python functions and unit tests, are overly simplistic, contaminated, and fail to reflect real-world scenarios. in this paper we present shadermatch, a novel benchmark for code completion in computer graphics programming. the benchmark is derived from real-world fragment shaders in opengl shading language (glsl) from the shadertoy platform, forming a zero-shot function completion task with 467 function headers and user-written comments as input. besides, we propose a two-step evaluation metric: static code comparison followed by frame rendering comparison. additionally, shadermatch introduces eight fine-grained labels for deeper insights. we evaluate over 20 open-source code-specific models and highlight notable performance outliers. results show that even top models fail to generate working code in 31% of cases, highlighting the challenge posed by glsl, a low-resource language rarely found in pretraining datasets. shadermatch provides a well-annotated, extendable dataset for future research. data, code, leaderboard, and discussions are available at: https://hf.co/spaces/vipitis/shadermatch.} {benchmarking,code completion,fragment shaders,glsl,language models,opengl shading language} {benchmarking,code completion,fragment shaders,glsl,language models,opengl shading language}', 'evaluating language models for computer graphics code completion {evaluation benchmarks are essential for developing and training language models, providing both comparison and optimization targets. existing code completion benchmarks, often based on standalone python functions and unit tests, are overly simplistic, contaminated, and fail to reflect real-world scenarios. in this paper we present shadermatch, a novel benchmark for code completion in computer graphics programming. the benchmark is derived from real-world fragment shaders in opengl shading language (glsl) from the shadertoy platform, forming a zero-shot function completion task with 467 function headers and user-written comments as input. besides, we propose a two-step evaluation metric: static code comparison followed by frame rendering comparison. additionally, shadermatch introduces eight fine-grained labels for deeper insights. we evaluate over 20 open-source code-specific models and highlight notable performance outliers. results show that even top models fail to generate working code in 31% of cases, highlighting the challenge posed by glsl, a low-resource language rarely found in pretraining datasets. shadermatch provides a well-annotated, extendable dataset for future research. data, code, leaderboard, and discussions are available at: https://hf.co/spaces/vipitis/shadermatch.} {benchmarking,code completion,fragment shaders,glsl,language models,opengl shading language} {benchmarking,code completion,fragment shaders,glsl,language models,opengl shading language}', 'evaluating language models for computer graphics code completion {evaluation benchmarks are essential for developing and training language models, providing both comparison and optimization targets. existing code completion benchmarks, often based on standalone python functions and unit tests, are overly simplistic, contaminated, and fail to reflect real-world scenarios. in this paper we present shadermatch, a novel benchmark for code completion in computer graphics programming. the benchmark is derived from real-world fragment shaders in opengl shading language (glsl) from the shadertoy platform, forming a zero-shot function completion task with 467 function headers and user-written comments as input. besides, we propose a two-step evaluation metric: static code comparison followed by frame rendering comparison. additionally, shadermatch introduces eight fine-grained labels for deeper insights. we evaluate over 20 open-source code-specific models and highlight notable performance outliers. results show that even top models fail to generate working code in 31% of cases, highlighting the challenge posed by glsl, a low-resource language rarely found in pretraining datasets. shadermatch provides a well-annotated, extendable dataset for future research. data, code, leaderboard, and discussions are available at: https://hf.co/spaces/vipitis/shadermatch.} {benchmarking,code completion,fragment shaders,glsl,language models,opengl shading language} {benchmarking,code completion,fragment shaders,glsl,language models,opengl shading language}']"
47,11,47_panel_mixed mode_labor_attitudes,"['panel', 'mixed mode', 'labor', 'attitudes', 'interviewer']","['the impact of survey mode design and questionnaire length on measurement quality {mixed-mode surveys are popular as they can save costs and maintain (or improve) response rates relative to single-mode surveys. nevertheless, it is not yet clear how design decisions like survey mode or questionnaire length impact measurement quality. in this study, we compare measurement quality in an experiment of three distinct survey designs implemented in the german sample of the european values study: a single-mode face-to-face design, a mixed-mode mail/web design, and a shorter (matrix) questionnaire in the mixed-mode design. we compare measurement quality in different ways, including differences in distributions across several data quality indicators as well as equivalence testing over 140 items in 25 attitudinal scales. we find similar data quality across the survey designs, although the mixed-mode survey shows more item nonresponse compared to the single-mode survey. using equivalence testing we find that most scales achieve metric equivalence and, to a lesser extent, scalar equivalence across the designs.} {data quality,matrix sampling,measurement invariance,mixed-mode survey,split questionnaire} {data quality,matrix sampling,measurement invariance,mixed-mode survey,split questionnaire}', 'effects of partner presence during the interview on survey responses: the example of questions concerning the division of household labor {despite the fact that third parties are present during a substantial amount of face-to-face interviews, bystander influence on respondents’ response behavior is not yet fully understood. we use nine waves of the german family panel pairfam and apply fixed effects panel regression models to analyze effects of third-party presence on items regarding the sharing of household tasks between partners. we find that both male and female respondents report doing a smaller share of household tasks when their partner is present during the interview as compared to when their partner is not present. similarly, if the respondent’s partner is present, both partners’ reports correspond more, so that they are less prone to resulting in unrealistically high sums. these results indicate that for items concerning household labor, partner presence does not compromise data quality but may in fact improve it.} {bystander effects,division of housework,division of labor,interview privacy,spouse presence,third-party presence} {bystander effects,division of housework,division of labor,interview privacy,spouse presence,third-party presence}', 'effects of partner presence during the interview on survey responses: the example of questions concerning the division of household labor {despite the fact that third parties are present during a substantial amount of face-to-face interviews, bystander influence on respondents’ response behavior is not yet fully understood. we use nine waves of the german family panel pairfam and apply fixed effects panel regression models to analyze effects of third-party presence on items regarding the sharing of household tasks between partners. we find that both male and female respondents report doing a smaller share of household tasks when their partner is present during the interview as compared to when their partner is not present. similarly, if the respondent’s partner is present, both partners’ reports correspond more, so that they are less prone to resulting in unrealistically high sums. these results indicate that for items concerning household labor, partner presence does not compromise data quality but may in fact improve it.} {bystander effects,division of housework,division of labor,interview privacy,spouse presence,third-party presence} {bystander effects,division of housework,division of labor,interview privacy,spouse presence,third-party presence}']"
48,11,48_profile_web tracking_germany_heterogeneous,"['profile', 'web tracking', 'germany', 'heterogeneous', 'health related']","['uncovering latent profiles of ict self-concept among adults in germany and their relation with gender {self-concept related to the use of information and communication technology (ict-sc) is reflected in how people feel and behave when confronted with digital technologies. although evidence from variable-centered analyses suggests a hierarchical and multidimensional structure of ict-sc in heterogeneous populations, it is not yet known whether different profiles of general ict-sc and specific ict-sc domains (communicate, process and store, generate content, safe application, solve problems) exist. this study aims to extend previous research using person-centered analyses and to examine whether different profiles of ict-sc can be identified in a heterogeneous adult population (18–69 years) from germany and how these profiles relate to gender. results of a latent profile analysis (german quota sample, n = 369) indicate a reliable three-profile solution. profile i (n = 48) is characterised by rather low ict-sc with relative profile strengths in the verbal-interactive domains (communicate, process and store). profile ii (n = 149) is characterised by low to average ict-sc across ict-sc domains. profile iii (n = 172) is characterised by high ict-sc with profile strengths in the technical-analytical domains (safe application, solve problems). gender did not correlate significantly with profile membership. we discuss the practical implications of the results for ict-sc interventions and suggest directions for future research.} {digcomp,gender differences,ict competence,ict self-concept,latent profile analysis} {digcomp,gender differences,ict competence,ict self-concept,latent profile analysis}', 'uncovering latent profiles of ict self-concept among adults in germany and their relation with gender {self-concept related to the use of information and communication technology (ict-sc) is reflected in how people feel and behave when confronted with digital technologies. although evidence from variable-centered analyses suggests a hierarchical and multidimensional structure of ict-sc in heterogeneous populations, it is not yet known whether different profiles of general ict-sc and specific ict-sc domains (communicate, process and store, generate content, safe application, solve problems) exist. this study aims to extend previous research using person-centered analyses and to examine whether different profiles of ict-sc can be identified in a heterogeneous adult population (18–69 years) from germany and how these profiles relate to gender. results of a latent profile analysis (german quota sample, n = 369) indicate a reliable three-profile solution. profile i (n = 48) is characterised by rather low ict-sc with relative profile strengths in the verbal-interactive domains (communicate, process and store). profile ii (n = 149) is characterised by low to average ict-sc across ict-sc domains. profile iii (n = 172) is characterised by high ict-sc with profile strengths in the technical-analytical domains (safe application, solve problems). gender did not correlate significantly with profile membership. we discuss the practical implications of the results for ict-sc interventions and suggest directions for future research.} {digcomp,gender differences,ict competence,ict self-concept,latent profile analysis} {digcomp,gender differences,ict competence,ict self-concept,latent profile analysis}', 'uncovering latent profiles of ict self-concept among adults in germany and their relation with gender {self-concept related to the use of information and communication technology (ict-sc) is reflected in how people feel and behave when confronted with digital technologies. although evidence from variable-centered analyses suggests a hierarchical and multidimensional structure of ict-sc in heterogeneous populations, it is not yet known whether different profiles of general ict-sc and specific ict-sc domains (communicate, process and store, generate content, safe application, solve problems) exist. this study aims to extend previous research using person-centered analyses and to examine whether different profiles of ict-sc can be identified in a heterogeneous adult population (18–69 years) from germany and how these profiles relate to gender. results of a latent profile analysis (german quota sample, n = 369) indicate a reliable three-profile solution. profile i (n = 48) is characterised by rather low ict-sc with relative profile strengths in the verbal-interactive domains (communicate, process and store). profile ii (n = 149) is characterised by low to average ict-sc across ict-sc domains. profile iii (n = 172) is characterised by high ict-sc with profile strengths in the technical-analytical domains (safe application, solve problems). gender did not correlate significantly with profile membership. we discuss the practical implications of the results for ict-sc interventions and suggest directions for future research.} {digcomp,gender differences,ict competence,ict self-concept,latent profile analysis} {digcomp,gender differences,ict competence,ict self-concept,latent profile analysis}']"
49,11,49_search engines_familiarity_political science_open science,"['search engines', 'familiarity', 'political science', 'open science', 'transformer']","['novelty in news search: a longitudinal study of the 2020 us elections {the 2020 us elections news coverage was extensive, with new pieces of information generated rapidly. this evolving scenario presented an opportunity to study the performance of search engines in a context in which they had to quickly process information as it was published. we analyze novelty, a measurement of new items that emerge in the top news search results, to compare the coverage and visibility of different topics. using virtual agents that simulate human web browsing behavior to collect search engine result pages, we conduct a longitudinal study of news results of five search engines collected in short bursts (every 21 minutes) from two regions (oregon, us and frankfurt, germany), starting on election day and lasting until one day after the announcement of biden as the winner. we find more new items emerging for election related queries (“joe biden,” “donald trump,” and “us elections”) compared to topical (e.g., “coronavirus”) or stable (e.g., “holocaust”) queries. we demonstrate that our method captures sudden changes in highly covered news topics as well as multiple differences across search engines and regions over time. we highlight novelty imbalances between candidate queries which affect their visibility during electoral periods, and conclude that, when it comes to news, search engines are responsible for such imbalances, either due to their algorithms or the set of news sources that they rely on.}', 'novelty in news search: a longitudinal study of the 2020 us elections {the 2020 us elections news coverage was extensive, with new pieces of information generated rapidly. this evolving scenario presented an opportunity to study the performance of search engines in a context in which they had to quickly process information as it was published. we analyze novelty, a measurement of new items that emerge in the top news search results, to compare the coverage and visibility of different topics. using virtual agents that simulate human web browsing behavior to collect search engine result pages, we conduct a longitudinal study of news results of five search engines collected in short bursts (every 21 minutes) from two regions (oregon, us and frankfurt, germany), starting on election day and lasting until one day after the announcement of biden as the winner. we find more new items emerging for election related queries (“joe biden,” “donald trump,” and “us elections”) compared to topical (e.g., “coronavirus”) or stable (e.g., “holocaust”) queries. we demonstrate that our method captures sudden changes in highly covered news topics as well as multiple differences across search engines and regions over time. we highlight novelty imbalances between candidate queries which affect their visibility during electoral periods, and conclude that, when it comes to news, search engines are responsible for such imbalances, either due to their algorithms or the set of news sources that they rely on.}', 'novelty in news search: a longitudinal study of the 2020 us elections {the 2020 us elections news coverage was extensive, with new pieces of information generated rapidly. this evolving scenario presented an opportunity to study the performance of search engines in a context in which they had to quickly process information as it was published. we analyze novelty, a measurement of new items that emerge in the top news search results, to compare the coverage and visibility of different topics. using virtual agents that simulate human web browsing behavior to collect search engine result pages, we conduct a longitudinal study of news results of five search engines collected in short bursts (every 21 minutes) from two regions (oregon, us and frankfurt, germany), starting on election day and lasting until one day after the announcement of biden as the winner. we find more new items emerging for election related queries (“joe biden,” “donald trump,” and “us elections”) compared to topical (e.g., “coronavirus”) or stable (e.g., “holocaust”) queries. we demonstrate that our method captures sudden changes in highly covered news topics as well as multiple differences across search engines and regions over time. we highlight novelty imbalances between candidate queries which affect their visibility during electoral periods, and conclude that, when it comes to news, search engines are responsible for such imbalances, either due to their algorithms or the set of news sources that they rely on.}']"
50,11,50_democratic_competition_socio economic_germany,"['democratic', 'competition', 'socio economic', 'germany', 'vignette experiment']","['lip service to liberal democracy in western europe? {political scientists heavily rely on standard survey questions referring to “democracy” when they study citizens’ attitudes toward (liberal) democracy. however, we only know little about the way in which citizens respond to these questions. this article focuses on two frequently highlighted issues: social desirability and the consistency between citizens’ understanding and researchers’ understanding of the term “democracy.” to address these issues, i collected novel survey data via yougov from 14,000 british, french, german, and italian respondents. i use a list experiment to show that respondents do not feel socially pressured to misreport their support for democracy. however, what citizens have in mind when they claim to support democracy only reflects norms and institutions of minimal conceptions of democracy. overall, this encourages the usage of questions regarding citizens’ support for democracy widely, although this should not be interpreted as the support for anything going beyond minimal conceptions of democracy (providing freedom and allowing for citizens’ influence on political decisions).} {liberal democracy,list experiment,support for democracy,topic models,understandings of democracy} {liberal democracy,list experiment,support for democracy,topic models,understandings of democracy}', 'party competition over democracy: democracy as electoral issue in germany {elected leaders increasingly undermine liberal democratic institutions with the support of their voters, openly challenging liberal democratic institutions in election campaigns. however, political scientists thus far have lacked the theoretical and empirical tools to study the role of elections in democratic backsliding. this article theorizes the degree to which democracy in general and liberal democracy more specifically can and should be conceptualized as valence and positional issues in multiparty electoral competitions of established liberal democracies. by investigating how german citizens and parties of the postwar period spoke about democracy per se and liberal democracy in their regional and national election manifestos, this article shows that democracy per se and liberal democracy, in particular, have been issues of different qualities in german postwar elections. while parties have used references to democracy in general as a mixed issue, showing both signs of valence and positional issues, parties’ emphasis on liberal democracy is shaped by a positional logic. social and direct democracy have also been positional issues. studying democracy and its various conceptions as electoral issues will help us address many important questions concerning the stability of democracies, shifting researchers’ focus to the competition of parties over citizens’ support for reforms that undermine or stabilize liberal democracy.} {direct democracy,germany,liberal democracy,party competition,positional issues,social democracy,valence issues} {direct democracy,germany,liberal democracy,party competition,positional issues,social democracy,valence issues}', 'party competition over democracy: democracy as electoral issue in germany {elected leaders increasingly undermine liberal democratic institutions with the support of their voters, openly challenging liberal democratic institutions in election campaigns. however, political scientists thus far have lacked the theoretical and empirical tools to study the role of elections in democratic backsliding. this article theorizes the degree to which democracy in general and liberal democracy more specifically can and should be conceptualized as valence and positional issues in multiparty electoral competitions of established liberal democracies. by investigating how german citizens and parties of the postwar period spoke about democracy per se and liberal democracy in their regional and national election manifestos, this article shows that democracy per se and liberal democracy, in particular, have been issues of different qualities in german postwar elections. while parties have used references to democracy in general as a mixed issue, showing both signs of valence and positional issues, parties’ emphasis on liberal democracy is shaped by a positional logic. social and direct democracy have also been positional issues. studying democracy and its various conceptions as electoral issues will help us address many important questions concerning the stability of democracies, shifting researchers’ focus to the competition of parties over citizens’ support for reforms that undermine or stabilize liberal democracy.} {direct democracy,germany,liberal democracy,party competition,positional issues,social democracy,valence issues} {direct democracy,germany,liberal democracy,party competition,positional issues,social democracy,valence issues}']"
51,11,51_tweets_polarization_argument mining_network,"['tweets', 'polarization', 'argument mining', 'network', 'classifier']","[""taco - twitter arguments from conversations {twitter has emerged as a global hub for engaging in online conversations and as a research corpus for various disciplines that have recognized the significance of its user-generated content. argument mining is an important analytical task for processing and understanding online discourse. specifically, it aims to identify the structural elements of arguments, denoted as information and inference. these elements, however, are not static and may require context within the conversation they are in, yet there is a lack of data and annotation frameworks addressing this dynamic aspect on twitter. we contribute taco, the first dataset of twitter arguments utilizing 1,814 tweets covering 200 entire conversations spanning six heterogeneous topics annotated with an agreement of 0.718 krippendorff's α among six experts. second, we provide our annotation framework, incorporating definitions from the cambridge dictionary, to define and identify argument components on twitter. our transformer-based classifier achieves an 85.06% macro f1 baseline score in detecting arguments. moreover, our data reveals that twitter users tend to engage in discussions involving informed inferences and information. taco serves multiple purposes, such as training tweet classifiers to manage tweets based on inference and information elements, while also providing valuable insights into the conversational reply patterns of tweets.} {argument mining,inference,information extraction,resource,twitter conversations} {argument mining,inference,information extraction,resource,twitter conversations}"", ""taco - twitter arguments from conversations {twitter has emerged as a global hub for engaging in online conversations and as a research corpus for various disciplines that have recognized the significance of its user-generated content. argument mining is an important analytical task for processing and understanding online discourse. specifically, it aims to identify the structural elements of arguments, denoted as information and inference. these elements, however, are not static and may require context within the conversation they are in, yet there is a lack of data and annotation frameworks addressing this dynamic aspect on twitter. we contribute taco, the first dataset of twitter arguments utilizing 1,814 tweets covering 200 entire conversations spanning six heterogeneous topics annotated with an agreement of 0.718 krippendorff's α among six experts. second, we provide our annotation framework, incorporating definitions from the cambridge dictionary, to define and identify argument components on twitter. our transformer-based classifier achieves an 85.06% macro f1 baseline score in detecting arguments. moreover, our data reveals that twitter users tend to engage in discussions involving informed inferences and information. taco serves multiple purposes, such as training tweet classifiers to manage tweets based on inference and information elements, while also providing valuable insights into the conversational reply patterns of tweets.} {argument mining,inference,information extraction,resource,twitter conversations} {argument mining,inference,information extraction,resource,twitter conversations}"", ""taco - twitter arguments from conversations {twitter has emerged as a global hub for engaging in online conversations and as a research corpus for various disciplines that have recognized the significance of its user-generated content. argument mining is an important analytical task for processing and understanding online discourse. specifically, it aims to identify the structural elements of arguments, denoted as information and inference. these elements, however, are not static and may require context within the conversation they are in, yet there is a lack of data and annotation frameworks addressing this dynamic aspect on twitter. we contribute taco, the first dataset of twitter arguments utilizing 1,814 tweets covering 200 entire conversations spanning six heterogeneous topics annotated with an agreement of 0.718 krippendorff's α among six experts. second, we provide our annotation framework, incorporating definitions from the cambridge dictionary, to define and identify argument components on twitter. our transformer-based classifier achieves an 85.06% macro f1 baseline score in detecting arguments. moreover, our data reveals that twitter users tend to engage in discussions involving informed inferences and information. taco serves multiple purposes, such as training tweet classifiers to manage tweets based on inference and information elements, while also providing valuable insights into the conversational reply patterns of tweets.} {argument mining,inference,information extraction,resource,twitter conversations} {argument mining,inference,information extraction,resource,twitter conversations}""]"
