Topic,Count,Name,Representation,Representative_Docs
-1,79,-1_energy_political_moderation_network,"['energy', 'political', 'moderation', 'network', 'europe']","['united in disagreement: analyzing policy networks in eu policy making {shared belief systems are generally assumed to forge policy networks. empirical evidence whether and to what extend shared policy core beliefs create ally networks and under which circumstances shared policy core beliefs are not necessary to form these networks, however, is limited. based on a novel inferential network approach in combination with mediation analysis, this study investigates the role of belief systems as a link between interest group type and policy preference congruence, ultimately leading to ally networks in the european union. in order to measure the intervening effect of policy core beliefs, automated text analysis is used. our results suggest that shared policy core beliefs are a strong mediator for members of the same interest group. in addition, “strange bedfellow” networks between ngos and businesses do, in fact, lack belief congruence and emerge on issues with low potential for intergroup conflict. this paper makes a contribution to our understanding of ally network formation and adds to the emerging line of research which combines quantitative text with inferential network analysis.} {advocacy coalitions,automated text analysis,eu energy policy,inferential network analysis,interest groups} {advocacy coalitions,automated text analysis,eu energy policy,inferential network analysis,interest groups}', 'united in disagreement: analyzing policy networks in eu policy making {shared belief systems are generally assumed to forge policy networks. empirical evidence whether and to what extend shared policy core beliefs create ally networks and under which circumstances shared policy core beliefs are not necessary to form these networks, however, is limited. based on a novel inferential network approach in combination with mediation analysis, this study investigates the role of belief systems as a link between interest group type and policy preference congruence, ultimately leading to ally networks in the european union. in order to measure the intervening effect of policy core beliefs, automated text analysis is used. our results suggest that shared policy core beliefs are a strong mediator for members of the same interest group. in addition, “strange bedfellow” networks between ngos and businesses do, in fact, lack belief congruence and emerge on issues with low potential for intergroup conflict. this paper makes a contribution to our understanding of ally network formation and adds to the emerging line of research which combines quantitative text with inferential network analysis.} {advocacy coalitions,automated text analysis,eu energy policy,inferential network analysis,interest groups} {advocacy coalitions,automated text analysis,eu energy policy,inferential network analysis,interest groups}', 'united in disagreement: analyzing policy networks in eu policy making {shared belief systems are generally assumed to forge policy networks. empirical evidence whether and to what extend shared policy core beliefs create ally networks and under which circumstances shared policy core beliefs are not necessary to form these networks, however, is limited. based on a novel inferential network approach in combination with mediation analysis, this study investigates the role of belief systems as a link between interest group type and policy preference congruence, ultimately leading to ally networks in the european union. in order to measure the intervening effect of policy core beliefs, automated text analysis is used. our results suggest that shared policy core beliefs are a strong mediator for members of the same interest group. in addition, “strange bedfellow” networks between ngos and businesses do, in fact, lack belief congruence and emerge on issues with low potential for intergroup conflict. this paper makes a contribution to our understanding of ally network formation and adds to the emerging line of research which combines quantitative text with inferential network analysis.} {advocacy coalitions,automated text analysis,eu energy policy,inferential network analysis,interest groups} {advocacy coalitions,automated text analysis,eu energy policy,inferential network analysis,interest groups}']"
0,181,0_germany_migration_differences_personality,"['germany', 'migration', 'differences', 'personality', 'election']","['do social engagement skills exist and matter beyond personality facet traits and vocational interests? a generalization study across six countries {social engagement skills as capacities for active interpersonal engagement are thought to conceptually differ from behavioral and motivational tendencies and to predict learning and life outcomes. we tested these assumptions on the distinct nature and relevance of social engagement skills. quota-representative self-reports from 6987 adults in six countries showed strong relations of social engagement skills with personality facets and weaker with vocational interests. partially supporting their distinctiveness, social engagement skills were not fully reducible to those correlates. skills predicted self-reported learning, quality-of-life, and job outcomes, but offered little incremental validity beyond personality and interests. results largely generalized across countries. yet, the complex interplay between social engagement skills, individual differences, and outcomes demonstrated cross-country variations, suggesting sensitivity to sociocontextual factors. we conclude that while social engagement skills conceptually differ from personality and interests and in themselves predict life success, they add limited empirical value beyond these constructs, at least for self-reports. educational relevance statement: social engagement skills are the capacities to actively engage with others. it is thought that these capacities differ from other person characteristics (e.g., behavioral or motivational tendencies), and that this distinction matters for explaining life success. our study showed that while self-reported social engagement skills shared similarities with other person characteristics, they still had unique aspects. moreover, social engagement skills mattered, such that more skilled adults reported higher quality-of-life, but not necessarily better learning. however, social engagement skills did not provide much extra insight into life success beyond what was already known from other person characteristics. other than the remaining results, these complex relations between social engagement skills, person characteristics, and life success largely varied across countries. the results highlight the importance of assessing social skills in a situation-specific manner, which will be imperative for targeted educational practices in the future. moreover, our study focused on adults, limiting applicability to youth, but results suggest that intervention efforts targeting social engagement skills may probably yield more interpersonal than academic benefits. finally, when designing or adapting complex educational programs, practitioners should consider sociocontextual factors.} {cross-national data,individual differences,learning,life outcomes,social-emotional skills} {cross-national data,individual differences,learning,life outcomes,social-emotional skills}', 'do social engagement skills exist and matter beyond personality facet traits and vocational interests? a generalization study across six countries {social engagement skills as capacities for active interpersonal engagement are thought to conceptually differ from behavioral and motivational tendencies and to predict learning and life outcomes. we tested these assumptions on the distinct nature and relevance of social engagement skills. quota-representative self-reports from 6987 adults in six countries showed strong relations of social engagement skills with personality facets and weaker with vocational interests. partially supporting their distinctiveness, social engagement skills were not fully reducible to those correlates. skills predicted self-reported learning, quality-of-life, and job outcomes, but offered little incremental validity beyond personality and interests. results largely generalized across countries. yet, the complex interplay between social engagement skills, individual differences, and outcomes demonstrated cross-country variations, suggesting sensitivity to sociocontextual factors. we conclude that while social engagement skills conceptually differ from personality and interests and in themselves predict life success, they add limited empirical value beyond these constructs, at least for self-reports. educational relevance statement: social engagement skills are the capacities to actively engage with others. it is thought that these capacities differ from other person characteristics (e.g., behavioral or motivational tendencies), and that this distinction matters for explaining life success. our study showed that while self-reported social engagement skills shared similarities with other person characteristics, they still had unique aspects. moreover, social engagement skills mattered, such that more skilled adults reported higher quality-of-life, but not necessarily better learning. however, social engagement skills did not provide much extra insight into life success beyond what was already known from other person characteristics. other than the remaining results, these complex relations between social engagement skills, person characteristics, and life success largely varied across countries. the results highlight the importance of assessing social skills in a situation-specific manner, which will be imperative for targeted educational practices in the future. moreover, our study focused on adults, limiting applicability to youth, but results suggest that intervention efforts targeting social engagement skills may probably yield more interpersonal than academic benefits. finally, when designing or adapting complex educational programs, practitioners should consider sociocontextual factors.} {cross-national data,individual differences,learning,life outcomes,social-emotional skills} {cross-national data,individual differences,learning,life outcomes,social-emotional skills}', 'do social engagement skills exist and matter beyond personality facet traits and vocational interests? a generalization study across six countries {social engagement skills as capacities for active interpersonal engagement are thought to conceptually differ from behavioral and motivational tendencies and to predict learning and life outcomes. we tested these assumptions on the distinct nature and relevance of social engagement skills. quota-representative self-reports from 6987 adults in six countries showed strong relations of social engagement skills with personality facets and weaker with vocational interests. partially supporting their distinctiveness, social engagement skills were not fully reducible to those correlates. skills predicted self-reported learning, quality-of-life, and job outcomes, but offered little incremental validity beyond personality and interests. results largely generalized across countries. yet, the complex interplay between social engagement skills, individual differences, and outcomes demonstrated cross-country variations, suggesting sensitivity to sociocontextual factors. we conclude that while social engagement skills conceptually differ from personality and interests and in themselves predict life success, they add limited empirical value beyond these constructs, at least for self-reports. educational relevance statement: social engagement skills are the capacities to actively engage with others. it is thought that these capacities differ from other person characteristics (e.g., behavioral or motivational tendencies), and that this distinction matters for explaining life success. our study showed that while self-reported social engagement skills shared similarities with other person characteristics, they still had unique aspects. moreover, social engagement skills mattered, such that more skilled adults reported higher quality-of-life, but not necessarily better learning. however, social engagement skills did not provide much extra insight into life success beyond what was already known from other person characteristics. other than the remaining results, these complex relations between social engagement skills, person characteristics, and life success largely varied across countries. the results highlight the importance of assessing social skills in a situation-specific manner, which will be imperative for targeted educational practices in the future. moreover, our study focused on adults, limiting applicability to youth, but results suggest that intervention efforts targeting social engagement skills may probably yield more interpersonal than academic benefits. finally, when designing or adapting complex educational programs, practitioners should consider sociocontextual factors.} {cross-national data,individual differences,learning,life outcomes,social-emotional skills} {cross-national data,individual differences,learning,life outcomes,social-emotional skills}']"
1,50,1_machine learning_large language models_llms_mining,"['machine learning', 'large language models', 'llms', 'mining', 'errors']","['large language models as a substitute for human experts in annotating political text {large-scale text analysis has grown rapidly as a method in political science and beyond. to date, text-as-data methods rely on large volumes of human-annotated training examples, which place a premium on researcher resources. however, advances in large language models (llms) may make automated annotation increasingly viable. this paper tests the performance of gpt-4 across a range of scenarios relevant for analysis of political text. we compare gpt-4 coding with human expert coding of tweets and news articles across four variables (whether text is political, its negativity, its sentiment, and its ideology) and across four countries (the united states, chile, germany, and italy). gpt-4 coding is highly accurate, especially for shorter texts such as tweets, correctly classifying texts up to 95% of the time. performance drops for longer news articles, and very slightly for non-english text. we introduce a ‘hybrid’ coding approach, in which disagreements of multiple gpt-4 runs are adjudicated by a human expert, which boosts accuracy. finally, we explore downstream effects, finding that transformer models trained on hand-coded or gpt-4-coded data yield almost identical outcomes. our results suggest that llm-assisted coding is a viable and cost-efficient approach, although consideration should be given to task complexity.} {gpt,large language models,machine learning,text analysis,text-as-data} {gpt,large language models,machine learning,text analysis,text-as-data}', 'large language models as a substitute for human experts in annotating political text {large-scale text analysis has grown rapidly as a method in political science and beyond. to date, text-as-data methods rely on large volumes of human-annotated training examples, which place a premium on researcher resources. however, advances in large language models (llms) may make automated annotation increasingly viable. this paper tests the performance of gpt-4 across a range of scenarios relevant for analysis of political text. we compare gpt-4 coding with human expert coding of tweets and news articles across four variables (whether text is political, its negativity, its sentiment, and its ideology) and across four countries (the united states, chile, germany, and italy). gpt-4 coding is highly accurate, especially for shorter texts such as tweets, correctly classifying texts up to 95% of the time. performance drops for longer news articles, and very slightly for non-english text. we introduce a ‘hybrid’ coding approach, in which disagreements of multiple gpt-4 runs are adjudicated by a human expert, which boosts accuracy. finally, we explore downstream effects, finding that transformer models trained on hand-coded or gpt-4-coded data yield almost identical outcomes. our results suggest that llm-assisted coding is a viable and cost-efficient approach, although consideration should be given to task complexity.} {gpt,large language models,machine learning,text analysis,text-as-data} {gpt,large language models,machine learning,text analysis,text-as-data}', 'large language models as a substitute for human experts in annotating political text {large-scale text analysis has grown rapidly as a method in political science and beyond. to date, text-as-data methods rely on large volumes of human-annotated training examples, which place a premium on researcher resources. however, advances in large language models (llms) may make automated annotation increasingly viable. this paper tests the performance of gpt-4 across a range of scenarios relevant for analysis of political text. we compare gpt-4 coding with human expert coding of tweets and news articles across four variables (whether text is political, its negativity, its sentiment, and its ideology) and across four countries (the united states, chile, germany, and italy). gpt-4 coding is highly accurate, especially for shorter texts such as tweets, correctly classifying texts up to 95% of the time. performance drops for longer news articles, and very slightly for non-english text. we introduce a ‘hybrid’ coding approach, in which disagreements of multiple gpt-4 runs are adjudicated by a human expert, which boosts accuracy. finally, we explore downstream effects, finding that transformer models trained on hand-coded or gpt-4-coded data yield almost identical outcomes. our results suggest that llm-assisted coding is a viable and cost-efficient approach, although consideration should be given to task complexity.} {gpt,large language models,machine learning,text analysis,text-as-data} {gpt,large language models,machine learning,text analysis,text-as-data}']"
2,43,2_facebook_reliability_web browsing_tracking,"['facebook', 'reliability', 'web browsing', 'tracking', 'life']","['using google trends data to study high-frequency search terms: evidence for a reliability-frequency continuum {google trends (gt) data are increasingly used in the social sciences and adjacent fields. however, previous research on the quality of gt data has raised concerns regarding their reliability. in the present study, we investigated whether reliability differs between low- and high-frequency search terms. in other words, we explored the existence of a reliability-frequency continuum in gt data. our study adds to previous research by investigating a more comprehensive set of search terms and different aspects of reliability (e.g., differences in relative search volume distributions, correctly identified maxima). for this purpose, we collected samples of gt data for ten high- and two low-frequency search terms. we obtained one real-time sample and 62 non–realtime samples per search term (30 non–realtime samples for low-frequency search terms). data collection was restricted to search data for germany. our data support the existence of a reliability-frequency continuum—low-frequency search terms are subject to greater reliability issues compared to high-frequency search terms. based on our findings, we have derived practical recommendations for the use of gt data and have outlined future research opportunities.} {data quality,google trends data,reliability,sample stability,search engine data} {data quality,google trends data,reliability,sample stability,search engine data}', 'using google trends data to study high-frequency search terms: evidence for a reliability-frequency continuum {google trends (gt) data are increasingly used in the social sciences and adjacent fields. however, previous research on the quality of gt data has raised concerns regarding their reliability. in the present study, we investigated whether reliability differs between low- and high-frequency search terms. in other words, we explored the existence of a reliability-frequency continuum in gt data. our study adds to previous research by investigating a more comprehensive set of search terms and different aspects of reliability (e.g., differences in relative search volume distributions, correctly identified maxima). for this purpose, we collected samples of gt data for ten high- and two low-frequency search terms. we obtained one real-time sample and 62 non–realtime samples per search term (30 non–realtime samples for low-frequency search terms). data collection was restricted to search data for germany. our data support the existence of a reliability-frequency continuum—low-frequency search terms are subject to greater reliability issues compared to high-frequency search terms. based on our findings, we have derived practical recommendations for the use of gt data and have outlined future research opportunities.} {data quality,google trends data,reliability,sample stability,search engine data} {data quality,google trends data,reliability,sample stability,search engine data}', 'using google trends data to study high-frequency search terms: evidence for a reliability-frequency continuum {google trends (gt) data are increasingly used in the social sciences and adjacent fields. however, previous research on the quality of gt data has raised concerns regarding their reliability. in the present study, we investigated whether reliability differs between low- and high-frequency search terms. in other words, we explored the existence of a reliability-frequency continuum in gt data. our study adds to previous research by investigating a more comprehensive set of search terms and different aspects of reliability (e.g., differences in relative search volume distributions, correctly identified maxima). for this purpose, we collected samples of gt data for ten high- and two low-frequency search terms. we obtained one real-time sample and 62 non–realtime samples per search term (30 non–realtime samples for low-frequency search terms). data collection was restricted to search data for germany. our data support the existence of a reliability-frequency continuum—low-frequency search terms are subject to greater reliability issues compared to high-frequency search terms. based on our findings, we have derived practical recommendations for the use of gt data and have outlined future research opportunities.} {data quality,google trends data,reliability,sample stability,search engine data} {data quality,google trends data,reliability,sample stability,search engine data}']"
3,40,3_political_multilevel_perception_germany,"['political', 'multilevel', 'perception', 'germany', 'trust']","['lip service to liberal democracy in western europe? {political scientists heavily rely on standard survey questions referring to “democracy” when they study citizens’ attitudes toward (liberal) democracy. however, we only know little about the way in which citizens respond to these questions. this article focuses on two frequently highlighted issues: social desirability and the consistency between citizens’ understanding and researchers’ understanding of the term “democracy.” to address these issues, i collected novel survey data via yougov from 14,000 british, french, german, and italian respondents. i use a list experiment to show that respondents do not feel socially pressured to misreport their support for democracy. however, what citizens have in mind when they claim to support democracy only reflects norms and institutions of minimal conceptions of democracy. overall, this encourages the usage of questions regarding citizens’ support for democracy widely, although this should not be interpreted as the support for anything going beyond minimal conceptions of democracy (providing freedom and allowing for citizens’ influence on political decisions).} {liberal democracy,list experiment,support for democracy,topic models,understandings of democracy} {liberal democracy,list experiment,support for democracy,topic models,understandings of democracy}', 'party competition over democracy: democracy as electoral issue in germany {elected leaders increasingly undermine liberal democratic institutions with the support of their voters, openly challenging liberal democratic institutions in election campaigns. however, political scientists thus far have lacked the theoretical and empirical tools to study the role of elections in democratic backsliding. this article theorizes the degree to which democracy in general and liberal democracy more specifically can and should be conceptualized as valence and positional issues in multiparty electoral competitions of established liberal democracies. by investigating how german citizens and parties of the postwar period spoke about democracy per se and liberal democracy in their regional and national election manifestos, this article shows that democracy per se and liberal democracy, in particular, have been issues of different qualities in german postwar elections. while parties have used references to democracy in general as a mixed issue, showing both signs of valence and positional issues, parties’ emphasis on liberal democracy is shaped by a positional logic. social and direct democracy have also been positional issues. studying democracy and its various conceptions as electoral issues will help us address many important questions concerning the stability of democracies, shifting researchers’ focus to the competition of parties over citizens’ support for reforms that undermine or stabilize liberal democracy.} {direct democracy,germany,liberal democracy,party competition,positional issues,social democracy,valence issues} {direct democracy,germany,liberal democracy,party competition,positional issues,social democracy,valence issues}', 'party competition over democracy: democracy as electoral issue in germany {elected leaders increasingly undermine liberal democratic institutions with the support of their voters, openly challenging liberal democratic institutions in election campaigns. however, political scientists thus far have lacked the theoretical and empirical tools to study the role of elections in democratic backsliding. this article theorizes the degree to which democracy in general and liberal democracy more specifically can and should be conceptualized as valence and positional issues in multiparty electoral competitions of established liberal democracies. by investigating how german citizens and parties of the postwar period spoke about democracy per se and liberal democracy in their regional and national election manifestos, this article shows that democracy per se and liberal democracy, in particular, have been issues of different qualities in german postwar elections. while parties have used references to democracy in general as a mixed issue, showing both signs of valence and positional issues, parties’ emphasis on liberal democracy is shaped by a positional logic. social and direct democracy have also been positional issues. studying democracy and its various conceptions as electoral issues will help us address many important questions concerning the stability of democracies, shifting researchers’ focus to the competition of parties over citizens’ support for reforms that undermine or stabilize liberal democracy.} {direct democracy,germany,liberal democracy,party competition,positional issues,social democracy,valence issues} {direct democracy,germany,liberal democracy,party competition,positional issues,social democracy,valence issues}']"
4,37,4_polarization_security_misinformation_social media,"['polarization', 'security', 'misinformation', 'social media', 'election']","[""effects of over-time exposure to partisan media and coverage of polarization on perceived polarization {america is said to be more polarized than ever before, and extensive research examines the causes and effects of political polarization. a less studied but more pronounced trend is that citizens perceive society and politics as sharply divided. we focus on news exposure as a key reason for these perceptions. we disentangle the unique effects of exposure to partisan outlets and to news coverage of polarization in general, whether in partisan or centrist news media. we rely on 9 months of online behavioral data (127,400,000 visits) from large samples in the u.s. and poland (total n = 2,462 & 2,120), paired with a three-wave panel survey on participants' attitudes and perceptions. we measure individual exposure, over-time and unobtrusively, to partisan outlets as well as to news coverage of polarization through a fine-tuned bert-based machine learning classifier. we find that both exposures increase perceived polarization, independently, in both countries. yet, in both contexts, it is news coverage of polarization, regardless of whether it is ideologically left, right, or centrist news outlets, that is the strongest driver of perceived polarization. these changes are confined to personal-level polarization (perceived distance between oneself and members of the opposing party), while no measure significantly influences perceptions of society, more generally, as being polarized. these findings have important implications for our understanding of how the media’s increasing tendency to focus on conflict as a central reporting frame can be the driver of often exaggerated perceptions of partisan divisions.} {computational social science,media coverage,partisan media,perceived polarization,web browsing data} {computational social science,media coverage,partisan media,perceived polarization,web browsing data}"", ""non-news websites expose people to more political content than news websites: evidence from browsing data in three countries {most scholars focus on the prevalence and democratic effects of (partisan) news exposure. this focus misses large parts of online activities of a majority of politically disinterested citizens. although political content also appears outside of news outlets and may profoundly shape public opinion, its prevalence and effects are under-studied at scale. this project combines three-wave panel survey data from three countries (total n = 7,266) with online behavioral data from the same participants (over 106m visits). we create a multi-lingual classifier to identify political content both in news and outside (e.g. in shopping or entertainment sites). we find that news consumption is infrequent: just 3.4% of participants’ online browsing comprised visits to news sites. only between 14% (nl) and 36% (us) of these visits were to news about politics. the overwhelming majority of participants' visits were to non-news sites. although only 1.6\\% of those visits related to politics, in absolute terms, citizens encounter politics more frequently outside of news than within news. out of every 10 visits to political content, 3.4 come from news and 6.6 from non-news sites. furthermore, exposure to political content outside news domains had the same–and in some cases stronger - associations with key democratic attitudes and behaviors as news exposure. these findings offer a comprehensive analysis of the online political (not solely news) ecosystem and demonstrate the importance of assessing the prevalence and effects of political content in non-news sources.} {computational social science,information consumption,misinformation,news exposure,polarization,political content,political knowledge} {computational social science,information consumption,misinformation,news exposure,polarization,political content,political knowledge}"", ""non-news websites expose people to more political content than news websites: evidence from browsing data in three countries {most scholars focus on the prevalence and democratic effects of (partisan) news exposure. this focus misses large parts of online activities of a majority of politically disinterested citizens. although political content also appears outside of news outlets and may profoundly shape public opinion, its prevalence and effects are under-studied at scale. this project combines three-wave panel survey data from three countries (total n = 7,266) with online behavioral data from the same participants (over 106m visits). we create a multi-lingual classifier to identify political content both in news and outside (e.g. in shopping or entertainment sites). we find that news consumption is infrequent: just 3.4% of participants’ online browsing comprised visits to news sites. only between 14% (nl) and 36% (us) of these visits were to news about politics. the overwhelming majority of participants' visits were to non-news sites. although only 1.6\\% of those visits related to politics, in absolute terms, citizens encounter politics more frequently outside of news than within news. out of every 10 visits to political content, 3.4 come from news and 6.6 from non-news sites. furthermore, exposure to political content outside news domains had the same–and in some cases stronger - associations with key democratic attitudes and behaviors as news exposure. these findings offer a comprehensive analysis of the online political (not solely news) ecosystem and demonstrate the importance of assessing the prevalence and effects of political content in non-news sources.} {computational social science,information consumption,misinformation,news exposure,polarization,political content,political knowledge} {computational social science,information consumption,misinformation,news exposure,polarization,political content,political knowledge}""]"
5,35,5_trust_learning_journalism_measurement,"['trust', 'learning', 'journalism', 'measurement', 'groups']","['improving media trust research through better measurement: an item response theory perspective {while trust in news media has come to the forefront of scholarly and public debate in recent years, academic researchers have raised persistent concern that measurement issues have prevented a better understanding of the concept. this research introduces an item response theory (irt) perspective to advance the state-of-the-art in media trust measurement beyond recent conceptual and analytical progress. i argue that standard survey instruments that concentrate on the perceived believability of news media restrict our capability to measure truly low media trust. furthermore, i suggest an important yet previously unnoticed pathway to overcoming this restriction in a scale by abdulla et al. that captures currency perceptions alongside believability perceptions. using a representative survey conducted in germany, i find robust empirical evidence that capturing currency vs. believability perceptions significantly impacts our ability to accurately measure lower vs. higher levels of media trust. the findings have implications for not only studies of media trust’s associations with antecedent and consequential constructs but any attempt to determine the true amount and divergence of citizens’ media trust. more generally, the results demonstrate how irt aids in putting scholarly debates on the dimensionality and interplay of trust with distrust on more common and fruitful grounds.} {confirmatory item factor analysis,item response theory,measurement,media trust,news credibility,news media,survey research} {confirmatory item factor analysis,item response theory,measurement,media trust,news credibility,news media,survey research}', 'improving media trust research through better measurement: an item response theory perspective {while trust in news media has come to the forefront of scholarly and public debate in recent years, academic researchers have raised persistent concern that measurement issues have prevented a better understanding of the concept. this research introduces an item response theory (irt) perspective to advance the state-of-the-art in media trust measurement beyond recent conceptual and analytical progress. i argue that standard survey instruments that concentrate on the perceived believability of news media restrict our capability to measure truly low media trust. furthermore, i suggest an important yet previously unnoticed pathway to overcoming this restriction in a scale by abdulla et al. that captures currency perceptions alongside believability perceptions. using a representative survey conducted in germany, i find robust empirical evidence that capturing currency vs. believability perceptions significantly impacts our ability to accurately measure lower vs. higher levels of media trust. the findings have implications for not only studies of media trust’s associations with antecedent and consequential constructs but any attempt to determine the true amount and divergence of citizens’ media trust. more generally, the results demonstrate how irt aids in putting scholarly debates on the dimensionality and interplay of trust with distrust on more common and fruitful grounds.} {confirmatory item factor analysis,item response theory,measurement,media trust,news credibility,news media,survey research} {confirmatory item factor analysis,item response theory,measurement,media trust,news credibility,news media,survey research}', 'improving media trust research through better measurement: an item response theory perspective {while trust in news media has come to the forefront of scholarly and public debate in recent years, academic researchers have raised persistent concern that measurement issues have prevented a better understanding of the concept. this research introduces an item response theory (irt) perspective to advance the state-of-the-art in media trust measurement beyond recent conceptual and analytical progress. i argue that standard survey instruments that concentrate on the perceived believability of news media restrict our capability to measure truly low media trust. furthermore, i suggest an important yet previously unnoticed pathway to overcoming this restriction in a scale by abdulla et al. that captures currency perceptions alongside believability perceptions. using a representative survey conducted in germany, i find robust empirical evidence that capturing currency vs. believability perceptions significantly impacts our ability to accurately measure lower vs. higher levels of media trust. the findings have implications for not only studies of media trust’s associations with antecedent and consequential constructs but any attempt to determine the true amount and divergence of citizens’ media trust. more generally, the results demonstrate how irt aids in putting scholarly debates on the dimensionality and interplay of trust with distrust on more common and fruitful grounds.} {confirmatory item factor analysis,item response theory,measurement,media trust,news credibility,news media,survey research} {confirmatory item factor analysis,item response theory,measurement,media trust,news credibility,news media,survey research}']"
6,32,6_nonresponse_waves_machine learning_mixed mode panel,"['nonresponse', 'waves', 'machine learning', 'mixed mode panel', 'population']","['creating design weights for a panel survey with multiple refreshment samples: a general discussion with an application to a probability-based mixed-mode panel {panel surveys suffer from attrition, where participants drop out over time. to maintain generalizability, refreshment samples are frequently employed, bringing in new individuals, increasing the number of panelists, and balancing sample composition. although refreshment samples offer numerous advantages, the inclusion of new panel members may introduce bias into the analysis if the design weights are not appropriately tailored to these new members and adjusted to align with existing panel members. if not correctly accounted for, their inclusion may bias results. this paper addresses the issue of designing proper weights by applying the multiple-frame weighting approach proposed by kalton and anderson, which is generally used for cross-sectional surveys, to ongoing panel studies with refreshment samples. we demonstrate its application to a synthetic data set and a probability-based mixed-mode panel with an initial sample and two refreshment samples. we compare estimates obtained using multiple-frame weighting with those obtained using unweighted and naively weighted methods (where design weights are used as calculated for the respective samples without adjusting for the fact that some members of the population have a chance of being sampled more than once due to the refreshments). these comparisons showcase the potential for bias introduced by neglecting proper weighting and underscore the importance of both a multiple-frame weighting approach and meticulous sample documentation.} {gesis panel,inclusion probabilities,multiple-frame weighting,panel surveys,refreshment samples} {gesis panel,inclusion probabilities,multiple-frame weighting,panel surveys,refreshment samples}', 'creating design weights for a panel survey with multiple refreshment samples: a general discussion with an application to a probability-based mixed-mode panel {panel surveys suffer from attrition, where participants drop out over time. to maintain generalizability, refreshment samples are frequently employed, bringing in new individuals, increasing the number of panelists, and balancing sample composition. although refreshment samples offer numerous advantages, the inclusion of new panel members may introduce bias into the analysis if the design weights are not appropriately tailored to these new members and adjusted to align with existing panel members. if not correctly accounted for, their inclusion may bias results. this paper addresses the issue of designing proper weights by applying the multiple-frame weighting approach proposed by kalton and anderson, which is generally used for cross-sectional surveys, to ongoing panel studies with refreshment samples. we demonstrate its application to a synthetic data set and a probability-based mixed-mode panel with an initial sample and two refreshment samples. we compare estimates obtained using multiple-frame weighting with those obtained using unweighted and naively weighted methods (where design weights are used as calculated for the respective samples without adjusting for the fact that some members of the population have a chance of being sampled more than once due to the refreshments). these comparisons showcase the potential for bias introduced by neglecting proper weighting and underscore the importance of both a multiple-frame weighting approach and meticulous sample documentation.} {gesis panel,inclusion probabilities,multiple-frame weighting,panel surveys,refreshment samples} {gesis panel,inclusion probabilities,multiple-frame weighting,panel surveys,refreshment samples}', 'creating design weights for a panel survey with multiple refreshment samples: a general discussion with an application to a probability-based mixed-mode panel {panel surveys suffer from attrition, where participants drop out over time. to maintain generalizability, refreshment samples are frequently employed, bringing in new individuals, increasing the number of panelists, and balancing sample composition. although refreshment samples offer numerous advantages, the inclusion of new panel members may introduce bias into the analysis if the design weights are not appropriately tailored to these new members and adjusted to align with existing panel members. if not correctly accounted for, their inclusion may bias results. this paper addresses the issue of designing proper weights by applying the multiple-frame weighting approach proposed by kalton and anderson, which is generally used for cross-sectional surveys, to ongoing panel studies with refreshment samples. we demonstrate its application to a synthetic data set and a probability-based mixed-mode panel with an initial sample and two refreshment samples. we compare estimates obtained using multiple-frame weighting with those obtained using unweighted and naively weighted methods (where design weights are used as calculated for the respective samples without adjusting for the fact that some members of the population have a chance of being sampled more than once due to the refreshments). these comparisons showcase the potential for bias introduced by neglecting proper weighting and underscore the importance of both a multiple-frame weighting approach and meticulous sample documentation.} {gesis panel,inclusion probabilities,multiple-frame weighting,panel surveys,refreshment samples} {gesis panel,inclusion probabilities,multiple-frame weighting,panel surveys,refreshment samples}']"
7,31,7_face_sampling_mixed mode_costs,"['face', 'sampling', 'mixed mode', 'costs', 'web']","['sequential and concurrent mixed-mode designs: a tailored approach {due to rising costs and declining response rates, surveys are increasingly moving from face-to-face interviewing to a self-administered mixed-mode design. mixed-mode surveys can be conducted using a concurrent or a sequential design. a sequential design in which the web mode is offered first is a common strategy for mixed-mode surveys as it reduces survey costs. however, when deciding which mode choice sequence to use, sample balance should also be considered. one approach to achieving a balanced sample might be to tailor the sequence of the choice of modes, or the mode choice sequence. for this purpose, we use an indicator that assigns the sampled persons to the different mode choice sequences to minimize the variability of response probabilities. in this study, we compare the sample composition achieved with a concurrent and a sequential design. additionally, we investigate whether indicator-based tailoring of the two mode choice sequences can improve sample composition. we implemented a randomized experiment in the 2021 german general social survey (allbus), which surveyed the general population aged 18 and older in private households (n 5,342) using a mixed-mode design (web and mail). in a first step, respondents were randomly assigned to a concurrent or a sequential design. we find that the two mode choice sequences lead to a similar sample composition. next, we identify age as the best available single indicator of the variables known before the survey to tailor the mode choice sequence. our analyses show that a tailored approach based on age improves the sample composition slightly.}', 'sequential and concurrent mixed-mode designs: a tailored approach {due to rising costs and declining response rates, surveys are increasingly moving from face-to-face interviewing to a self-administered mixed-mode design. mixed-mode surveys can be conducted using a concurrent or a sequential design. a sequential design in which the web mode is offered first is a common strategy for mixed-mode surveys as it reduces survey costs. however, when deciding which mode choice sequence to use, sample balance should also be considered. one approach to achieving a balanced sample might be to tailor the sequence of the choice of modes, or the mode choice sequence. for this purpose, we use an indicator that assigns the sampled persons to the different mode choice sequences to minimize the variability of response probabilities. in this study, we compare the sample composition achieved with a concurrent and a sequential design. additionally, we investigate whether indicator-based tailoring of the two mode choice sequences can improve sample composition. we implemented a randomized experiment in the 2021 german general social survey (allbus), which surveyed the general population aged 18 and older in private households (n 5,342) using a mixed-mode design (web and mail). in a first step, respondents were randomly assigned to a concurrent or a sequential design. we find that the two mode choice sequences lead to a similar sample composition. next, we identify age as the best available single indicator of the variables known before the survey to tailor the mode choice sequence. our analyses show that a tailored approach based on age improves the sample composition slightly.}', 'sequential and concurrent mixed-mode designs: a tailored approach {due to rising costs and declining response rates, surveys are increasingly moving from face-to-face interviewing to a self-administered mixed-mode design. mixed-mode surveys can be conducted using a concurrent or a sequential design. a sequential design in which the web mode is offered first is a common strategy for mixed-mode surveys as it reduces survey costs. however, when deciding which mode choice sequence to use, sample balance should also be considered. one approach to achieving a balanced sample might be to tailor the sequence of the choice of modes, or the mode choice sequence. for this purpose, we use an indicator that assigns the sampled persons to the different mode choice sequences to minimize the variability of response probabilities. in this study, we compare the sample composition achieved with a concurrent and a sequential design. additionally, we investigate whether indicator-based tailoring of the two mode choice sequences can improve sample composition. we implemented a randomized experiment in the 2021 german general social survey (allbus), which surveyed the general population aged 18 and older in private households (n 5,342) using a mixed-mode design (web and mail). in a first step, respondents were randomly assigned to a concurrent or a sequential design. we find that the two mode choice sequences lead to a similar sample composition. next, we identify age as the best available single indicator of the variables known before the survey to tailor the mode choice sequence. our analyses show that a tailored approach based on age improves the sample composition slightly.}']"
8,31,8_recruitment_online panel_probability based_mixed mode,"['recruitment', 'online panel', 'probability based', 'mixed mode', 'access']","['how do internet-related characteristics affect whether members of a german mixed-mode panel switch from the mail to the web mode? {in recent years, several longitudinal studies have transitioned from an interviewer-administered to a mixed-mode design, using the internet as one of the modes of data collection. however, a substantial proportion of panelists are reluctant to participate in web surveys when offered a choice in an ongoing mixed-mode panel. we still know little about the characteristics of panel members that drive them to comply with the request to complete surveys via the internet. this study aims to fill this gap by investigating how internet-related characteristics are linked to the willingness of panelists to switch from the mail mode to the web. we use data from multiple waves of the gesis panel, a probability-based mixed-mode panel in germany (n = 5734). a web-push intervention motivated 28% of 1364 panelists of the mail mode to complete the survey online in a single wave and 70% of these 380 short-term switchers to switch to the web mode permanently. we measured indicators of internet use, internet skills, and attitudes toward the internet as potential mechanisms of this short-term and long-term mode switching in the two waves before the intervention. our results suggest that internet use and internet skills affect respondents’ willingness to switch modes in a single wave. for these short-term switchers, however, none of the internet-related characteristics could explain mode switching in the long term. we also present self-reported reasons by panelists for not accepting the offer to switch modes that correspond to these findings. the results of this study can be used to develop effective push-to-web methods for longitudinal mixed-mode surveys.} {internet skills,internet use,mixed-mode,panel survey,web survey} {internet skills,internet use,mixed-mode,panel survey,web survey}', 'how do internet-related characteristics affect whether members of a german mixed-mode panel switch from the mail to the web mode? {in recent years, several longitudinal studies have transitioned from an interviewer-administered to a mixed-mode design, using the internet as one of the modes of data collection. however, a substantial proportion of panelists are reluctant to participate in web surveys when offered a choice in an ongoing mixed-mode panel. we still know little about the characteristics of panel members that drive them to comply with the request to complete surveys via the internet. this study aims to fill this gap by investigating how internet-related characteristics are linked to the willingness of panelists to switch from the mail mode to the web. we use data from multiple waves of the gesis panel, a probability-based mixed-mode panel in germany (n = 5734). a web-push intervention motivated 28% of 1364 panelists of the mail mode to complete the survey online in a single wave and 70% of these 380 short-term switchers to switch to the web mode permanently. we measured indicators of internet use, internet skills, and attitudes toward the internet as potential mechanisms of this short-term and long-term mode switching in the two waves before the intervention. our results suggest that internet use and internet skills affect respondents’ willingness to switch modes in a single wave. for these short-term switchers, however, none of the internet-related characteristics could explain mode switching in the long term. we also present self-reported reasons by panelists for not accepting the offer to switch modes that correspond to these findings. the results of this study can be used to develop effective push-to-web methods for longitudinal mixed-mode surveys.} {internet skills,internet use,mixed-mode,panel survey,web survey} {internet skills,internet use,mixed-mode,panel survey,web survey}', 'how do internet-related characteristics affect whether members of a german mixed-mode panel switch from the mail to the web mode? {in recent years, several longitudinal studies have transitioned from an interviewer-administered to a mixed-mode design, using the internet as one of the modes of data collection. however, a substantial proportion of panelists are reluctant to participate in web surveys when offered a choice in an ongoing mixed-mode panel. we still know little about the characteristics of panel members that drive them to comply with the request to complete surveys via the internet. this study aims to fill this gap by investigating how internet-related characteristics are linked to the willingness of panelists to switch from the mail mode to the web. we use data from multiple waves of the gesis panel, a probability-based mixed-mode panel in germany (n = 5734). a web-push intervention motivated 28% of 1364 panelists of the mail mode to complete the survey online in a single wave and 70% of these 380 short-term switchers to switch to the web mode permanently. we measured indicators of internet use, internet skills, and attitudes toward the internet as potential mechanisms of this short-term and long-term mode switching in the two waves before the intervention. our results suggest that internet use and internet skills affect respondents’ willingness to switch modes in a single wave. for these short-term switchers, however, none of the internet-related characteristics could explain mode switching in the long term. we also present self-reported reasons by panelists for not accepting the offer to switch modes that correspond to these findings. the results of this study can be used to develop effective push-to-web methods for longitudinal mixed-mode surveys.} {internet skills,internet use,mixed-mode,panel survey,web survey} {internet skills,internet use,mixed-mode,panel survey,web survey}']"
9,31,9_government_metadata_channels_recognition,"['government', 'metadata', 'channels', 'recognition', 'energy']","['a comprehensive analysis of acknowledgement texts in web of science: a case study on four scientific domains {analysis of acknowledgments is particularly interesting as acknowledgments may give information not only about funding, but they are also able to reveal hidden contributions to authorship and the researcher’s collaboration patterns, context in which research was conducted, and specific aspects of the academic work. the focus of the present research is the analysis of a large sample of acknowledgement texts indexed in the web of science (wos) core collection. record types “article” and “review” from four different scientific domains, namely social sciences, economics, oceanography and computer science, published from 2014 to 2019 in a scientific journal in english were considered. six types of acknowledged entities, i.e., funding agency, grant number, individuals, university, corporation and miscellaneous, were extracted from the acknowledgement texts using a named entity recognition tagger and subsequently examined. a general analysis of the acknowledgement texts showed that indexing of funding information in wos is incomplete. the analysis of the automatically extracted entities revealed differences and distinct patterns in the distribution of acknowledged entities of different types between different scientific domains. a strong association was found between acknowledged entity and scientific domain, and acknowledged entity and entity type. only negligible correlation was found between the number of citations and the number of acknowledged entities. generally, the number of words in the acknowledgement texts positively correlates with the number of acknowledged funding organizations, universities, individuals and miscellaneous entities. at the same time, acknowledgement texts with the larger number of sentences have more acknowledged individuals and miscellaneous categories.} {acknowledged entities,acknowledgements,named entity recognition,web of science} {acknowledged entities,acknowledgements,named entity recognition,web of science}', 'a comprehensive analysis of acknowledgement texts in web of science: a case study on four scientific domains {analysis of acknowledgments is particularly interesting as acknowledgments may give information not only about funding, but they are also able to reveal hidden contributions to authorship and the researcher’s collaboration patterns, context in which research was conducted, and specific aspects of the academic work. the focus of the present research is the analysis of a large sample of acknowledgement texts indexed in the web of science (wos) core collection. record types “article” and “review” from four different scientific domains, namely social sciences, economics, oceanography and computer science, published from 2014 to 2019 in a scientific journal in english were considered. six types of acknowledged entities, i.e., funding agency, grant number, individuals, university, corporation and miscellaneous, were extracted from the acknowledgement texts using a named entity recognition tagger and subsequently examined. a general analysis of the acknowledgement texts showed that indexing of funding information in wos is incomplete. the analysis of the automatically extracted entities revealed differences and distinct patterns in the distribution of acknowledged entities of different types between different scientific domains. a strong association was found between acknowledged entity and scientific domain, and acknowledged entity and entity type. only negligible correlation was found between the number of citations and the number of acknowledged entities. generally, the number of words in the acknowledgement texts positively correlates with the number of acknowledged funding organizations, universities, individuals and miscellaneous entities. at the same time, acknowledgement texts with the larger number of sentences have more acknowledged individuals and miscellaneous categories.} {acknowledged entities,acknowledgements,named entity recognition,web of science} {acknowledged entities,acknowledgements,named entity recognition,web of science}', 'a comprehensive analysis of acknowledgement texts in web of science: a case study on four scientific domains {analysis of acknowledgments is particularly interesting as acknowledgments may give information not only about funding, but they are also able to reveal hidden contributions to authorship and the researcher’s collaboration patterns, context in which research was conducted, and specific aspects of the academic work. the focus of the present research is the analysis of a large sample of acknowledgement texts indexed in the web of science (wos) core collection. record types “article” and “review” from four different scientific domains, namely social sciences, economics, oceanography and computer science, published from 2014 to 2019 in a scientific journal in english were considered. six types of acknowledged entities, i.e., funding agency, grant number, individuals, university, corporation and miscellaneous, were extracted from the acknowledgement texts using a named entity recognition tagger and subsequently examined. a general analysis of the acknowledgement texts showed that indexing of funding information in wos is incomplete. the analysis of the automatically extracted entities revealed differences and distinct patterns in the distribution of acknowledged entities of different types between different scientific domains. a strong association was found between acknowledged entity and scientific domain, and acknowledged entity and entity type. only negligible correlation was found between the number of citations and the number of acknowledged entities. generally, the number of words in the acknowledgement texts positively correlates with the number of acknowledged funding organizations, universities, individuals and miscellaneous entities. at the same time, acknowledgement texts with the larger number of sentences have more acknowledged individuals and miscellaneous categories.} {acknowledged entities,acknowledgements,named entity recognition,web of science} {acknowledged entities,acknowledgements,named entity recognition,web of science}']"
10,24,10_covid 19 pandemic_trust_actor_social science,"['covid 19 pandemic', 'trust', 'actor', 'social science', 'hybrid']","['a dataset on survey designs and quality of social and behavioral science surveys during the covid-19 pandemic {in the social and behavioral sciences, surveys are frequently used to collect data. during the covid-19 pandemic, surveys provided political actors and public health professionals with timely insights on the attitudes and behaviors of the general population. these insights were key in guiding actions to fight the pandemic. however, the data quality of these surveys remains unclear because systematic knowledge about how the survey data were collected during the covid-19 pandemic is lacking. this is unfortunate, since decades of survey research have shown that survey design impacts data. our survey data collection and the covid-19 pandemic (sdccp) project deals with this research gap. we collected rich metadata on survey design for 717 social and behavioral science surveys carried out in germany during the first two years of the covid-19 pandemic. in this data descriptor, we present a unique resource for a systematic assessment of the survey data collection practices and quality of surveys conducted in germany during the covid-19 pandemic.}', 'a dataset on survey designs and quality of social and behavioral science surveys during the covid-19 pandemic {in the social and behavioral sciences, surveys are frequently used to collect data. during the covid-19 pandemic, surveys provided political actors and public health professionals with timely insights on the attitudes and behaviors of the general population. these insights were key in guiding actions to fight the pandemic. however, the data quality of these surveys remains unclear because systematic knowledge about how the survey data were collected during the covid-19 pandemic is lacking. this is unfortunate, since decades of survey research have shown that survey design impacts data. our survey data collection and the covid-19 pandemic (sdccp) project deals with this research gap. we collected rich metadata on survey design for 717 social and behavioral science surveys carried out in germany during the first two years of the covid-19 pandemic. in this data descriptor, we present a unique resource for a systematic assessment of the survey data collection practices and quality of surveys conducted in germany during the covid-19 pandemic.}', 'a dataset on survey designs and quality of social and behavioral science surveys during the covid-19 pandemic {in the social and behavioral sciences, surveys are frequently used to collect data. during the covid-19 pandemic, surveys provided political actors and public health professionals with timely insights on the attitudes and behaviors of the general population. these insights were key in guiding actions to fight the pandemic. however, the data quality of these surveys remains unclear because systematic knowledge about how the survey data were collected during the covid-19 pandemic is lacking. this is unfortunate, since decades of survey research have shown that survey design impacts data. our survey data collection and the covid-19 pandemic (sdccp) project deals with this research gap. we collected rich metadata on survey design for 717 social and behavioral science surveys carried out in germany during the first two years of the covid-19 pandemic. in this data descriptor, we present a unique resource for a systematic assessment of the survey data collection practices and quality of surveys conducted in germany during the covid-19 pandemic.}']"
11,23,11_comparability_big_governance_personality traits,"['comparability', 'big', 'governance', 'personality traits', 'level']","['river sampling – a fishing expedition: a non-probability case study {the ease with which large amounts of data can be collected via the internet has led to a renewed interest in the use of non-probability samples. to that end, this paper performs a case study, comparing two non-probability datasets – one based on a river-sampling approach, one drawn from an online-access panel – to a reference probability sample. of particular interest is the single-question river-sampling approach, as the data collected for this study presents an attempt to field a multi-item scale with such a sampling method. each dataset consists of the same psychometric measures for two of the big-5 personality traits, which are expected to perform independently of sample composition. to assess the similarity of the three datasets we compare their correlation matrices, apply linear and non-linear dimension reduction techniques, and analyze the distance between the datasets. our results show that there are important limitations when implementing a multi-item scale via a single-question river sample. we find that, while the correlation between our data sets is similar, the samples are composed of persons with different personality traits.} {big-5,non-linear dimension reduction,non-probability sample,river sample,web survey research} {big-5,non-linear dimension reduction,non-probability sample,river sample,web survey research}', 'river sampling – a fishing expedition: a non-probability case study {the ease with which large amounts of data can be collected via the internet has led to a renewed interest in the use of non-probability samples. to that end, this paper performs a case study, comparing two non-probability datasets – one based on a river-sampling approach, one drawn from an online-access panel – to a reference probability sample. of particular interest is the single-question river-sampling approach, as the data collected for this study presents an attempt to field a multi-item scale with such a sampling method. each dataset consists of the same psychometric measures for two of the big-5 personality traits, which are expected to perform independently of sample composition. to assess the similarity of the three datasets we compare their correlation matrices, apply linear and non-linear dimension reduction techniques, and analyze the distance between the datasets. our results show that there are important limitations when implementing a multi-item scale via a single-question river sample. we find that, while the correlation between our data sets is similar, the samples are composed of persons with different personality traits.} {big-5,non-linear dimension reduction,non-probability sample,river sample,web survey research} {big-5,non-linear dimension reduction,non-probability sample,river sample,web survey research}', 'river sampling – a fishing expedition: a non-probability case study {the ease with which large amounts of data can be collected via the internet has led to a renewed interest in the use of non-probability samples. to that end, this paper performs a case study, comparing two non-probability datasets – one based on a river-sampling approach, one drawn from an online-access panel – to a reference probability sample. of particular interest is the single-question river-sampling approach, as the data collected for this study presents an attempt to field a multi-item scale with such a sampling method. each dataset consists of the same psychometric measures for two of the big-5 personality traits, which are expected to perform independently of sample composition. to assess the similarity of the three datasets we compare their correlation matrices, apply linear and non-linear dimension reduction techniques, and analyze the distance between the datasets. our results show that there are important limitations when implementing a multi-item scale via a single-question river sample. we find that, while the correlation between our data sets is similar, the samples are composed of persons with different personality traits.} {big-5,non-linear dimension reduction,non-probability sample,river sample,web survey research} {big-5,non-linear dimension reduction,non-probability sample,river sample,web survey research}']"
12,21,12_digital_frameworks_social science_measurement invariance,"['digital', 'frameworks', 'social science', 'measurement invariance', 'error']","['assessing data quality in the age of digital social research: a systematic review {while survey data has long been the focus of quantitative social science analyses, observational and content data, although long-established, are gaining renewed attention; especially when this type of data is obtained by and for observing digital content and behavior. today, digital technologies allow social scientists to track “everyday behavior” and to extract opinions from public discussions on online platforms. these new types of digital traces of human behavior, together with computational methods for analyzing them, have opened new avenues for analyzing, understanding, and addressing social science research questions. however, even the most innovative and extensive amounts of data are hollow if they are not of high quality. but what does data quality mean for modern social science data? to investigate this rather abstract question the present study focuses on four objectives. first, we provide researchers with a decision tree to identify appropriate data quality frameworks for a given use case. second, we determine which data types and quality dimensions are already addressed in the existing frameworks. third, we identify gaps with respect to different data types and data quality dimensions within the existing frameworks which need to be filled. and fourth, we provide a detailed literature overview for the intrinsic and extrinsic perspectives on data quality. by conducting a systematic literature review based on text mining methods, we identified and reviewed 58 data quality frameworks. in our decision tree, the three categories, namely, data type, the perspective it takes, and its level of granularity, help researchers to find appropriate data quality frameworks. we, furthermore, discovered gaps in the available frameworks with respect to visual and especially linked data and point out in our review that even famous frameworks might miss important aspects. the article ends with a critical discussion of the current state of the literature and potential future research avenues.} {data quality,data quality concepts,data quality frameworks,measurement,representation,systematic review} {data quality,data quality concepts,data quality frameworks,measurement,representation,systematic review}', 'assessing data quality in the age of digital social research: a systematic review {while survey data has long been the focus of quantitative social science analyses, observational and content data, although long-established, are gaining renewed attention; especially when this type of data is obtained by and for observing digital content and behavior. today, digital technologies allow social scientists to track “everyday behavior” and to extract opinions from public discussions on online platforms. these new types of digital traces of human behavior, together with computational methods for analyzing them, have opened new avenues for analyzing, understanding, and addressing social science research questions. however, even the most innovative and extensive amounts of data are hollow if they are not of high quality. but what does data quality mean for modern social science data? to investigate this rather abstract question the present study focuses on four objectives. first, we provide researchers with a decision tree to identify appropriate data quality frameworks for a given use case. second, we determine which data types and quality dimensions are already addressed in the existing frameworks. third, we identify gaps with respect to different data types and data quality dimensions within the existing frameworks which need to be filled. and fourth, we provide a detailed literature overview for the intrinsic and extrinsic perspectives on data quality. by conducting a systematic literature review based on text mining methods, we identified and reviewed 58 data quality frameworks. in our decision tree, the three categories, namely, data type, the perspective it takes, and its level of granularity, help researchers to find appropriate data quality frameworks. we, furthermore, discovered gaps in the available frameworks with respect to visual and especially linked data and point out in our review that even famous frameworks might miss important aspects. the article ends with a critical discussion of the current state of the literature and potential future research avenues.} {data quality,data quality concepts,data quality frameworks,measurement,representation,systematic review} {data quality,data quality concepts,data quality frameworks,measurement,representation,systematic review}', 'assessing data quality in the age of digital social research: a systematic review {while survey data has long been the focus of quantitative social science analyses, observational and content data, although long-established, are gaining renewed attention; especially when this type of data is obtained by and for observing digital content and behavior. today, digital technologies allow social scientists to track “everyday behavior” and to extract opinions from public discussions on online platforms. these new types of digital traces of human behavior, together with computational methods for analyzing them, have opened new avenues for analyzing, understanding, and addressing social science research questions. however, even the most innovative and extensive amounts of data are hollow if they are not of high quality. but what does data quality mean for modern social science data? to investigate this rather abstract question the present study focuses on four objectives. first, we provide researchers with a decision tree to identify appropriate data quality frameworks for a given use case. second, we determine which data types and quality dimensions are already addressed in the existing frameworks. third, we identify gaps with respect to different data types and data quality dimensions within the existing frameworks which need to be filled. and fourth, we provide a detailed literature overview for the intrinsic and extrinsic perspectives on data quality. by conducting a systematic literature review based on text mining methods, we identified and reviewed 58 data quality frameworks. in our decision tree, the three categories, namely, data type, the perspective it takes, and its level of granularity, help researchers to find appropriate data quality frameworks. we, furthermore, discovered gaps in the available frameworks with respect to visual and especially linked data and point out in our review that even famous frameworks might miss important aspects. the article ends with a critical discussion of the current state of the literature and potential future research avenues.} {data quality,data quality concepts,data quality frameworks,measurement,representation,systematic review} {data quality,data quality concepts,data quality frameworks,measurement,representation,systematic review}']"
13,21,13_gender_organizations_europe_inclusion,"['gender', 'organizations', 'europe', 'inclusion', 'measurement']","['the role of intersectionality and context in measuring gender-based violence in universities and research-performing organizations in europe for the development of inclusive structural interventions {the aim of the article is to discuss how thinking about gender-based violence intersectionally and in context can not only enrich our understanding but also lead to transformative change in organizations. the article argues that to better understand gender-based violence in universities and research institutions, analyses need to be intersectional and contextual. such approaches go beyond binary understandings of gender and narrow legalistic definitions of gender-based violence. the article reflects on how to operationalize this to derive starting points for intersectional categories to consider and contextual factors to measure at micro-, meso-, and macro-levels. it concludes that a multilevel intersectional analysis leads to more nuanced knowledge on experiences of gender-based violence and is, therefore, better equipped to inform the development of measures to eradicate the problem in an inclusive way.} {gender-based violence,intersectionality,research-performing organizations,surveys,theorizing quantitative measurement} {gender-based violence,intersectionality,research-performing organizations,surveys,theorizing quantitative measurement}', 'the role of intersectionality and context in measuring gender-based violence in universities and research-performing organizations in europe for the development of inclusive structural interventions {the aim of the article is to discuss how thinking about gender-based violence intersectionally and in context can not only enrich our understanding but also lead to transformative change in organizations. the article argues that to better understand gender-based violence in universities and research institutions, analyses need to be intersectional and contextual. such approaches go beyond binary understandings of gender and narrow legalistic definitions of gender-based violence. the article reflects on how to operationalize this to derive starting points for intersectional categories to consider and contextual factors to measure at micro-, meso-, and macro-levels. it concludes that a multilevel intersectional analysis leads to more nuanced knowledge on experiences of gender-based violence and is, therefore, better equipped to inform the development of measures to eradicate the problem in an inclusive way.} {gender-based violence,intersectionality,research-performing organizations,surveys,theorizing quantitative measurement} {gender-based violence,intersectionality,research-performing organizations,surveys,theorizing quantitative measurement}', 'the role of intersectionality and context in measuring gender-based violence in universities and research-performing organizations in europe for the development of inclusive structural interventions {the aim of the article is to discuss how thinking about gender-based violence intersectionally and in context can not only enrich our understanding but also lead to transformative change in organizations. the article argues that to better understand gender-based violence in universities and research institutions, analyses need to be intersectional and contextual. such approaches go beyond binary understandings of gender and narrow legalistic definitions of gender-based violence. the article reflects on how to operationalize this to derive starting points for intersectional categories to consider and contextual factors to measure at micro-, meso-, and macro-levels. it concludes that a multilevel intersectional analysis leads to more nuanced knowledge on experiences of gender-based violence and is, therefore, better equipped to inform the development of measures to eradicate the problem in an inclusive way.} {gender-based violence,intersectionality,research-performing organizations,surveys,theorizing quantitative measurement} {gender-based violence,intersectionality,research-performing organizations,surveys,theorizing quantitative measurement}']"
14,21,14_arguments_quality_mining_language model,"['arguments', 'quality', 'mining', 'language model', 'artificial intelligence']","[""argument quality assessment in the age of instruction-following large language models {the computational treatment of arguments on controversial issues has been subject to extensive nlp research, due to its envisioned impact on opinion formation, decision making, writing education, and the like. a critical task in any such application is the assessment of an argument's quality-but it is also particularly challenging. in this position paper, we start from a brief survey of argument quality research, where we identify the diversity of quality notions and the subjectiveness of their perception as the main hurdles towards substantial progress on argument quality assessment. we argue that the capabilities of instruction-following large language models (llms) to leverage knowledge across contexts enable a much more reliable assessment. rather than just fine-tuning llms towards leaderboard chasing on assessment tasks, they need to be instructed systematically with argumentation theories and scenarios as well as with ways to solve argument-related problems. we discuss the real-world opportunities and ethical issues emerging thereby.} {argument quality,computational argumentation,instruction fine-tuning,large language model} {argument quality,computational argumentation,instruction fine-tuning,large language model}"", ""argument quality assessment in the age of instruction-following large language models {the computational treatment of arguments on controversial issues has been subject to extensive nlp research, due to its envisioned impact on opinion formation, decision making, writing education, and the like. a critical task in any such application is the assessment of an argument's quality-but it is also particularly challenging. in this position paper, we start from a brief survey of argument quality research, where we identify the diversity of quality notions and the subjectiveness of their perception as the main hurdles towards substantial progress on argument quality assessment. we argue that the capabilities of instruction-following large language models (llms) to leverage knowledge across contexts enable a much more reliable assessment. rather than just fine-tuning llms towards leaderboard chasing on assessment tasks, they need to be instructed systematically with argumentation theories and scenarios as well as with ways to solve argument-related problems. we discuss the real-world opportunities and ethical issues emerging thereby.} {argument quality,computational argumentation,instruction fine-tuning,large language model} {argument quality,computational argumentation,instruction fine-tuning,large language model}"", ""argument quality assessment in the age of instruction-following large language models {the computational treatment of arguments on controversial issues has been subject to extensive nlp research, due to its envisioned impact on opinion formation, decision making, writing education, and the like. a critical task in any such application is the assessment of an argument's quality-but it is also particularly challenging. in this position paper, we start from a brief survey of argument quality research, where we identify the diversity of quality notions and the subjectiveness of their perception as the main hurdles towards substantial progress on argument quality assessment. we argue that the capabilities of instruction-following large language models (llms) to leverage knowledge across contexts enable a much more reliable assessment. rather than just fine-tuning llms towards leaderboard chasing on assessment tasks, they need to be instructed systematically with argumentation theories and scenarios as well as with ways to solve argument-related problems. we discuss the real-world opportunities and ethical issues emerging thereby.} {argument quality,computational argumentation,instruction fine-tuning,large language model} {argument quality,computational argumentation,instruction fine-tuning,large language model}""]"
15,21,15_closed_quality_pretesting_coding,"['closed', 'quality', 'pretesting', 'coding', 'interviewing']","[""multi-label classification of open-ended questions with bert {open-ended questions in surveys are valuable because they do not constrain the respondent's answer, thereby avoiding biases. however, answers to open-ended questions are text data which are harder to analyze. traditionally, answers were manually classified as specified in the coding manual. in the last 10 years, researchers have tried to automate coding. most of the effort has gone into the easier problem of single label prediction, where answers are classified into a single code. however, open-ends that require multi-label classification, i.e., that are assigned multiple codes, occur frequently. this paper focuses on multi-label classification of text answers to open-ended survey questions in social science surveys. here, open-ends are frequently mildly multi-label, where the average number of labels per answer text is relatively low. we evaluate the performance of the transformer-based architecture bert for the german language in comparison to traditional multi-label algorithms (binary relevance, label powerset, ecc) in a german social science survey, the gles panel (n=17,584, 55 labels). we evaluate the algorithms on 0/1 loss. we find that classification with bert (forcing at least one label) has the smallest 0/1 loss (13.1%) among methods considered (18.9%-21.6%). our work has important implications for social scientists: 1) multi-label classification with bert works in the german language for open-ends. 2) for mildly multi-label classification tasks, the loss now appears small enough to allow for fully automatic classification. previously, the loss was more substantial, usually requiring semiautomatic approaches. 3) unlike the nearest competitor, ecc, multi-label classification with bert requires only a single model for all labels.} {all-that-apply,ecc,label powerset,open-ends,survey methodology} {all-that-apply,ecc,label powerset,open-ends,survey methodology}"", 'the effects of open-ended probes on closed survey questions in web surveys {probes are follow-ups to survey questions used to gain insights on respondents’ understanding of and responses to these questions. they are usually administered as open-ended questions, primarily in the context of questionnaire pretesting. due to the decreased cost of data collection for open-ended questions in web surveys, researchers have argued for embedding more open-ended probes in large-scale web surveys. however, there are concerns that this may cause reactivity and impact survey data. the study presents a randomized experiment in which identical survey questions were run with and without open-ended probes. embedding open-ended probes resulted in higher levels of survey break off, as well as increased backtracking and answer changes to previous questions. in most cases, there was no impact of open-ended probes on the cognitive processing of and response to survey questions. implications for embedding open-ended probes into web surveys are discussed.} {cognitive pretest,open-ended questions,reactivity,response quality,web probing} {cognitive pretest,open-ended questions,reactivity,response quality,web probing}', 'the effects of open-ended probes on closed survey questions in web surveys {probes are follow-ups to survey questions used to gain insights on respondents’ understanding of and responses to these questions. they are usually administered as open-ended questions, primarily in the context of questionnaire pretesting. due to the decreased cost of data collection for open-ended questions in web surveys, researchers have argued for embedding more open-ended probes in large-scale web surveys. however, there are concerns that this may cause reactivity and impact survey data. the study presents a randomized experiment in which identical survey questions were run with and without open-ended probes. embedding open-ended probes resulted in higher levels of survey break off, as well as increased backtracking and answer changes to previous questions. in most cases, there was no impact of open-ended probes on the cognitive processing of and response to survey questions. implications for embedding open-ended probes into web surveys are discussed.} {cognitive pretest,open-ended questions,reactivity,response quality,web probing} {cognitive pretest,open-ended questions,reactivity,response quality,web probing}']"
16,19,16_public opinion_driven_psychology_privacy,"['public opinion', 'driven', 'psychology', 'privacy', 'cross']","['the role of public opinion research in the democratic process: insights from politicians, journalists, and the general public {this study reveals the existence of a paradox in how the public views polling within the democratic process. specifically, even though the public believes that it can influence policymaking, it considers public opinion polls not as useful as other, less representative forms of public input, such as comments at town hall meetings. analyzing data from multiple surveys conducted in the united states of america, we find no evidence for the democratic representation hypothesis with respect to polling. comparisons across stakeholders (public, journalists, and politicians) demonstrate that general perceptions of inputs into the democratic process are similar, which confirms the citizen-elite congruence hypothesis. however, unlike members of the public, experts are more likely to believe that public opinion polls are the optimal method by which the public can successfully inform policymaking, a finding consistent with the legitimization hypothesis. with respect to perceptions of politicians, we found substantial differences regarding party registration with democrats and independents favoring public opinion polling and republicans preferring alternative methods (e.g., town hall meetings) of informing policymakers.} {democratic representation,media,policymaking,politicians,preferences,public opinion research,public policy,survey value} {democratic representation,media,policymaking,politicians,preferences,public opinion research,public policy,survey value}', 'the role of public opinion research in the democratic process: insights from politicians, journalists, and the general public {this study reveals the existence of a paradox in how the public views polling within the democratic process. specifically, even though the public believes that it can influence policymaking, it considers public opinion polls not as useful as other, less representative forms of public input, such as comments at town hall meetings. analyzing data from multiple surveys conducted in the united states of america, we find no evidence for the democratic representation hypothesis with respect to polling. comparisons across stakeholders (public, journalists, and politicians) demonstrate that general perceptions of inputs into the democratic process are similar, which confirms the citizen-elite congruence hypothesis. however, unlike members of the public, experts are more likely to believe that public opinion polls are the optimal method by which the public can successfully inform policymaking, a finding consistent with the legitimization hypothesis. with respect to perceptions of politicians, we found substantial differences regarding party registration with democrats and independents favoring public opinion polling and republicans preferring alternative methods (e.g., town hall meetings) of informing policymakers.} {democratic representation,media,policymaking,politicians,preferences,public opinion research,public policy,survey value} {democratic representation,media,policymaking,politicians,preferences,public opinion research,public policy,survey value}', 'the role of public opinion research in the democratic process: insights from politicians, journalists, and the general public {this study reveals the existence of a paradox in how the public views polling within the democratic process. specifically, even though the public believes that it can influence policymaking, it considers public opinion polls not as useful as other, less representative forms of public input, such as comments at town hall meetings. analyzing data from multiple surveys conducted in the united states of america, we find no evidence for the democratic representation hypothesis with respect to polling. comparisons across stakeholders (public, journalists, and politicians) demonstrate that general perceptions of inputs into the democratic process are similar, which confirms the citizen-elite congruence hypothesis. however, unlike members of the public, experts are more likely to believe that public opinion polls are the optimal method by which the public can successfully inform policymaking, a finding consistent with the legitimization hypothesis. with respect to perceptions of politicians, we found substantial differences regarding party registration with democrats and independents favoring public opinion polling and republicans preferring alternative methods (e.g., town hall meetings) of informing policymakers.} {democratic representation,media,policymaking,politicians,preferences,public opinion research,public policy,survey value} {democratic representation,media,policymaking,politicians,preferences,public opinion research,public policy,survey value}']"
17,16,17_split_questionnaire_errors_machine,"['split', 'questionnaire', 'errors', 'machine', 'languages']","['how does back translation fare against team translation? an experimental case study in the language combination english–german {when it comes to quality in questionnaire translation and hence comparability in comparative research, the chosen translation method is crucial for the outcome. few empirical studies compare different translation methods—a fact which is often deplored in the research community. to fill the gap, in this study, the team translation approach is compared against a simple back-translation approach. the starting point in both cases was the initial english–german translations of issp (international social survey program) questions. the final translations from both approaches were assessed, with a focus on how translation issues, such as mistranslations or wording issues identified in the initial translations were addressed. while none of the twenty-nine issues in the initial translation were present in the final team translation version, twenty-two of these issues were still present in the final version after the back-translation approach. for a selected number of items, we also ran a split-ballot experiment in a web survey. only five out of fifteen items (33 percent) that went into the experiment showed significant differences between the translations, and only one could clearly be attributed to remaining errors in the back-translation version. in sum, the final translation from the team approach clearly outperformed the final translation from the back-translation approach when it comes to text-based criteria (in particular, accuracy and fluency). the quantitative test showed that many translation issues (those remaining in the translation after the back translation step) had no effect on the estimates. nevertheless, we ask respondents to put effort into survey responding; in the same vein, we as researchers should put effort in the survey experience by providing questions that are clearly worded and free of errors, which puts the team approach ahead of the back-translation approach.} {back translation,comparison of translation methods,questionnaire translation,split-ballot experiment,team translation} {back translation,comparison of translation methods,questionnaire translation,split-ballot experiment,team translation}', 'how does back translation fare against team translation? an experimental case study in the language combination english–german {when it comes to quality in questionnaire translation and hence comparability in comparative research, the chosen translation method is crucial for the outcome. few empirical studies compare different translation methods—a fact which is often deplored in the research community. to fill the gap, in this study, the team translation approach is compared against a simple back-translation approach. the starting point in both cases was the initial english–german translations of issp (international social survey program) questions. the final translations from both approaches were assessed, with a focus on how translation issues, such as mistranslations or wording issues identified in the initial translations were addressed. while none of the twenty-nine issues in the initial translation were present in the final team translation version, twenty-two of these issues were still present in the final version after the back-translation approach. for a selected number of items, we also ran a split-ballot experiment in a web survey. only five out of fifteen items (33 percent) that went into the experiment showed significant differences between the translations, and only one could clearly be attributed to remaining errors in the back-translation version. in sum, the final translation from the team approach clearly outperformed the final translation from the back-translation approach when it comes to text-based criteria (in particular, accuracy and fluency). the quantitative test showed that many translation issues (those remaining in the translation after the back translation step) had no effect on the estimates. nevertheless, we ask respondents to put effort into survey responding; in the same vein, we as researchers should put effort in the survey experience by providing questions that are clearly worded and free of errors, which puts the team approach ahead of the back-translation approach.} {back translation,comparison of translation methods,questionnaire translation,split-ballot experiment,team translation} {back translation,comparison of translation methods,questionnaire translation,split-ballot experiment,team translation}', 'how does back translation fare against team translation? an experimental case study in the language combination english–german {when it comes to quality in questionnaire translation and hence comparability in comparative research, the chosen translation method is crucial for the outcome. few empirical studies compare different translation methods—a fact which is often deplored in the research community. to fill the gap, in this study, the team translation approach is compared against a simple back-translation approach. the starting point in both cases was the initial english–german translations of issp (international social survey program) questions. the final translations from both approaches were assessed, with a focus on how translation issues, such as mistranslations or wording issues identified in the initial translations were addressed. while none of the twenty-nine issues in the initial translation were present in the final team translation version, twenty-two of these issues were still present in the final version after the back-translation approach. for a selected number of items, we also ran a split-ballot experiment in a web survey. only five out of fifteen items (33 percent) that went into the experiment showed significant differences between the translations, and only one could clearly be attributed to remaining errors in the back-translation version. in sum, the final translation from the team approach clearly outperformed the final translation from the back-translation approach when it comes to text-based criteria (in particular, accuracy and fluency). the quantitative test showed that many translation issues (those remaining in the translation after the back translation step) had no effect on the estimates. nevertheless, we ask respondents to put effort into survey responding; in the same vein, we as researchers should put effort in the survey experience by providing questions that are clearly worded and free of errors, which puts the team approach ahead of the back-translation approach.} {back translation,comparison of translation methods,questionnaire translation,split-ballot experiment,team translation} {back translation,comparison of translation methods,questionnaire translation,split-ballot experiment,team translation}']"
18,16,18_content_political attitudes_web tracking_measure,"['content', 'political attitudes', 'web tracking', 'measure', 'tweets']","['how to detect and influence looking up answers to political knowledge questions in web surveys {when answering political knowledge questions in web surveys, respondents can look up the correct answer on the internet. this response behavior artificially inflates political knowledge scores that are supposed to measure fact-based information. in the present study, we address the existing knowledge gaps of previous research regarding looking up answers to political knowledge questions in web surveys. we conducted an experimental study based on the german internet panel, a large-scale population survey that uses a probability-based sample. based on this experiment, we show that instructions help to reduce the number of lookups to knowledge questions in web surveys. we provide further evidence that looking up answers results in more correct answers to knowledge questions and, thus, in inflated political knowledge scores. finally, our findings illustrate the challenges and benefits of using self-reported or paradata-based lookup measures as well as a combined measure that aims at utilizing both to detect lookups to political knowledge questions in web surveys.}', 'how to detect and influence looking up answers to political knowledge questions in web surveys {when answering political knowledge questions in web surveys, respondents can look up the correct answer on the internet. this response behavior artificially inflates political knowledge scores that are supposed to measure fact-based information. in the present study, we address the existing knowledge gaps of previous research regarding looking up answers to political knowledge questions in web surveys. we conducted an experimental study based on the german internet panel, a large-scale population survey that uses a probability-based sample. based on this experiment, we show that instructions help to reduce the number of lookups to knowledge questions in web surveys. we provide further evidence that looking up answers results in more correct answers to knowledge questions and, thus, in inflated political knowledge scores. finally, our findings illustrate the challenges and benefits of using self-reported or paradata-based lookup measures as well as a combined measure that aims at utilizing both to detect lookups to political knowledge questions in web surveys.}', 'how to detect and influence looking up answers to political knowledge questions in web surveys {when answering political knowledge questions in web surveys, respondents can look up the correct answer on the internet. this response behavior artificially inflates political knowledge scores that are supposed to measure fact-based information. in the present study, we address the existing knowledge gaps of previous research regarding looking up answers to political knowledge questions in web surveys. we conducted an experimental study based on the german internet panel, a large-scale population survey that uses a probability-based sample. based on this experiment, we show that instructions help to reduce the number of lookups to knowledge questions in web surveys. we provide further evidence that looking up answers results in more correct answers to knowledge questions and, thus, in inflated political knowledge scores. finally, our findings illustrate the challenges and benefits of using self-reported or paradata-based lookup measures as well as a combined measure that aims at utilizing both to detect lookups to political knowledge questions in web surveys.}']"
19,15,19_chapter_processes_germany_changes,"['chapter', 'processes', 'germany', 'changes', 'political attitudes']","['introduction {german unification can be viewed as a case study when it comes to analyzing transformation processes. to understand and investigate these processes, this chapter follows two main goals. first, it is necessary to have a basic understanding of the historical setting. this introduction thus serves as an overarching chapter, giving a short overview of differences in political systems and ideology during the time of the german separation, the rapprochement and transformation process as well as discussions about possible causes for persisting differences. it will explain how the perspectives taken in the following parts and individual chapters tie together to form a picture of transformation processes in germany. second, this chapter serves as a methodological guide through different statistical approaches that may be used to analyze societal and individual changes over time by pointing out common pitfalls of study designs and methods used in transformation research. after giving an overview of methods used in the past, the datasets and methods used in this volume are introduced. the chapter concludes with a critical discussion of past and present methods above and beyond the specific german context.}', 'introduction {german unification can be viewed as a case study when it comes to analyzing transformation processes. to understand and investigate these processes, this chapter follows two main goals. first, it is necessary to have a basic understanding of the historical setting. this introduction thus serves as an overarching chapter, giving a short overview of differences in political systems and ideology during the time of the german separation, the rapprochement and transformation process as well as discussions about possible causes for persisting differences. it will explain how the perspectives taken in the following parts and individual chapters tie together to form a picture of transformation processes in germany. second, this chapter serves as a methodological guide through different statistical approaches that may be used to analyze societal and individual changes over time by pointing out common pitfalls of study designs and methods used in transformation research. after giving an overview of methods used in the past, the datasets and methods used in this volume are introduced. the chapter concludes with a critical discussion of past and present methods above and beyond the specific german context.}', 'introduction {german unification can be viewed as a case study when it comes to analyzing transformation processes. to understand and investigate these processes, this chapter follows two main goals. first, it is necessary to have a basic understanding of the historical setting. this introduction thus serves as an overarching chapter, giving a short overview of differences in political systems and ideology during the time of the german separation, the rapprochement and transformation process as well as discussions about possible causes for persisting differences. it will explain how the perspectives taken in the following parts and individual chapters tie together to form a picture of transformation processes in germany. second, this chapter serves as a methodological guide through different statistical approaches that may be used to analyze societal and individual changes over time by pointing out common pitfalls of study designs and methods used in transformation research. after giving an overview of methods used in the past, the datasets and methods used in this volume are introduced. the chapter concludes with a critical discussion of past and present methods above and beyond the specific german context.}']"
20,15,20_open science_social media_publications_training,"['open science', 'social media', 'publications', 'training', 'retrieval']","['can i trust and share it? enhancing scientific content in social media posts with additional information {recent advances on the web have made social media a significant platform for disseminating scientific information. however, posts referencing peer-reviewed research often lack sufficient context for non-experts to assess their credibility. in this study, we investigate how different strategies for enriching social media posts referencing scientific publications affect users’ trust perceptions and sharing behavior. we developed a web-based platform that simulates a social media feed containing posts with links to scientific publications and conducted a user study (n=160), comparing four conditions: a baseline with original posts, and three enriched variants containing (1) metadata from the publication (title, abstract, authors), (2) a direct quote from the publication, and (3) an ai-generated summary of the publication. our results show that enriched posts were shared more frequently than baseline posts, though trustworthiness ratings did not significantly differ. furthermore, the ai-generated summaries were perceived as the most understandable form of enrichment. interaction data showed that users were more likely to engage with the enriched content than with posts containing only links to the publications.} {ai-generated summary,scientific information,sharing behavior,social media,trustworthiness} {ai-generated summary,scientific information,sharing behavior,social media,trustworthiness}', 'can i trust and share it? enhancing scientific content in social media posts with additional information {recent advances on the web have made social media a significant platform for disseminating scientific information. however, posts referencing peer-reviewed research often lack sufficient context for non-experts to assess their credibility. in this study, we investigate how different strategies for enriching social media posts referencing scientific publications affect users’ trust perceptions and sharing behavior. we developed a web-based platform that simulates a social media feed containing posts with links to scientific publications and conducted a user study (n=160), comparing four conditions: a baseline with original posts, and three enriched variants containing (1) metadata from the publication (title, abstract, authors), (2) a direct quote from the publication, and (3) an ai-generated summary of the publication. our results show that enriched posts were shared more frequently than baseline posts, though trustworthiness ratings did not significantly differ. furthermore, the ai-generated summaries were perceived as the most understandable form of enrichment. interaction data showed that users were more likely to engage with the enriched content than with posts containing only links to the publications.} {ai-generated summary,scientific information,sharing behavior,social media,trustworthiness} {ai-generated summary,scientific information,sharing behavior,social media,trustworthiness}', 'can i trust and share it? enhancing scientific content in social media posts with additional information {recent advances on the web have made social media a significant platform for disseminating scientific information. however, posts referencing peer-reviewed research often lack sufficient context for non-experts to assess their credibility. in this study, we investigate how different strategies for enriching social media posts referencing scientific publications affect users’ trust perceptions and sharing behavior. we developed a web-based platform that simulates a social media feed containing posts with links to scientific publications and conducted a user study (n=160), comparing four conditions: a baseline with original posts, and three enriched variants containing (1) metadata from the publication (title, abstract, authors), (2) a direct quote from the publication, and (3) an ai-generated summary of the publication. our results show that enriched posts were shared more frequently than baseline posts, though trustworthiness ratings did not significantly differ. furthermore, the ai-generated summaries were perceived as the most understandable form of enrichment. interaction data showed that users were more likely to engage with the enriched content than with posts containing only links to the publications.} {ai-generated summary,scientific information,sharing behavior,social media,trustworthiness} {ai-generated summary,scientific information,sharing behavior,social media,trustworthiness}']"
21,14,21_modeling_detection_correlation_gender,"['modeling', 'detection', 'correlation', 'gender', 'depth']","['why we need to abandon fixed cutoffs for goodness-of-fit indices: an extensive simulation and possible solutions {to evaluate model fit in confirmatory factor analysis, researchers compare goodness-of-fit indices (gofs) against fixed cutoff values (e.g., cfi >.950) derived from simulation studies. methodologists have cautioned that cutoffs for gofs are only valid for settings similar to the simulation scenarios from which cutoffs originated. despite these warnings, fixed cutoffs for popular gofs (i.e., χ2, χ2/df, cfi, rmsea, srmr) continue to be widely used in applied research. we (1) argue that the practice of using fixed cutoffs needs to be abandoned and (2) review time-honored and emerging alternatives to fixed cutoffs. we first present the most in-depth simulation study to date on the sensitivity of gofs to model misspecification (i.e., misspecified factor dimensionality and unmodeled cross-loadings) and their susceptibility to further data and analysis characteristics (i.e., estimator, number of indicators, number and distribution of response options, loading magnitude, sample size, and factor correlation). we included all characteristics identified as influential in previous studies. our simulation enabled us to replicate well-known influences on gofs and establish hitherto unknown or underappreciated ones. in particular, the magnitude of the factor correlation turned out to moderate the effects of several characteristics on gofs. second, to address these problems, we discuss several strategies for assessing model fit that take the dependency of gofs on the modeling context into account. we highlight tailored (or “dynamic”) cutoffs as a way forward. we provide convenient tables with scenario-specific cutoffs as well as regression formulae to predict cutoffs tailored to the empirical setting of interest.} {confirmatory factor analysis,fit index,goodness-of-fit,ordered categorical data,structural equation modeling} {confirmatory factor analysis,fit index,goodness-of-fit,ordered categorical data,structural equation modeling}', 'why we need to abandon fixed cutoffs for goodness-of-fit indices: an extensive simulation and possible solutions {to evaluate model fit in confirmatory factor analysis, researchers compare goodness-of-fit indices (gofs) against fixed cutoff values (e.g., cfi >.950) derived from simulation studies. methodologists have cautioned that cutoffs for gofs are only valid for settings similar to the simulation scenarios from which cutoffs originated. despite these warnings, fixed cutoffs for popular gofs (i.e., χ2, χ2/df, cfi, rmsea, srmr) continue to be widely used in applied research. we (1) argue that the practice of using fixed cutoffs needs to be abandoned and (2) review time-honored and emerging alternatives to fixed cutoffs. we first present the most in-depth simulation study to date on the sensitivity of gofs to model misspecification (i.e., misspecified factor dimensionality and unmodeled cross-loadings) and their susceptibility to further data and analysis characteristics (i.e., estimator, number of indicators, number and distribution of response options, loading magnitude, sample size, and factor correlation). we included all characteristics identified as influential in previous studies. our simulation enabled us to replicate well-known influences on gofs and establish hitherto unknown or underappreciated ones. in particular, the magnitude of the factor correlation turned out to moderate the effects of several characteristics on gofs. second, to address these problems, we discuss several strategies for assessing model fit that take the dependency of gofs on the modeling context into account. we highlight tailored (or “dynamic”) cutoffs as a way forward. we provide convenient tables with scenario-specific cutoffs as well as regression formulae to predict cutoffs tailored to the empirical setting of interest.} {confirmatory factor analysis,fit index,goodness-of-fit,ordered categorical data,structural equation modeling} {confirmatory factor analysis,fit index,goodness-of-fit,ordered categorical data,structural equation modeling}', 'why we need to abandon fixed cutoffs for goodness-of-fit indices: an extensive simulation and possible solutions {to evaluate model fit in confirmatory factor analysis, researchers compare goodness-of-fit indices (gofs) against fixed cutoff values (e.g., cfi >.950) derived from simulation studies. methodologists have cautioned that cutoffs for gofs are only valid for settings similar to the simulation scenarios from which cutoffs originated. despite these warnings, fixed cutoffs for popular gofs (i.e., χ2, χ2/df, cfi, rmsea, srmr) continue to be widely used in applied research. we (1) argue that the practice of using fixed cutoffs needs to be abandoned and (2) review time-honored and emerging alternatives to fixed cutoffs. we first present the most in-depth simulation study to date on the sensitivity of gofs to model misspecification (i.e., misspecified factor dimensionality and unmodeled cross-loadings) and their susceptibility to further data and analysis characteristics (i.e., estimator, number of indicators, number and distribution of response options, loading magnitude, sample size, and factor correlation). we included all characteristics identified as influential in previous studies. our simulation enabled us to replicate well-known influences on gofs and establish hitherto unknown or underappreciated ones. in particular, the magnitude of the factor correlation turned out to moderate the effects of several characteristics on gofs. second, to address these problems, we discuss several strategies for assessing model fit that take the dependency of gofs on the modeling context into account. we highlight tailored (or “dynamic”) cutoffs as a way forward. we provide convenient tables with scenario-specific cutoffs as well as regression formulae to predict cutoffs tailored to the empirical setting of interest.} {confirmatory factor analysis,fit index,goodness-of-fit,ordered categorical data,structural equation modeling} {confirmatory factor analysis,fit index,goodness-of-fit,ordered categorical data,structural equation modeling}']"
22,14,22_voting_immigration_media_right wing,"['voting', 'immigration', 'media', 'right wing', 'individual level']","[""ready or not. national identity, vote choice, and mass media: evidence from germany {exploiting the increased prominence of debates on immigration, right-wing parties often frame and campaign against immigrants as a threat to national societies. research on national identity has shown that these parties are particularly successful among voters with an ethnically charged, exclusionary conception of nation. national identity, however, tends to be rather latent and stable, while far-right voting is much more volatile. explaining a temporal influence of national identity on political behavior, social-psychological theories argue that identities need to be activated to become behaviorally relevant. the main argument of this article is that the presence of immigration-related news in the mass media can serve as such a situational factor for thinking about the nation and thus increase its salience for electoral behavior. combining individual-level panel data from the german longitudinal election study's short-term campaign panel (gles, 2019) with a measure of media salience of immigration-related news in news articles, this study is the first to examine whether national identity can be activated for political behavior through the salience of immigration-related issues in the mass media using panel data.} {identity activation,media salience,national identity,voting} {identity activation,media salience,national identity,voting}"", ""ready or not. national identity, vote choice, and mass media: evidence from germany {exploiting the increased prominence of debates on immigration, right-wing parties often frame and campaign against immigrants as a threat to national societies. research on national identity has shown that these parties are particularly successful among voters with an ethnically charged, exclusionary conception of nation. national identity, however, tends to be rather latent and stable, while far-right voting is much more volatile. explaining a temporal influence of national identity on political behavior, social-psychological theories argue that identities need to be activated to become behaviorally relevant. the main argument of this article is that the presence of immigration-related news in the mass media can serve as such a situational factor for thinking about the nation and thus increase its salience for electoral behavior. combining individual-level panel data from the german longitudinal election study's short-term campaign panel (gles, 2019) with a measure of media salience of immigration-related news in news articles, this study is the first to examine whether national identity can be activated for political behavior through the salience of immigration-related issues in the mass media using panel data.} {identity activation,media salience,national identity,voting} {identity activation,media salience,national identity,voting}"", ""ready or not. national identity, vote choice, and mass media: evidence from germany {exploiting the increased prominence of debates on immigration, right-wing parties often frame and campaign against immigrants as a threat to national societies. research on national identity has shown that these parties are particularly successful among voters with an ethnically charged, exclusionary conception of nation. national identity, however, tends to be rather latent and stable, while far-right voting is much more volatile. explaining a temporal influence of national identity on political behavior, social-psychological theories argue that identities need to be activated to become behaviorally relevant. the main argument of this article is that the presence of immigration-related news in the mass media can serve as such a situational factor for thinking about the nation and thus increase its salience for electoral behavior. combining individual-level panel data from the german longitudinal election study's short-term campaign panel (gles, 2019) with a measure of media salience of immigration-related news in news articles, this study is the first to examine whether national identity can be activated for political behavior through the salience of immigration-related issues in the mass media using panel data.} {identity activation,media salience,national identity,voting} {identity activation,media salience,national identity,voting}""]"
23,13,23_european_governance_crises_attitudes,"['european', 'governance', 'crises', 'attitudes', 'levels']","['solidarity: a european value? {solidarity is considered essential for the sustainability of societies, both at the level of individual contributions to society and as an aspect of cooperation between countries. as such, solidarity is often called upon by politicians in a declarative way. in contrast to most prior work, we investigate an attitudinal perspective on solidarity, not behavioural or policy-preference perspectives. we look at questions such as the prevalence of solidarity attitudes among european populations, the degree to which the declared norm is shared among these populations, and whether solidarity attitudes have changed with consecutive crises in europe. we also discuss possible antecedents of solidarity levels. distinguishing solidarity by close and universal scopes, we find that both are associated with the identification of citizens with communities at different levels. in country and time comparisons, european societies display a good degree of homogeneity and stability. close solidarity is more pronounced than universal solidarity, and this may have even increased over consecutive crises. there are clear differences in relation to socio-historical region, but only modest associations with the religious composition of countries in terms of denominations. one role of religiosity might be that of an identity marker, where more heterogeneity comes with lower levels of solidarity.} {european crises,evs,identity,latent class analysis,solidarity} {european crises,evs,identity,latent class analysis,solidarity}', 'solidarity: a european value? {solidarity is considered essential for the sustainability of societies, both at the level of individual contributions to society and as an aspect of cooperation between countries. as such, solidarity is often called upon by politicians in a declarative way. in contrast to most prior work, we investigate an attitudinal perspective on solidarity, not behavioural or policy-preference perspectives. we look at questions such as the prevalence of solidarity attitudes among european populations, the degree to which the declared norm is shared among these populations, and whether solidarity attitudes have changed with consecutive crises in europe. we also discuss possible antecedents of solidarity levels. distinguishing solidarity by close and universal scopes, we find that both are associated with the identification of citizens with communities at different levels. in country and time comparisons, european societies display a good degree of homogeneity and stability. close solidarity is more pronounced than universal solidarity, and this may have even increased over consecutive crises. there are clear differences in relation to socio-historical region, but only modest associations with the religious composition of countries in terms of denominations. one role of religiosity might be that of an identity marker, where more heterogeneity comes with lower levels of solidarity.} {european crises,evs,identity,latent class analysis,solidarity} {european crises,evs,identity,latent class analysis,solidarity}', 'solidarity: a european value? {solidarity is considered essential for the sustainability of societies, both at the level of individual contributions to society and as an aspect of cooperation between countries. as such, solidarity is often called upon by politicians in a declarative way. in contrast to most prior work, we investigate an attitudinal perspective on solidarity, not behavioural or policy-preference perspectives. we look at questions such as the prevalence of solidarity attitudes among european populations, the degree to which the declared norm is shared among these populations, and whether solidarity attitudes have changed with consecutive crises in europe. we also discuss possible antecedents of solidarity levels. distinguishing solidarity by close and universal scopes, we find that both are associated with the identification of citizens with communities at different levels. in country and time comparisons, european societies display a good degree of homogeneity and stability. close solidarity is more pronounced than universal solidarity, and this may have even increased over consecutive crises. there are clear differences in relation to socio-historical region, but only modest associations with the religious composition of countries in terms of denominations. one role of religiosity might be that of an identity marker, where more heterogeneity comes with lower levels of solidarity.} {european crises,evs,identity,latent class analysis,solidarity} {european crises,evs,identity,latent class analysis,solidarity}']"
24,13,24_search engines_performance_open science_political science,"['search engines', 'performance', 'open science', 'political science', '2021']","['novelty in news search: a longitudinal study of the 2020 us elections {the 2020 us elections news coverage was extensive, with new pieces of information generated rapidly. this evolving scenario presented an opportunity to study the performance of search engines in a context in which they had to quickly process information as it was published. we analyze novelty, a measurement of new items that emerge in the top news search results, to compare the coverage and visibility of different topics. using virtual agents that simulate human web browsing behavior to collect search engine result pages, we conduct a longitudinal study of news results of five search engines collected in short bursts (every 21 minutes) from two regions (oregon, us and frankfurt, germany), starting on election day and lasting until one day after the announcement of biden as the winner. we find more new items emerging for election related queries (“joe biden,” “donald trump,” and “us elections”) compared to topical (e.g., “coronavirus”) or stable (e.g., “holocaust”) queries. we demonstrate that our method captures sudden changes in highly covered news topics as well as multiple differences across search engines and regions over time. we highlight novelty imbalances between candidate queries which affect their visibility during electoral periods, and conclude that, when it comes to news, search engines are responsible for such imbalances, either due to their algorithms or the set of news sources that they rely on.}', 'novelty in news search: a longitudinal study of the 2020 us elections {the 2020 us elections news coverage was extensive, with new pieces of information generated rapidly. this evolving scenario presented an opportunity to study the performance of search engines in a context in which they had to quickly process information as it was published. we analyze novelty, a measurement of new items that emerge in the top news search results, to compare the coverage and visibility of different topics. using virtual agents that simulate human web browsing behavior to collect search engine result pages, we conduct a longitudinal study of news results of five search engines collected in short bursts (every 21 minutes) from two regions (oregon, us and frankfurt, germany), starting on election day and lasting until one day after the announcement of biden as the winner. we find more new items emerging for election related queries (“joe biden,” “donald trump,” and “us elections”) compared to topical (e.g., “coronavirus”) or stable (e.g., “holocaust”) queries. we demonstrate that our method captures sudden changes in highly covered news topics as well as multiple differences across search engines and regions over time. we highlight novelty imbalances between candidate queries which affect their visibility during electoral periods, and conclude that, when it comes to news, search engines are responsible for such imbalances, either due to their algorithms or the set of news sources that they rely on.}', 'novelty in news search: a longitudinal study of the 2020 us elections {the 2020 us elections news coverage was extensive, with new pieces of information generated rapidly. this evolving scenario presented an opportunity to study the performance of search engines in a context in which they had to quickly process information as it was published. we analyze novelty, a measurement of new items that emerge in the top news search results, to compare the coverage and visibility of different topics. using virtual agents that simulate human web browsing behavior to collect search engine result pages, we conduct a longitudinal study of news results of five search engines collected in short bursts (every 21 minutes) from two regions (oregon, us and frankfurt, germany), starting on election day and lasting until one day after the announcement of biden as the winner. we find more new items emerging for election related queries (“joe biden,” “donald trump,” and “us elections”) compared to topical (e.g., “coronavirus”) or stable (e.g., “holocaust”) queries. we demonstrate that our method captures sudden changes in highly covered news topics as well as multiple differences across search engines and regions over time. we highlight novelty imbalances between candidate queries which affect their visibility during electoral periods, and conclude that, when it comes to news, search engines are responsible for such imbalances, either due to their algorithms or the set of news sources that they rely on.}']"
25,13,25_risk_children_immigration_19 pandemic,"['risk', 'children', 'immigration', '19 pandemic', '2020']","[""tit for tat? eu risk-sharing and experienced reciprocity {as with previous crises, eu-wide risk-sharing has also been demanded during the covid-19 pandemic. yet, this crisis did not unfold in a political vacuum. instead, public backing for eu-wide risk-sharing might have been informed by past crises experiences. building on the idea of experienced reciprocal risk-sharing, we assume that the willingness to share risks is greater when a crisis-ridden country has also shown solidarity before, whereas readiness to cooperate may be mitigated by non-solidarity-oriented behaviour in the past. we test this assumption based on a survey experiment carried out in eleven eu countries in 2020. our findings suggest that, when people are given information about whether another country has acted in solidarity in the past, this influences their willingness to support risk-sharing in the present. however, we also find evidence that respondents’ preferences outside the experimental setting do not always match their country's recent history of reciprocal risk-sharing.} {collective memory,covid-19,crises,eu,reciprocity,risk-sharing} {collective memory,covid-19,crises,eu,reciprocity,risk-sharing}"", ""tit for tat? eu risk-sharing and experienced reciprocity {as with previous crises, eu-wide risk-sharing has also been demanded during the covid-19 pandemic. yet, this crisis did not unfold in a political vacuum. instead, public backing for eu-wide risk-sharing might have been informed by past crises experiences. building on the idea of experienced reciprocal risk-sharing, we assume that the willingness to share risks is greater when a crisis-ridden country has also shown solidarity before, whereas readiness to cooperate may be mitigated by non-solidarity-oriented behaviour in the past. we test this assumption based on a survey experiment carried out in eleven eu countries in 2020. our findings suggest that, when people are given information about whether another country has acted in solidarity in the past, this influences their willingness to support risk-sharing in the present. however, we also find evidence that respondents’ preferences outside the experimental setting do not always match their country's recent history of reciprocal risk-sharing.} {collective memory,covid-19,crises,eu,reciprocity,risk-sharing} {collective memory,covid-19,crises,eu,reciprocity,risk-sharing}"", ""tit for tat? eu risk-sharing and experienced reciprocity {as with previous crises, eu-wide risk-sharing has also been demanded during the covid-19 pandemic. yet, this crisis did not unfold in a political vacuum. instead, public backing for eu-wide risk-sharing might have been informed by past crises experiences. building on the idea of experienced reciprocal risk-sharing, we assume that the willingness to share risks is greater when a crisis-ridden country has also shown solidarity before, whereas readiness to cooperate may be mitigated by non-solidarity-oriented behaviour in the past. we test this assumption based on a survey experiment carried out in eleven eu countries in 2020. our findings suggest that, when people are given information about whether another country has acted in solidarity in the past, this influences their willingness to support risk-sharing in the present. however, we also find evidence that respondents’ preferences outside the experimental setting do not always match their country's recent history of reciprocal risk-sharing.} {collective memory,covid-19,crises,eu,reciprocity,risk-sharing} {collective memory,covid-19,crises,eu,reciprocity,risk-sharing}""]"
26,12,26_discourse_social media_polarization_scenarios,"['discourse', 'social media', 'polarization', 'scenarios', 'election']","[""toeing the party line: election manifestos as a key to understand political discourse on twitter {political discourse on twitter is a moving target: politicians continuously make statements about their positions. it is therefore crucial to track their discourse on social media to understand their ideological positions and goals. however, twitter data is also challenging to work with since it is ambiguous and often dependent on social context, and consequently, recent work on political positioning has tended to focus strongly on manifestos (parties' electoral programs) rather than social media. in this paper, we extend recently proposed methods to predict pairwise positional similarities between parties from the manifesto case to the twitter case, using hashtags as a signal to fine-tune text representations, without the need for manual annotation. we verify the efficacy of fine-tuning and conduct a series of experiments that assess the robustness of our method for low-resource scenarios. we find that our method yields stable positioning reflective of manifesto positioning, both in scenarios with all tweets of candidates across years available and when only smaller subsets from shorter time periods are available. this indicates that it is possible to reliably analyze the relative positioning of actors forgoing manual annotation, even in the noisier context of social media.}"", ""toeing the party line: election manifestos as a key to understand political discourse on twitter {political discourse on twitter is a moving target: politicians continuously make statements about their positions. it is therefore crucial to track their discourse on social media to understand their ideological positions and goals. however, twitter data is also challenging to work with since it is ambiguous and often dependent on social context, and consequently, recent work on political positioning has tended to focus strongly on manifestos (parties' electoral programs) rather than social media. in this paper, we extend recently proposed methods to predict pairwise positional similarities between parties from the manifesto case to the twitter case, using hashtags as a signal to fine-tune text representations, without the need for manual annotation. we verify the efficacy of fine-tuning and conduct a series of experiments that assess the robustness of our method for low-resource scenarios. we find that our method yields stable positioning reflective of manifesto positioning, both in scenarios with all tweets of candidates across years available and when only smaller subsets from shorter time periods are available. this indicates that it is possible to reliably analyze the relative positioning of actors forgoing manual annotation, even in the noisier context of social media.}"", ""toeing the party line: election manifestos as a key to understand political discourse on twitter {political discourse on twitter is a moving target: politicians continuously make statements about their positions. it is therefore crucial to track their discourse on social media to understand their ideological positions and goals. however, twitter data is also challenging to work with since it is ambiguous and often dependent on social context, and consequently, recent work on political positioning has tended to focus strongly on manifestos (parties' electoral programs) rather than social media. in this paper, we extend recently proposed methods to predict pairwise positional similarities between parties from the manifesto case to the twitter case, using hashtags as a signal to fine-tune text representations, without the need for manual annotation. we verify the efficacy of fine-tuning and conduct a series of experiments that assess the robustness of our method for low-resource scenarios. we find that our method yields stable positioning reflective of manifesto positioning, both in scenarios with all tweets of candidates across years available and when only smaller subsets from shorter time periods are available. this indicates that it is possible to reliably analyze the relative positioning of actors forgoing manual annotation, even in the noisier context of social media.}""]"
27,11,27_family_network_italy_united states,"['family', 'network', 'italy', 'united states', 'correlation']","['resi: a comprehensive benchmark for representational similarity measures {measuring the similarity of different representations of neural architectures is a fundamental task and an open research challenge for the machine learning community. this paper presents the first comprehensive benchmark for evaluating representational similarity measures based on well-defined groundings of similarity. the representational similarity (resi) benchmark consists of (i) six carefully designed tests for similarity measures, (ii) 24 similarity measures, (iii) 14 neural network architectures, and (iv) seven datasets, spanning the graph, language, and vision domains. the benchmark opens up several important avenues of research on representational similarity that enable novel explorations and applications of neural architectures. we demonstrate the utility of the resi benchmark by conducting experiments on various neural network architectures, real-world datasets, and similarity measures. all components of the benchmark are publicly available and thereby facilitate systematic reproduction and production of research results. the benchmark is extensible; future research can build on it and expand on it. we believe that the resi benchmark can serve as a sound platform catalyzing future research that aims to systematically evaluate existing and explore novel ways of comparing representations of neural architectures.}', 'resi: a comprehensive benchmark for representational similarity measures {measuring the similarity of different representations of neural architectures is a fundamental task and an open research challenge for the machine learning community. this paper presents the first comprehensive benchmark for evaluating representational similarity measures based on well-defined groundings of similarity. the representational similarity (resi) benchmark consists of (i) six carefully designed tests for similarity measures, (ii) 24 similarity measures, (iii) 14 neural network architectures, and (iv) seven datasets, spanning the graph, language, and vision domains. the benchmark opens up several important avenues of research on representational similarity that enable novel explorations and applications of neural architectures. we demonstrate the utility of the resi benchmark by conducting experiments on various neural network architectures, real-world datasets, and similarity measures. all components of the benchmark are publicly available and thereby facilitate systematic reproduction and production of research results. the benchmark is extensible; future research can build on it and expand on it. we believe that the resi benchmark can serve as a sound platform catalyzing future research that aims to systematically evaluate existing and explore novel ways of comparing representations of neural architectures.}', 'resi: a comprehensive benchmark for representational similarity measures {measuring the similarity of different representations of neural architectures is a fundamental task and an open research challenge for the machine learning community. this paper presents the first comprehensive benchmark for evaluating representational similarity measures based on well-defined groundings of similarity. the representational similarity (resi) benchmark consists of (i) six carefully designed tests for similarity measures, (ii) 24 similarity measures, (iii) 14 neural network architectures, and (iv) seven datasets, spanning the graph, language, and vision domains. the benchmark opens up several important avenues of research on representational similarity that enable novel explorations and applications of neural architectures. we demonstrate the utility of the resi benchmark by conducting experiments on various neural network architectures, real-world datasets, and similarity measures. all components of the benchmark are publicly available and thereby facilitate systematic reproduction and production of research results. the benchmark is extensible; future research can build on it and expand on it. we believe that the resi benchmark can serve as a sound platform catalyzing future research that aims to systematically evaluate existing and explore novel ways of comparing representations of neural architectures.}']"
28,10,28_interviewing_performance_pretesting_machine learning,"['interviewing', 'performance', 'pretesting', 'machine learning', 'prevalence']","['a comparative evaluation of quantification methods {quantification represents the problem of estimating the distribution of class labels on unseen data. it also represents a growing research field in supervised machine learning, for which a large variety of different algorithms has been proposed in recent years. however, a comprehensive empirical comparison of quantification methods that supports algorithm selection is not available yet. in this work, we close this research gap by conducting a thorough empirical performance comparison of 24 different quantification methods on in total more than 40 datasets, considering binary as well as multiclass quantification settings. we observe that no single algorithm generally outperforms all competitors, but identify a group of methods that perform best in the binary setting, including the threshold selection-based median sweep and tsmax methods, the dys framework including the hdy method, forman’s mixture model, and friedman’s method. for the multiclass setting, we observe that a different, broad group of algorithms yields good performance, including the hdx method, the generalized probabilistic adjusted count, the readme method, the energy distance minimization method, the em algorithm for quantification, and friedman’s method. we also find that tuning the underlying classifiers has in most cases only a limited impact on the quantification performance. more generally, we find that the performance on multiclass quantification is inferior to the results obtained in the binary setting. our results can guide practitioners who intend to apply quantification algorithms and help researchers identify opportunities for future research.} {class distribution estimation,comparative evaluation,prevalence estimation,quantification,supervised machine learning} {class distribution estimation,comparative evaluation,prevalence estimation,quantification,supervised machine learning}', 'a comparative evaluation of quantification methods {quantification represents the problem of estimating the distribution of class labels on unseen data. it also represents a growing research field in supervised machine learning, for which a large variety of different algorithms has been proposed in recent years. however, a comprehensive empirical comparison of quantification methods that supports algorithm selection is not available yet. in this work, we close this research gap by conducting a thorough empirical performance comparison of 24 different quantification methods on in total more than 40 datasets, considering binary as well as multiclass quantification settings. we observe that no single algorithm generally outperforms all competitors, but identify a group of methods that perform best in the binary setting, including the threshold selection-based median sweep and tsmax methods, the dys framework including the hdy method, forman’s mixture model, and friedman’s method. for the multiclass setting, we observe that a different, broad group of algorithms yields good performance, including the hdx method, the generalized probabilistic adjusted count, the readme method, the energy distance minimization method, the em algorithm for quantification, and friedman’s method. we also find that tuning the underlying classifiers has in most cases only a limited impact on the quantification performance. more generally, we find that the performance on multiclass quantification is inferior to the results obtained in the binary setting. our results can guide practitioners who intend to apply quantification algorithms and help researchers identify opportunities for future research.} {class distribution estimation,comparative evaluation,prevalence estimation,quantification,supervised machine learning} {class distribution estimation,comparative evaluation,prevalence estimation,quantification,supervised machine learning}', 'a comparative evaluation of quantification methods {quantification represents the problem of estimating the distribution of class labels on unseen data. it also represents a growing research field in supervised machine learning, for which a large variety of different algorithms has been proposed in recent years. however, a comprehensive empirical comparison of quantification methods that supports algorithm selection is not available yet. in this work, we close this research gap by conducting a thorough empirical performance comparison of 24 different quantification methods on in total more than 40 datasets, considering binary as well as multiclass quantification settings. we observe that no single algorithm generally outperforms all competitors, but identify a group of methods that perform best in the binary setting, including the threshold selection-based median sweep and tsmax methods, the dys framework including the hdy method, forman’s mixture model, and friedman’s method. for the multiclass setting, we observe that a different, broad group of algorithms yields good performance, including the hdx method, the generalized probabilistic adjusted count, the readme method, the energy distance minimization method, the em algorithm for quantification, and friedman’s method. we also find that tuning the underlying classifiers has in most cases only a limited impact on the quantification performance. more generally, we find that the performance on multiclass quantification is inferior to the results obtained in the binary setting. our results can guide practitioners who intend to apply quantification algorithms and help researchers identify opportunities for future research.} {class distribution estimation,comparative evaluation,prevalence estimation,quantification,supervised machine learning} {class distribution estimation,comparative evaluation,prevalence estimation,quantification,supervised machine learning}']"
