Topic,Count,Name,Representation,Representative_Docs
-1,13,-1_task_online_named entity recognition_f1,"['task', 'online', 'named entity recognition', 'f1', 'evidence']","[""in scientific papers, it is common practice to cite other articles to substantiate claims, provide evidence for factual assertions, reference limitations, and research gaps, and fulfill various other purposes. when authors include a citation in a given sentence, there are two considerations they need to take into account: (i) where in the sentence to place the citation and (ii) which citation to choose to support the underlying claim. in this paper, we focus on the first task as it allows multiple potential approaches that rely on the researcher's individual style and the specific norms and conventions of the relevant scientific community. we propose two automatic methodologies that leverage transformers architecture for either solving a mask-filling problem or a named entity recognition problem. on top of the results of the proposed methodologies, we apply ad-hoc natural language processing heuristics to further improve their outcome. we also introduce s2orc-9k, an open dataset for fine-tuning models on this task. a formal evaluation demonstrates that the generative approach significantly outperforms five alternative methods when fine-tuned on the novel dataset. furthermore, this model's results show no statistically significant deviation from the outputs of three senior researchers."", ""in scientific papers, it is common practice to cite other articles to substantiate claims, provide evidence for factual assertions, reference limitations, and research gaps, and fulfill various other purposes. when authors include a citation in a given sentence, there are two considerations they need to take into account: (i) where in the sentence to place the citation and (ii) which citation to choose to support the underlying claim. in this paper, we focus on the first task as it allows multiple potential approaches that rely on the researcher's individual style and the specific norms and conventions of the relevant scientific community. we propose two automatic methodologies that leverage transformers architecture for either solving a mask-filling problem or a named entity recognition problem. on top of the results of the proposed methodologies, we apply ad-hoc natural language processing heuristics to further improve their outcome. we also introduce s2orc-9k, an open dataset for fine-tuning models on this task. a formal evaluation demonstrates that the generative approach significantly outperforms five alternative methods when fine-tuned on the novel dataset. furthermore, this model's results show no statistically significant deviation from the outputs of three senior researchers."", ""in scientific papers, it is common practice to cite other articles to substantiate claims, provide evidence for factual assertions, reference limitations, and research gaps, and fulfill various other purposes. when authors include a citation in a given sentence, there are two considerations they need to take into account: (i) where in the sentence to place the citation and (ii) which citation to choose to support the underlying claim. in this paper, we focus on the first task as it allows multiple potential approaches that rely on the researcher's individual style and the specific norms and conventions of the relevant scientific community. we propose two automatic methodologies that leverage transformers architecture for either solving a mask-filling problem or a named entity recognition problem. on top of the results of the proposed methodologies, we apply ad-hoc natural language processing heuristics to further improve their outcome. we also introduce s2orc-9k, an open dataset for fine-tuning models on this task. a formal evaluation demonstrates that the generative approach significantly outperforms five alternative methods when fine-tuned on the novel dataset. furthermore, this model's results show no statistically significant deviation from the outputs of three senior researchers.""]"
0,62,0_language_training_domain_accuracy,"['language', 'training', 'domain', 'accuracy', 'impact']","['language models can serve as a valuable tool for software developers to increase productivity. large generative models can be used for code generation and code completion, while smaller encoder-only models are capable of performing code search tasks using natural language queries. these capabilities are heavily influenced by the quality and diversity of the available training data. source code datasets used for training usually focus on the most popular languages and testing is mostly conducted on the same distributions, often overlooking low-resource programming languages. motivated by the nlp generalization taxonomy proposed by hupkes et. al., we propose a new benchmark dataset called gencodesearchnet (gecs) which builds upon existing natural language code search datasets to systemically evaluate the programming language understanding generalization capabilities of language models. as part of the full dataset, we introduce a new, manually curated subset statcodesearch that focuses on r, a popular but so far underrepresented programming language that is often used by researchers outside the field of computer science. for evaluation and comparison, we collect several baseline results using fine-tuned bert-style models and gpt-style large language models in a zero-shot setting.', 'language models can serve as a valuable tool for software developers to increase productivity. large generative models can be used for code generation and code completion, while smaller encoder-only models are capable of performing code search tasks using natural language queries. these capabilities are heavily influenced by the quality and diversity of the available training data. source code datasets used for training usually focus on the most popular languages and testing is mostly conducted on the same distributions, often overlooking low-resource programming languages. motivated by the nlp generalization taxonomy proposed by hupkes et. al., we propose a new benchmark dataset called gencodesearchnet (gecs) which builds upon existing natural language code search datasets to systemically evaluate the programming language understanding generalization capabilities of language models. as part of the full dataset, we introduce a new, manually curated subset statcodesearch that focuses on r, a popular but so far underrepresented programming language that is often used by researchers outside the field of computer science. for evaluation and comparison, we collect several baseline results using fine-tuned bert-style models and gpt-style large language models in a zero-shot setting.', 'language models can serve as a valuable tool for software developers to increase productivity. large generative models can be used for code generation and code completion, while smaller encoder-only models are capable of performing code search tasks using natural language queries. these capabilities are heavily influenced by the quality and diversity of the available training data. source code datasets used for training usually focus on the most popular languages and testing is mostly conducted on the same distributions, often overlooking low-resource programming languages. motivated by the nlp generalization taxonomy proposed by hupkes et. al., we propose a new benchmark dataset called gencodesearchnet (gecs) which builds upon existing natural language code search datasets to systemically evaluate the programming language understanding generalization capabilities of language models. as part of the full dataset, we introduce a new, manually curated subset statcodesearch that focuses on r, a popular but so far underrepresented programming language that is often used by researchers outside the field of computer science. for evaluation and comparison, we collect several baseline results using fine-tuned bert-style models and gpt-style large language models in a zero-shot setting.']"
1,28,1_training_domain_topics_automated,"['training', 'domain', 'topics', 'automated', 'increasing']","['given the recent proliferation of fake news online, fact-checking has emerged as a critical defence against misinformation. several fact-checking organisations are currently employed in the initiative to assess the truthfulness of online claims. verified claims serve as foundational data for various cross-domain research, including fields of social science and natural language processing, where they are used to study misinformation and several downstream tasks such as automated fact-verification. however, these fact-checking websites inherently harbour biases, posing challenges for academic endeavours aiming to discern truth from misinformation. in this study, we aim to explore the evolving landscape of online claims verified by multiple fact-checking organisations and analyse the underlying biases of individual fact-checking websites. leveraging claimskg, the largest available corpus of fact-checked claims, we analyse the temporal evolution of claims, focusing on topics, veracity levels, and entities to offer insights into the complex dimensions of online information. we utilise data and dimensions available from claimskg for our analysis and for dimensions such as topics which are not present in claimskg, we create a topic taxonomy and implement a transformer-based model, for multi-label classification of claims. we also observe how similar claims are co-occurant amongst different websites. our work serves as a standardised framework for categorising claims sourced from diverse fact-checking organisations, laying the foundation for coherent and interpretable fact-checking datasets. the analysis conducted in this work sheds light on the dynamic landscape of online claims verified by several fact-checking organisations and dives into biases and distributions of several fact-checking websites.', 'given the recent proliferation of fake news online, fact-checking has emerged as a critical defence against misinformation. several fact-checking organisations are currently employed in the initiative to assess the truthfulness of online claims. verified claims serve as foundational data for various cross-domain research, including fields of social science and natural language processing, where they are used to study misinformation and several downstream tasks such as automated fact-verification. however, these fact-checking websites inherently harbour biases, posing challenges for academic endeavours aiming to discern truth from misinformation. in this study, we aim to explore the evolving landscape of online claims verified by multiple fact-checking organisations and analyse the underlying biases of individual fact-checking websites. leveraging claimskg, the largest available corpus of fact-checked claims, we analyse the temporal evolution of claims, focusing on topics, veracity levels, and entities to offer insights into the complex dimensions of online information. we utilise data and dimensions available from claimskg for our analysis and for dimensions such as topics which are not present in claimskg, we create a topic taxonomy and implement a transformer-based model, for multi-label classification of claims. we also observe how similar claims are co-occurant amongst different websites. our work serves as a standardised framework for categorising claims sourced from diverse fact-checking organisations, laying the foundation for coherent and interpretable fact-checking datasets. the analysis conducted in this work sheds light on the dynamic landscape of online claims verified by several fact-checking organisations and dives into biases and distributions of several fact-checking websites.', 'given the recent proliferation of fake news online, fact-checking has emerged as a critical defence against misinformation. several fact-checking organisations are currently employed in the initiative to assess the truthfulness of online claims. verified claims serve as foundational data for various cross-domain research, including fields of social science and natural language processing, where they are used to study misinformation and several downstream tasks such as automated fact-verification. however, these fact-checking websites inherently harbour biases, posing challenges for academic endeavours aiming to discern truth from misinformation. in this study, we aim to explore the evolving landscape of online claims verified by multiple fact-checking organisations and analyse the underlying biases of individual fact-checking websites. leveraging claimskg, the largest available corpus of fact-checked claims, we analyse the temporal evolution of claims, focusing on topics, veracity levels, and entities to offer insights into the complex dimensions of online information. we utilise data and dimensions available from claimskg for our analysis and for dimensions such as topics which are not present in claimskg, we create a topic taxonomy and implement a transformer-based model, for multi-label classification of claims. we also observe how similar claims are co-occurant amongst different websites. our work serves as a standardised framework for categorising claims sourced from diverse fact-checking organisations, laying the foundation for coherent and interpretable fact-checking datasets. the analysis conducted in this work sheds light on the dynamic landscape of online claims verified by several fact-checking organisations and dives into biases and distributions of several fact-checking websites.']"
2,27,2_scientific_extraction_topics_future,"['scientific', 'extraction', 'topics', 'future', 'intelligence']","['scientific publications serve as a source of disseminating information across research communities, often containing diverse data elements such as plain-text, tables, and figures. tables in particular offer a structured presentation of essential research data, enabling efficient information access. automatic extraction of tabular data alongside contextual information from scientific publications can significantly enhance research workflows and integrate more research data into scholarly research cycle, particularly supporting research data management (rdm). in marine geology, the researchers conduct expeditions at oceanographic locations and accumulate substantial amounts of valuable data such as sedimentation rate (sr), mass accumulation rate (mar) alongside relevant contextual information, often enriched with spatio-temporal context in tables of publications. these expeditions are costly and time intensive, emphasizing on the value of making such data more accessible and reusable. this paper introduces an end to end approach to extract and model heterogeneous tabular data from marine geology publications. our approach extracts metadata and tabular content from publications, modeling them into a heterogeneous information network (hin). the network uncovers hidden relationships and patterns across multiple documents, offering new insights and facilitating enhanced data referencing. experimental results and exploration on marine geology datasets demonstrate the effectiveness of our approach, showcasing its potential to support research data management and data driven scientific exploration.', 'the joint workshop of the 4th extraction and evaluation of knowledge entities from scientific documents (eeke2023; https://eeke-workshop.github.io/) and the 3rd ai + informetrics (aii2023; https://ai-informetrics.github.io/) was held at santa fe, new mexico, usa and online, co-located with the acm/ieee joint conference on digital libraries (jcdl) 2023. the two workshop series aim to engage the communities in open problems in the extraction and evaluation of knowledge entities from scientific documents and the modeling and applications of ai + informetrics for broad interests in science of science, science, technology, & innovation, etc. this joint workshop comprises keynote speeches, oral presentations, and poster sessions. the main topics of the proceedings include entity extraction and its applications, along with the integration of artificial intelligence + informetrics.', 'the joint workshop of the 5th extraction and evaluation of knowledge entities from scientific documents (eeke2024; https://eeke-workshop.github.io/) and the 4th ai + informetrics (aii2024; https://ai-informetrics.github.io/) was held in changchun, china and online, co-located with the iconference2024. the two workshop series are designed to actively engage diverse communities in addressing open challenges related to the extraction and evaluation of knowledge entities from scientific documents and the modeling and applications of ai-empowered informetrics for broad interests in science of science, science, technology, & innovation, etc. the joint workshop features a comprehensive agenda, including keynotes from leading experts, oral presentations showcasing cutting-edge research, and poster sessions for in-depth discussions. the primary topics covered in the proceedings encompass the methodologies and applications of entity extraction, as well as the convergence of ai and informetrics, to drive advancements in these fields.']"
3,24,3_domain_level_increasing_recent years,"['domain', 'level', 'increasing', 'recent years', 'resource']","['in recent years, exciting sources of data have been modeled as knowledge graphs (kgs). this modeling represents both structural relationships and the entity-specific multi-modal data in kgs. in various data analytics pipelines and machine learning (ml), the task of semantic similarity estimation plays a significant role. assigning similarity values to entity pairs is needed in recommendation systems, clustering, classification, entity matching/disambiguation and many others. efficient and scalable frameworks are needed to handle the quadratic complexity of all-pair semantic similarity on big data kgs. moreover, heterogeneous kgs demand multi-modal semantic similarity estimation to cover the versatile contents like categorical relations between classes or their attribute literals like strings, timestamps or numeric data. in this paper, we propose the sime4kg framework as a resource providing generic open-source modules that perform semantic similarity estimation in multi-modal kgs. to justify the computational costs of similarity estimation, the sime4kg generates reproducible, reusable and explainable results. the pipeline results are a native semantic rdf kg, including the experiment results, hyper-parameter setup and explanation of the results, like the most influential features. for fast and scalable execution in memory, we implemented the distributed approach using apache spark. the entire development of this framework is integrated into the holistic distributed semantic analytics stack (sansa).', 'in recent years, exciting sources of data have been modeled as knowledge graphs (kgs). this modeling represents both structural relationships and the entity-specific multi-modal data in kgs. in various data analytics pipelines and machine learning (ml), the task of semantic similarity estimation plays a significant role. assigning similarity values to entity pairs is needed in recommendation systems, clustering, classification, entity matching/disambiguation and many others. efficient and scalable frameworks are needed to handle the quadratic complexity of all-pair semantic similarity on big data kgs. moreover, heterogeneous kgs demand multi-modal semantic similarity estimation to cover the versatile contents like categorical relations between classes or their attribute literals like strings, timestamps or numeric data. in this paper, we propose the sime4kg framework as a resource providing generic open-source modules that perform semantic similarity estimation in multi-modal kgs. to justify the computational costs of similarity estimation, the sime4kg generates reproducible, reusable and explainable results. the pipeline results are a native semantic rdf kg, including the experiment results, hyper-parameter setup and explanation of the results, like the most influential features. for fast and scalable execution in memory, we implemented the distributed approach using apache spark. the entire development of this framework is integrated into the holistic distributed semantic analytics stack (sansa).', 'in recent years, exciting sources of data have been modeled as knowledge graphs (kgs). this modeling represents both structural relationships and the entity-specific multi-modal data in kgs. in various data analytics pipelines and machine learning (ml), the task of semantic similarity estimation plays a significant role. assigning similarity values to entity pairs is needed in recommendation systems, clustering, classification, entity matching/disambiguation and many others. efficient and scalable frameworks are needed to handle the quadratic complexity of all-pair semantic similarity on big data kgs. moreover, heterogeneous kgs demand multi-modal semantic similarity estimation to cover the versatile contents like categorical relations between classes or their attribute literals like strings, timestamps or numeric data. in this paper, we propose the sime4kg framework as a resource providing generic open-source modules that perform semantic similarity estimation in multi-modal kgs. to justify the computational costs of similarity estimation, the sime4kg generates reproducible, reusable and explainable results. the pipeline results are a native semantic rdf kg, including the experiment results, hyper-parameter setup and explanation of the results, like the most influential features. for fast and scalable execution in memory, we implemented the distributed approach using apache spark. the entire development of this framework is integrated into the holistic distributed semantic analytics stack (sansa).']"
4,21,4_graph_network_state_best,"['graph', 'network', 'state', 'best', 'design']","[""session-based recommendation is a challenging task, which aims at making recommendation for anonymous users based on in-session data, i.e. short-term interaction data. most session-based recommendation methods only model user's preferences with the current session sequence, which ignore rich information from a global perspective. meanwhile, previous works usually apply gnn to capture the transformation relationship between items, however the graph used in gnn is built through a static mode, which may introduce noise to the graph structure if user's preferences shift. in this paper, we propose a novel method called dynamic global structure enhanced multi-channel graph neural network (dgs-mgnn) to learn accurate representations of items from multiple perspectives. in dgs-mgnn, we propose a novel gnn model named multi-channel graph neural network to generate the local, global and consensus graphs dynamically and learn more informative representations of items based on the corresponding graph. meanwhile, in order to reduce the noise information within sessions, we utilize the graph structure to assist the attention mechanism to filter noisy information within each session, so as to generate an accurate intention representation for the user. finally, combined with a repeat and explore module, a more accurate prediction probability distribution is generated. we conduct extensive experiments on three widely used datasets, and the results demonstrate that dgs-mgnn is consistently superior to the state-of-the-art baseline models."", ""session-based recommendation is a challenging task, which aims at making recommendation for anonymous users based on in-session data, i.e. short-term interaction data. most session-based recommendation methods only model user's preferences with the current session sequence, which ignore rich information from a global perspective. meanwhile, previous works usually apply gnn to capture the transformation relationship between items, however the graph used in gnn is built through a static mode, which may introduce noise to the graph structure if user's preferences shift. in this paper, we propose a novel method called dynamic global structure enhanced multi-channel graph neural network (dgs-mgnn) to learn accurate representations of items from multiple perspectives. in dgs-mgnn, we propose a novel gnn model named multi-channel graph neural network to generate the local, global and consensus graphs dynamically and learn more informative representations of items based on the corresponding graph. meanwhile, in order to reduce the noise information within sessions, we utilize the graph structure to assist the attention mechanism to filter noisy information within each session, so as to generate an accurate intention representation for the user. finally, combined with a repeat and explore module, a more accurate prediction probability distribution is generated. we conduct extensive experiments on three widely used datasets, and the results demonstrate that dgs-mgnn is consistently superior to the state-of-the-art baseline models."", ""session-based recommendation is a challenging task, which aims at making recommendation for anonymous users based on in-session data, i.e. short-term interaction data. most session-based recommendation methods only model user's preferences with the current session sequence, which ignore rich information from a global perspective. meanwhile, previous works usually apply gnn to capture the transformation relationship between items, however the graph used in gnn is built through a static mode, which may introduce noise to the graph structure if user's preferences shift. in this paper, we propose a novel method called dynamic global structure enhanced multi-channel graph neural network (dgs-mgnn) to learn accurate representations of items from multiple perspectives. in dgs-mgnn, we propose a novel gnn model named multi-channel graph neural network to generate the local, global and consensus graphs dynamically and learn more informative representations of items based on the corresponding graph. meanwhile, in order to reduce the noise information within sessions, we utilize the graph structure to assist the attention mechanism to filter noisy information within each session, so as to generate an accurate intention representation for the user. finally, combined with a repeat and explore module, a more accurate prediction probability distribution is generated. we conduct extensive experiments on three widely used datasets, and the results demonstrate that dgs-mgnn is consistently superior to the state-of-the-art baseline models.""]"
5,19,5_quality_search_behavior_key,"['quality', 'search', 'behavior', 'key', 'potential']","['anomaly detection is an important problem that has been well-studied within diverse research areas and application domains. however, within the field of semantic web and knowledge graphs, anomaly detection has been relatively overlooked. additionally, the existing literature on anomaly detection over knowledge graphs lacks proper organization and poses challenges for new researchers seeking a comprehensive understanding. in light of these gaps, this paper aims to offer a well-structured and comprehensive overview of the existing research conducted on anomaly detection over knowledge graphs. in this overview, we review the quality metrics of kgs and discuss the possible errors which may occur in different parts of the rdf data. additionally, we outline a generic conceptual framework for the execution pipeline of anomaly detection over kgs. moreover, we study the anomaly detection techniques, along with their variants, and present key assumptions, to differentiate between normal and anomalous behavior. finally, we outline open issues in research and challenges encountered while adopting anomaly detection techniques for kgs.', 'anomaly detection is an important problem that has been well-studied within diverse research areas and application domains. however, within the field of semantic web and knowledge graphs, anomaly detection has been relatively overlooked. additionally, the existing literature on anomaly detection over knowledge graphs lacks proper organization and poses challenges for new researchers seeking a comprehensive understanding. in light of these gaps, this paper aims to offer a well-structured and comprehensive overview of the existing research conducted on anomaly detection over knowledge graphs. in this overview, we review the quality metrics of kgs and discuss the possible errors which may occur in different parts of the rdf data. additionally, we outline a generic conceptual framework for the execution pipeline of anomaly detection over kgs. moreover, we study the anomaly detection techniques, along with their variants, and present key assumptions, to differentiate between normal and anomalous behavior. finally, we outline open issues in research and challenges encountered while adopting anomaly detection techniques for kgs.', 'anomaly detection is an important problem that has been well-studied within diverse research areas and application domains. however, within the field of semantic web and knowledge graphs, anomaly detection has been relatively overlooked. additionally, the existing literature on anomaly detection over knowledge graphs lacks proper organization and poses challenges for new researchers seeking a comprehensive understanding. in light of these gaps, this paper aims to offer a well-structured and comprehensive overview of the existing research conducted on anomaly detection over knowledge graphs. in this overview, we review the quality metrics of kgs and discuss the possible errors which may occur in different parts of the rdf data. additionally, we outline a generic conceptual framework for the execution pipeline of anomaly detection over kgs. moreover, we study the anomaly detection techniques, along with their variants, and present key assumptions, to differentiate between normal and anomalous behavior. finally, we outline open issues in research and challenges encountered while adopting anomaly detection techniques for kgs.']"
6,16,6_entities_performance_extraction_state art,"['entities', 'performance', 'extraction', 'state art', 'graph']","[""relation extraction, is a pivotal task in nlp, impacts information retrieval, natural language understanding (nlu) and knowledge generation. machine learning model has coined itself as the most influential term in this era of deep learning and llm. in scientific text how machine learning models relate with other key entities, holds always a quintessentially interesting topic. knowing the origins of machine learning model in terms of their architecture open a crucial tunnel of understanding towards its characteristics. in this paper we experiment on tracing the machine learning model architecture of the machine learning models from their mentions in scholarly texts. we attack this problem in supervised approach; first we identify multiple machine learning model oriented entities present in a sentence and then figure out if each of such entities are based on another such entity through binary ('based on' and other relation) classification task. we report our findings with four state of the art baseline models. the findings report here exemplary performance with luke model as winner. the presence of 'based on' relation has quite low evidence support, which effected the performance result of the models, which inspire for further explorations for improvement."", ""relation extraction, is a pivotal task in nlp, impacts information retrieval, natural language understanding (nlu) and knowledge generation. machine learning model has coined itself as the most influential term in this era of deep learning and llm. in scientific text how machine learning models relate with other key entities, holds always a quintessentially interesting topic. knowing the origins of machine learning model in terms of their architecture open a crucial tunnel of understanding towards its characteristics. in this paper we experiment on tracing the machine learning model architecture of the machine learning models from their mentions in scholarly texts. we attack this problem in supervised approach; first we identify multiple machine learning model oriented entities present in a sentence and then figure out if each of such entities are based on another such entity through binary ('based on' and other relation) classification task. we report our findings with four state of the art baseline models. the findings report here exemplary performance with luke model as winner. the presence of 'based on' relation has quite low evidence support, which effected the performance result of the models, which inspire for further explorations for improvement."", ""relation extraction, is a pivotal task in nlp, impacts information retrieval, natural language understanding (nlu) and knowledge generation. machine learning model has coined itself as the most influential term in this era of deep learning and llm. in scientific text how machine learning models relate with other key entities, holds always a quintessentially interesting topic. knowing the origins of machine learning model in terms of their architecture open a crucial tunnel of understanding towards its characteristics. in this paper we experiment on tracing the machine learning model architecture of the machine learning models from their mentions in scholarly texts. we attack this problem in supervised approach; first we identify multiple machine learning model oriented entities present in a sentence and then figure out if each of such entities are based on another such entity through binary ('based on' and other relation) classification task. we report our findings with four state of the art baseline models. the findings report here exemplary performance with luke model as winner. the presence of 'based on' relation has quite low evidence support, which effected the performance result of the models, which inspire for further explorations for improvement.""]"
7,15,7_online_topics_applications_impact,"['online', 'topics', 'applications', 'impact', 'employed']","[""artificial intelligence (ai) has emerged as a transformative technology with applications across multiple domains. the corpus of work related to the field of ai has grown significantly in volume as well as in terms of the application of ai in wider domains. however, given the wide application of ai in diverse areas, the measurement and characterization of the span of ai research is often a challenging task. bibliometrics is a well-established method in the scientific community to measure the patterns and impact of research. it however has also received significant criticism for its overemphasis on the macroscopic picture and the inability to provide a deep understanding of growth and thematic structure of knowledge-creation activities. therefore, this study presents a framework comprising of two techniques, namely, bradford's distribution and path analysis to characterize the growth and thematic evolution of the discipline. while the bradford distribution provides a macroscopic view of artificial intelligence research in terms of patterns of growth, the path analysis method presents a microscopic analysis of the thematic evolutionary trajectories, thereby completing the analytical framework. detailed insights into the evolution of each subdomain are drawn, major techniques employed in various ai applications are identified, and some relevant implications are discussed to demonstrate the usefulness of the analyses."", ""artificial intelligence (ai) has emerged as a transformative technology with applications across multiple domains. the corpus of work related to the field of ai has grown significantly in volume as well as in terms of the application of ai in wider domains. however, given the wide application of ai in diverse areas, the measurement and characterization of the span of ai research is often a challenging task. bibliometrics is a well-established method in the scientific community to measure the patterns and impact of research. it however has also received significant criticism for its overemphasis on the macroscopic picture and the inability to provide a deep understanding of growth and thematic structure of knowledge-creation activities. therefore, this study presents a framework comprising of two techniques, namely, bradford's distribution and path analysis to characterize the growth and thematic evolution of the discipline. while the bradford distribution provides a macroscopic view of artificial intelligence research in terms of patterns of growth, the path analysis method presents a microscopic analysis of the thematic evolutionary trajectories, thereby completing the analytical framework. detailed insights into the evolution of each subdomain are drawn, major techniques employed in various ai applications are identified, and some relevant implications are discussed to demonstrate the usefulness of the analyses."", ""artificial intelligence (ai) has emerged as a transformative technology with applications across multiple domains. the corpus of work related to the field of ai has grown significantly in volume as well as in terms of the application of ai in wider domains. however, given the wide application of ai in diverse areas, the measurement and characterization of the span of ai research is often a challenging task. bibliometrics is a well-established method in the scientific community to measure the patterns and impact of research. it however has also received significant criticism for its overemphasis on the macroscopic picture and the inability to provide a deep understanding of growth and thematic structure of knowledge-creation activities. therefore, this study presents a framework comprising of two techniques, namely, bradford's distribution and path analysis to characterize the growth and thematic evolution of the discipline. while the bradford distribution provides a macroscopic view of artificial intelligence research in terms of patterns of growth, the path analysis method presents a microscopic analysis of the thematic evolutionary trajectories, thereby completing the analytical framework. detailed insights into the evolution of each subdomain are drawn, major techniques employed in various ai applications are identified, and some relevant implications are discussed to demonstrate the usefulness of the analyses.""]"
8,11,8_impact_author_performance_corpus,"['impact', 'author', 'performance', 'corpus', 'types']","['evaluation of researchers’ output is vital for hiring committees and funding bodies, and it is usually measured via their scientific productivity, citations, or a combined metric such as the h-index. assessing young researchers is more critical because it takes a while to get citations and increment of h-index. hence, predicting the h-index can help to discover the researchers’ scientific impact. in addition, identifying the influential factors to predict the scientific impact is helpful for researchers and their organizations seeking solutions to improve it. this study investigates the effect of the author, paper/venue-specific features on the future h-index. for this purpose, we used a machine learning approach to predict the h-index and feature analysis techniques to advance the understanding of feature impact. utilizing the bibliometric data in scopus, we defined and extracted two main groups of features. the first relates to prior scientific impact, and we name it ‘prior impact-based features’ and includes the number of publications, received citations, and h-index. the second group is ‘non-prior impact-based features’ and contains the features related to author, co-authorship, paper, and venue characteristics. we explored their importance in predicting researchers’ h-index in three career phases. also, we examined the temporal dimension of predicting performance for different feature categories to find out which features are more reliable for long- and short-term prediction. we referred to the gender of the authors to examine the role of this author’s characteristics in the prediction task. our findings showed that gender has a very slight effect in predicting the h-index. although the results demonstrate better performance for the models containing prior impact-based features for all researchers’ groups in the near future, we found that non-prior impact-based features are more robust predictors for younger scholars in the long term. also, prior impact-based features lose their power to predict more than other features in the long term.', 'evaluation of researchers’ output is vital for hiring committees and funding bodies, and it is usually measured via their scientific productivity, citations, or a combined metric such as the h-index. assessing young researchers is more critical because it takes a while to get citations and increment of h-index. hence, predicting the h-index can help to discover the researchers’ scientific impact. in addition, identifying the influential factors to predict the scientific impact is helpful for researchers and their organizations seeking solutions to improve it. this study investigates the effect of the author, paper/venue-specific features on the future h-index. for this purpose, we used a machine learning approach to predict the h-index and feature analysis techniques to advance the understanding of feature impact. utilizing the bibliometric data in scopus, we defined and extracted two main groups of features. the first relates to prior scientific impact, and we name it ‘prior impact-based features’ and includes the number of publications, received citations, and h-index. the second group is ‘non-prior impact-based features’ and contains the features related to author, co-authorship, paper, and venue characteristics. we explored their importance in predicting researchers’ h-index in three career phases. also, we examined the temporal dimension of predicting performance for different feature categories to find out which features are more reliable for long- and short-term prediction. we referred to the gender of the authors to examine the role of this author’s characteristics in the prediction task. our findings showed that gender has a very slight effect in predicting the h-index. although the results demonstrate better performance for the models containing prior impact-based features for all researchers’ groups in the near future, we found that non-prior impact-based features are more robust predictors for younger scholars in the long term. also, prior impact-based features lose their power to predict more than other features in the long term.', 'evaluation of researchers’ output is vital for hiring committees and funding bodies, and it is usually measured via their scientific productivity, citations, or a combined metric such as the h-index. assessing young researchers is more critical because it takes a while to get citations and increment of h-index. hence, predicting the h-index can help to discover the researchers’ scientific impact. in addition, identifying the influential factors to predict the scientific impact is helpful for researchers and their organizations seeking solutions to improve it. this study investigates the effect of the author, paper/venue-specific features on the future h-index. for this purpose, we used a machine learning approach to predict the h-index and feature analysis techniques to advance the understanding of feature impact. utilizing the bibliometric data in scopus, we defined and extracted two main groups of features. the first relates to prior scientific impact, and we name it ‘prior impact-based features’ and includes the number of publications, received citations, and h-index. the second group is ‘non-prior impact-based features’ and contains the features related to author, co-authorship, paper, and venue characteristics. we explored their importance in predicting researchers’ h-index in three career phases. also, we examined the temporal dimension of predicting performance for different feature categories to find out which features are more reliable for long- and short-term prediction. we referred to the gender of the authors to examine the role of this author’s characteristics in the prediction task. our findings showed that gender has a very slight effect in predicting the h-index. although the results demonstrate better performance for the models containing prior impact-based features for all researchers’ groups in the near future, we found that non-prior impact-based features are more robust predictors for younger scholars in the long term. also, prior impact-based features lose their power to predict more than other features in the long term.']"
